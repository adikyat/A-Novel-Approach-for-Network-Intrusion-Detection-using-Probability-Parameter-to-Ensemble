{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Algo2NSL-KDD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S3VL09aoHRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "8a5fd69e-4367-49aa-dd88-32d1ef8a7394"
      },
      "source": [
        "from __future__ import print_function\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import h5py\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
        "import tensorflow.keras.backend as K\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z95qpcUGoUO2",
        "colab_type": "code",
        "outputId": "97197e4a-7d73-453b-81e9-d74ed5b5c48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtRaJMCNoHSD",
        "colab_type": "code",
        "outputId": "99e0cf82-ec5e-4b92-fe6a-b91d84c4e254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "data= pd.read_csv('drive/My Drive/BE FINAL/my_5class_shuffled.csv', index_col=None)\n",
        "#data= pd.read_csv('drive/My Drive/BE FINAL/Small Training Set_5class.csv', index_col=None)\n",
        "\n",
        "smdata= pd.read_csv('drive/My Drive/BE FINAL/KDDTest11_5.csv', index_col=None)\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(148514, 42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4Y9b3CGiWUJ",
        "colab_type": "code",
        "outputId": "1b9b1597-e134-4cc0-c5cd-f5a4ce9032f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "traindata,testdata = train_test_split(data, test_size=0.1, random_state=42)#random for splitting same data when run again.\n",
        "traindata,valdata = train_test_split(traindata, test_size=0.11, random_state=42)#random for splitting same data when run again.\n",
        "\n",
        "print(valdata.shape)\n",
        "print(traindata.shape)\n",
        "print(testdata.shape)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14703, 42)\n",
            "(118959, 42)\n",
            "(14852, 42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_U-l-McoHSl",
        "colab_type": "code",
        "outputId": "4fb0aed3-3429-47bb-c9cc-a86409d41741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from collections import Counter\n",
        "print(Counter(traindata[\"label\"]))\n",
        "print(Counter(testdata[\"label\"]))\n",
        "print(Counter(valdata[\"label\"]))\n",
        "print(Counter(smdata[\"label\"]))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'normal': 61633, 'dos': 42877, 'probe': 11278, 'r2l': 2975, 'u2r': 196})\n",
            "Counter({'normal': 7721, 'dos': 5275, 'probe': 1415, 'r2l': 406, 'u2r': 35})\n",
            "Counter({'normal': 7698, 'dos': 5232, 'probe': 1384, 'r2l': 368, 'u2r': 21})\n",
            "Counter({'normal': 9711, 'dos': 7458, 'r2l': 2754, 'probe': 2421, 'u2r': 200})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-C58aXfoHUG",
        "colab_type": "code",
        "outputId": "0e653945-0142-4362-eab2-66efc0ec707e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encodings = dict()\n",
        "for c in traindata.columns:\n",
        "    #print df[c].dtype\n",
        "    if traindata[c].dtype == \"object\":\n",
        "        encodings[c] = LabelEncoder() #to give numerical label to char type labels.\n",
        "        encodings[c]\n",
        "        traindata[c] = encodings[c].fit_transform(traindata[c])\n",
        "        testdata[c] = encodings[c].fit_transform(testdata[c])\n",
        "        valdata[c] = encodings[c].fit_transform(valdata[c])\n",
        "encodings1 = dict()\n",
        "for c in smdata.columns:\n",
        "    #print df[c].dtype\n",
        "    if smdata[c].dtype == \"object\":\n",
        "        encodings1[c] = LabelEncoder() #to give numerical label to char type labels.\n",
        "        encodings1[c]\n",
        "        smdata[c] = encodings1[c].fit_transform(smdata[c])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akSHPXhaoHU0",
        "colab_type": "code",
        "outputId": "90ed96dd-87fe-40f5-aa4d-5810b24d64c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(Counter(traindata[\"label\"]))\n",
        "print(Counter(testdata[\"label\"]))\n",
        "print(Counter(valdata[\"label\"]))\n",
        "print(Counter(smdata[\"label\"]))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({1: 61633, 0: 42877, 2: 11278, 3: 2975, 4: 196})\n",
            "Counter({1: 7721, 0: 5275, 2: 1415, 3: 406, 4: 35})\n",
            "Counter({1: 7698, 0: 5232, 2: 1384, 3: 368, 4: 21})\n",
            "Counter({1: 9711, 0: 7458, 3: 2754, 2: 2421, 4: 200})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUrxKwMFoHVQ",
        "colab_type": "code",
        "outputId": "3c97df7c-d97a-4126-932b-f9efa2621653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "X = traindata.iloc[:,0:41]\n",
        "Y = traindata.iloc[:,41]\n",
        "C = testdata.iloc[:,41]\n",
        "T = testdata.iloc[:,0:41]\n",
        "vx = valdata.iloc[:,0:41]\n",
        "vy = valdata.iloc[:,41]\n",
        "smx = smdata.iloc[:,0:41]\n",
        "smy = smdata.iloc[:,41]\n",
        "smx.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>\"protocol_type\"</th>\n",
              "      <th>\"service\"</th>\n",
              "      <th>\"flag\"</th>\n",
              "      <th>\"src_bytes\"</th>\n",
              "      <th>\"dst_bytes\"</th>\n",
              "      <th>land</th>\n",
              "      <th>\"wrong_fragment\"</th>\n",
              "      <th>urgent</th>\n",
              "      <th>\"hot\"</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>\"root_shell\"</th>\n",
              "      <th>su_attempted</th>\n",
              "      <th>num_root</th>\n",
              "      <th>num_file_creations</th>\n",
              "      <th>num_shells</th>\n",
              "      <th>\"num_access_files\"</th>\n",
              "      <th>num_outbound_cmds</th>\n",
              "      <th>is_host_login</th>\n",
              "      <th>is_guest_login</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate.1</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>229</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>255</td>\n",
              "      <td>10</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>255</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>12983</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>134</td>\n",
              "      <td>86</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3</td>\n",
              "      <td>57</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>29</td>\n",
              "      <td>86</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   duration   \"protocol_type\"  ...  dst_host_rerror_rate  dst_host_srv_rerror_rate\n",
              "0         0                 1  ...                  1.00                      1.00\n",
              "1         0                 1  ...                  1.00                      1.00\n",
              "2         2                 1  ...                  0.00                      0.00\n",
              "3         0                 0  ...                  0.00                      0.00\n",
              "4         1                 1  ...                  0.83                      0.71\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6OUNBP3oHVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=X.drop(['land','su_attempted','num_outbound_cmds','is_host_login','urgent','num_failed_logins','su_attempted','num_file_creations','num_shells','srv_diff_host_rate'], axis = 1) \n",
        "T=T.drop(['land','su_attempted','num_outbound_cmds','is_host_login','urgent','num_failed_logins','su_attempted','num_file_creations','num_shells','srv_diff_host_rate'], axis = 1) \n",
        "vx=vx.drop(['land','su_attempted','num_outbound_cmds','is_host_login','urgent','num_failed_logins','su_attempted','num_file_creations','num_shells','srv_diff_host_rate'], axis = 1) \n",
        "smx=smx.drop(['land','su_attempted','num_outbound_cmds','is_host_login','urgent','num_failed_logins','su_attempted','num_file_creations','num_shells','srv_diff_host_rate'], axis = 1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B-gOuYPoHVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler #normalization\n",
        "trainX= StandardScaler().fit_transform(X)\n",
        "testT= StandardScaler().fit_transform(T)\n",
        "valx= StandardScaler().fit_transform(vx)\n",
        "smx= StandardScaler().fit_transform(smx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcT88gFCuMFC",
        "colab_type": "code",
        "outputId": "6100df6e-d905-42da-8a3b-6d9ee38bfda8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "trainX_nn = np.array(X)\n",
        "testT_nn = np.array(T)\n",
        "valx_nn = np.array(vx)\n",
        "smx_nn = np.array(smx)\n",
        "\n",
        "trainX_nn.astype(float)\n",
        "testT_nn.astype(float)\n",
        "valx_nn.astype(float)\n",
        "smx_nn.astype(float)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.15553409, -0.17630335,  0.93396356, ..., -0.3527496 ,\n",
              "         1.97979091,  1.9291162 ],\n",
              "       [-0.15553409, -0.17630335,  0.93396356, ..., -0.3527496 ,\n",
              "         1.97979091,  1.9291162 ],\n",
              "       [-0.15411277, -0.17630335, -0.88225435, ..., -0.3527496 ,\n",
              "        -0.60271888, -0.56548308],\n",
              "       ...,\n",
              "       [-0.15553409, -0.17630335, -0.67269075, ..., -0.3527496 ,\n",
              "        -0.4219432 , -0.39086113],\n",
              "       [-0.15553409,  2.34244362, -1.44109063, ..., -0.3527496 ,\n",
              "        -0.60271888, -0.56548308],\n",
              "       [-0.15553409, -0.17630335,  1.42294531, ..., -0.3527496 ,\n",
              "         0.53358543,  1.9291162 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23D61u_HuWa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = Normalizer().fit(trainX_nn)\n",
        "trainX_nn = scaler.transform(trainX_nn)\n",
        "\n",
        "scaler = Normalizer().fit(testT_nn)\n",
        "testT_nn = scaler.transform(testT_nn)\n",
        "\n",
        "scaler = Normalizer().fit(valx_nn)\n",
        "valx_nn = scaler.transform(valx_nn)\n",
        "\n",
        "scaler = Normalizer().fit(smx_nn)\n",
        "smx_nn = scaler.transform(smx_nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXFZFc1moHV2",
        "colab_type": "code",
        "outputId": "7272a23d-7d75-4faa-f231-323775bb66be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train = np.array(Y)\n",
        "y_test = np.array(C)\n",
        "valy = np.array(vy)\n",
        "smy = np.array(smy)\n",
        "\n",
        "from collections import Counter\n",
        "Counter(y_train)\n",
        "Counter(y_test)\n",
        "valy[4]=4\n",
        "Counter(valy)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 5232, 1: 7697, 2: 1384, 3: 368, 4: 22})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3UBqREboHV5",
        "colab_type": "code",
        "outputId": "b0950a18-aebf-4d70-e6bf-803de9ddc928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y_train1= to_categorical(y_train)\n",
        "y_test1= to_categorical(y_test)\n",
        "valy1= to_categorical(valy)\n",
        "smy1= to_categorical(smy)\n",
        "\n",
        "X_train = np.array(trainX)\n",
        "X_test = np.array(testT)##\n",
        "X_val = np.array(valx)##\n",
        "X_sm = np.array(smx)##\n",
        "\n",
        "X_train_nn = np.array(trainX_nn)\n",
        "X_test_nn = np.array(testT_nn)##\n",
        "x_val_nn = np.array(valx_nn)##\n",
        "x_sm_nn = np.array(smx_nn)##\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "print(y_train1.shape)\n",
        "print(y_test1.shape)\n",
        "X_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(118959, 5)\n",
            "(14852, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118959, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO0cVL2KoHWD",
        "colab_type": "code",
        "outputId": "1f3286a9-92f9-424c-857f-3f6b100a4fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "    # reshape input to be [samples, time steps, features]\n",
        "X_train1_nn = np.reshape(X_train_nn, (X_train_nn.shape[0],X_train_nn.shape[1],1))\n",
        "X_test1_nn = np.reshape(X_test_nn, (X_test_nn.shape[0],X_test_nn.shape[1],1))\n",
        "x_val1_nn = np.reshape(x_val_nn, (x_val_nn.shape[0],x_val_nn.shape[1],1))\n",
        "x_sm1_nn = np.reshape(x_sm_nn, (x_sm_nn.shape[0],x_sm_nn.shape[1],1))\n",
        "\n",
        "X_train1_nn.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118959, 32, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMuGj-wnab3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "json_file = open('drive/My Drive/BE FINAL/nsl-kdd_final-code_results/cnn_model.json', 'r')\n",
        "nn_model_json = json_file.read()\n",
        "json_file.close()\n",
        "cnn = model_from_json(nn_model_json)\n",
        " #load weights into new model\n",
        "cnn.load_weights(\"drive/My Drive/BE FINAL/nsl-kdd_final-code_results/cnn_model.h5\")\n",
        "\n",
        "#knn_model = joblib.load('C:/Users/Aditya Kyatham/AppData/Local/Programs/Python/Python36/FINAL_BE_PROJ/CIC/knn_model.sav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3N0yvS1ljLY",
        "colab_type": "code",
        "outputId": "cf9cbde3-19cd-4fe7-d17d-db567a0af4f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "from keras.models import model_from_json\n",
        "\n",
        "cnn = Sequential()\n",
        "cnn.add(Conv1D(64, 3, activation=\"relu\", input_shape=(32, 1), padding=\"same\"))\n",
        "cnn.add(Conv1D(64, 3, activation=\"relu\", padding=\"same\"))\n",
        "cnn.add(MaxPooling1D(pool_size=2))\n",
        "cnn.add(Conv1D(128, 3, activation=\"relu\", padding=\"same\"))\n",
        "cnn.add(Conv1D(128, 3, activation=\"relu\", padding=\"same\"))\n",
        "cnn.add(MaxPooling1D(pool_size=2))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(256, activation=\"relu\"))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(5, activation=\"softmax\"))\n",
        "cnn.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])#,tf.keras.metrics.Precision()])#, tf.keras.metrics.Recall()])\n",
        "stopper = EarlyStopping(monitor='val_acc', patience = 10, mode='auto')\n",
        "\n",
        "history = cnn.fit(X_train1_nn, y_train1,batch_size=batch_size,validation_data=(x_val1_nn, valy1),epochs=1000)#,callbacks = [stopper])#,checkpointer,csv_logger])\n",
        "# serialize model to JSON\n",
        "#model_json = cnn.to_json()\n",
        "#with open(\"drive/My Drive/BE FINAL/nsl-kdd_final-code_results/cnn_model.json\", \"w\") as json_file:\n",
        "    #json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "#cnn.save_weights(\"drive/My Drive/BE FINAL/nsl-kdd_final-code_results/cnn_model.h5\")\n",
        "#print(\"Saved model to disk\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 809 samples, validate on 100 samples\n",
            "Epoch 1/1000\n",
            "809/809 [==============================] - 1s 1ms/step - loss: 1.1080 - acc: 0.7491 - val_loss: 0.6458 - val_acc: 0.7700\n",
            "Epoch 2/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 0.6186 - acc: 0.8035 - val_loss: 0.4731 - val_acc: 0.8400\n",
            "Epoch 3/1000\n",
            "809/809 [==============================] - 0s 143us/step - loss: 0.5187 - acc: 0.8319 - val_loss: 0.4213 - val_acc: 0.8500\n",
            "Epoch 4/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.4568 - acc: 0.8467 - val_loss: 0.3814 - val_acc: 0.9000\n",
            "Epoch 5/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 0.4164 - acc: 0.8690 - val_loss: 0.3316 - val_acc: 0.9100\n",
            "Epoch 6/1000\n",
            "809/809 [==============================] - 0s 145us/step - loss: 0.3941 - acc: 0.8690 - val_loss: 0.3144 - val_acc: 0.9400\n",
            "Epoch 7/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.3526 - acc: 0.8813 - val_loss: 0.2964 - val_acc: 0.9400\n",
            "Epoch 8/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 0.3367 - acc: 0.8912 - val_loss: 0.2902 - val_acc: 0.9400\n",
            "Epoch 9/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.3130 - acc: 0.8937 - val_loss: 0.2937 - val_acc: 0.9200\n",
            "Epoch 10/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 0.2976 - acc: 0.8986 - val_loss: 0.2773 - val_acc: 0.9400\n",
            "Epoch 11/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.2810 - acc: 0.9172 - val_loss: 0.2666 - val_acc: 0.9300\n",
            "Epoch 12/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 0.2727 - acc: 0.9147 - val_loss: 0.2652 - val_acc: 0.9400\n",
            "Epoch 13/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 0.2696 - acc: 0.9048 - val_loss: 0.2664 - val_acc: 0.9300\n",
            "Epoch 14/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 0.2644 - acc: 0.9135 - val_loss: 0.2497 - val_acc: 0.9400\n",
            "Epoch 15/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 0.2445 - acc: 0.9147 - val_loss: 0.2668 - val_acc: 0.9200\n",
            "Epoch 16/1000\n",
            "809/809 [==============================] - 0s 146us/step - loss: 0.2575 - acc: 0.9048 - val_loss: 0.2519 - val_acc: 0.9400\n",
            "Epoch 17/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.2285 - acc: 0.9147 - val_loss: 0.2582 - val_acc: 0.9400\n",
            "Epoch 18/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 0.2264 - acc: 0.9234 - val_loss: 0.2552 - val_acc: 0.9400\n",
            "Epoch 19/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.2193 - acc: 0.9221 - val_loss: 0.2355 - val_acc: 0.9400\n",
            "Epoch 20/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.2066 - acc: 0.9221 - val_loss: 0.2507 - val_acc: 0.9400\n",
            "Epoch 21/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 0.1925 - acc: 0.9394 - val_loss: 0.2532 - val_acc: 0.9400\n",
            "Epoch 22/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 0.2028 - acc: 0.9271 - val_loss: 0.2388 - val_acc: 0.9400\n",
            "Epoch 23/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.1902 - acc: 0.9357 - val_loss: 0.2361 - val_acc: 0.9400\n",
            "Epoch 24/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.1947 - acc: 0.9320 - val_loss: 0.3230 - val_acc: 0.9200\n",
            "Epoch 25/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 0.2114 - acc: 0.9308 - val_loss: 0.2447 - val_acc: 0.9500\n",
            "Epoch 26/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.1712 - acc: 0.9394 - val_loss: 0.2509 - val_acc: 0.9500\n",
            "Epoch 27/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 0.1738 - acc: 0.9333 - val_loss: 0.3071 - val_acc: 0.9200\n",
            "Epoch 28/1000\n",
            "809/809 [==============================] - 0s 141us/step - loss: 0.1722 - acc: 0.9394 - val_loss: 0.2362 - val_acc: 0.9400\n",
            "Epoch 29/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.1740 - acc: 0.9370 - val_loss: 0.2598 - val_acc: 0.9400\n",
            "Epoch 30/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.1831 - acc: 0.9370 - val_loss: 0.2257 - val_acc: 0.9500\n",
            "Epoch 31/1000\n",
            "809/809 [==============================] - 0s 106us/step - loss: 0.1701 - acc: 0.9407 - val_loss: 0.2320 - val_acc: 0.9500\n",
            "Epoch 32/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.1351 - acc: 0.9543 - val_loss: 0.2307 - val_acc: 0.9500\n",
            "Epoch 33/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 0.1365 - acc: 0.9518 - val_loss: 0.2533 - val_acc: 0.9500\n",
            "Epoch 34/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.1495 - acc: 0.9493 - val_loss: 0.2322 - val_acc: 0.9600\n",
            "Epoch 35/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 0.1282 - acc: 0.9617 - val_loss: 0.2386 - val_acc: 0.9500\n",
            "Epoch 36/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 0.1230 - acc: 0.9580 - val_loss: 0.2329 - val_acc: 0.9600\n",
            "Epoch 37/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.1192 - acc: 0.9629 - val_loss: 0.2282 - val_acc: 0.9700\n",
            "Epoch 38/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.1275 - acc: 0.9555 - val_loss: 0.2336 - val_acc: 0.9500\n",
            "Epoch 39/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.1245 - acc: 0.9604 - val_loss: 0.2357 - val_acc: 0.9600\n",
            "Epoch 40/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 0.1057 - acc: 0.9691 - val_loss: 0.2608 - val_acc: 0.9500\n",
            "Epoch 41/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.1154 - acc: 0.9518 - val_loss: 0.2836 - val_acc: 0.9400\n",
            "Epoch 42/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 0.1236 - acc: 0.9654 - val_loss: 0.2393 - val_acc: 0.9600\n",
            "Epoch 43/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.1071 - acc: 0.9629 - val_loss: 0.2504 - val_acc: 0.9700\n",
            "Epoch 44/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.0855 - acc: 0.9740 - val_loss: 0.2360 - val_acc: 0.9700\n",
            "Epoch 45/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.0874 - acc: 0.9728 - val_loss: 0.2540 - val_acc: 0.9700\n",
            "Epoch 46/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.1084 - acc: 0.9654 - val_loss: 0.2762 - val_acc: 0.9400\n",
            "Epoch 47/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 0.0989 - acc: 0.9629 - val_loss: 0.2868 - val_acc: 0.9500\n",
            "Epoch 48/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.1015 - acc: 0.9642 - val_loss: 0.2388 - val_acc: 0.9600\n",
            "Epoch 49/1000\n",
            "809/809 [==============================] - 0s 151us/step - loss: 0.0999 - acc: 0.9691 - val_loss: 0.2290 - val_acc: 0.9700\n",
            "Epoch 50/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 0.0711 - acc: 0.9740 - val_loss: 0.2745 - val_acc: 0.9500\n",
            "Epoch 51/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.1095 - acc: 0.9642 - val_loss: 0.2344 - val_acc: 0.9700\n",
            "Epoch 52/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.1243 - acc: 0.9617 - val_loss: 0.2313 - val_acc: 0.9700\n",
            "Epoch 53/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0810 - acc: 0.9728 - val_loss: 0.2229 - val_acc: 0.9700\n",
            "Epoch 54/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 0.0892 - acc: 0.9679 - val_loss: 0.2323 - val_acc: 0.9400\n",
            "Epoch 55/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 0.0806 - acc: 0.9753 - val_loss: 0.2250 - val_acc: 0.9700\n",
            "Epoch 56/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 0.0722 - acc: 0.9778 - val_loss: 0.2602 - val_acc: 0.9600\n",
            "Epoch 57/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 0.0708 - acc: 0.9740 - val_loss: 0.2519 - val_acc: 0.9600\n",
            "Epoch 58/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0655 - acc: 0.9728 - val_loss: 0.2650 - val_acc: 0.9700\n",
            "Epoch 59/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 0.0629 - acc: 0.9802 - val_loss: 0.2614 - val_acc: 0.9700\n",
            "Epoch 60/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0691 - acc: 0.9765 - val_loss: 0.2595 - val_acc: 0.9700\n",
            "Epoch 61/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0464 - acc: 0.9827 - val_loss: 0.2578 - val_acc: 0.9700\n",
            "Epoch 62/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0686 - acc: 0.9753 - val_loss: 0.2717 - val_acc: 0.9700\n",
            "Epoch 63/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 0.0577 - acc: 0.9815 - val_loss: 0.2734 - val_acc: 0.9700\n",
            "Epoch 64/1000\n",
            "809/809 [==============================] - 0s 136us/step - loss: 0.0489 - acc: 0.9852 - val_loss: 0.2919 - val_acc: 0.9600\n",
            "Epoch 65/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0457 - acc: 0.9889 - val_loss: 0.2375 - val_acc: 0.9700\n",
            "Epoch 66/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0484 - acc: 0.9864 - val_loss: 0.2712 - val_acc: 0.9700\n",
            "Epoch 67/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 0.0437 - acc: 0.9852 - val_loss: 0.2731 - val_acc: 0.9700\n",
            "Epoch 68/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.0488 - acc: 0.9802 - val_loss: 0.3002 - val_acc: 0.9700\n",
            "Epoch 69/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0532 - acc: 0.9864 - val_loss: 0.2610 - val_acc: 0.9600\n",
            "Epoch 70/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 0.0495 - acc: 0.9864 - val_loss: 0.2747 - val_acc: 0.9700\n",
            "Epoch 71/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0561 - acc: 0.9753 - val_loss: 0.2587 - val_acc: 0.9600\n",
            "Epoch 72/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 0.0531 - acc: 0.9790 - val_loss: 0.2721 - val_acc: 0.9600\n",
            "Epoch 73/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 0.0397 - acc: 0.9876 - val_loss: 0.2841 - val_acc: 0.9700\n",
            "Epoch 74/1000\n",
            "809/809 [==============================] - 0s 140us/step - loss: 0.0486 - acc: 0.9802 - val_loss: 0.2814 - val_acc: 0.9700\n",
            "Epoch 75/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0405 - acc: 0.9876 - val_loss: 0.2448 - val_acc: 0.9600\n",
            "Epoch 76/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0422 - acc: 0.9864 - val_loss: 0.2967 - val_acc: 0.9700\n",
            "Epoch 77/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0421 - acc: 0.9852 - val_loss: 0.2741 - val_acc: 0.9600\n",
            "Epoch 78/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0347 - acc: 0.9864 - val_loss: 0.2542 - val_acc: 0.9700\n",
            "Epoch 79/1000\n",
            "809/809 [==============================] - 0s 153us/step - loss: 0.0292 - acc: 0.9913 - val_loss: 0.3093 - val_acc: 0.9600\n",
            "Epoch 80/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.0381 - acc: 0.9839 - val_loss: 0.2473 - val_acc: 0.9700\n",
            "Epoch 81/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0424 - acc: 0.9839 - val_loss: 0.3034 - val_acc: 0.9500\n",
            "Epoch 82/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0329 - acc: 0.9913 - val_loss: 0.2992 - val_acc: 0.9700\n",
            "Epoch 83/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0412 - acc: 0.9864 - val_loss: 0.3415 - val_acc: 0.9500\n",
            "Epoch 84/1000\n",
            "809/809 [==============================] - 0s 138us/step - loss: 0.0435 - acc: 0.9839 - val_loss: 0.2914 - val_acc: 0.9600\n",
            "Epoch 85/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0324 - acc: 0.9876 - val_loss: 0.2698 - val_acc: 0.9700\n",
            "Epoch 86/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0283 - acc: 0.9926 - val_loss: 0.3250 - val_acc: 0.9700\n",
            "Epoch 87/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.0275 - acc: 0.9913 - val_loss: 0.3130 - val_acc: 0.9700\n",
            "Epoch 88/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0216 - acc: 0.9938 - val_loss: 0.3282 - val_acc: 0.9600\n",
            "Epoch 89/1000\n",
            "809/809 [==============================] - 0s 136us/step - loss: 0.0242 - acc: 0.9938 - val_loss: 0.3275 - val_acc: 0.9700\n",
            "Epoch 90/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0269 - acc: 0.9938 - val_loss: 0.3353 - val_acc: 0.9600\n",
            "Epoch 91/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0336 - acc: 0.9876 - val_loss: 0.3389 - val_acc: 0.9700\n",
            "Epoch 92/1000\n",
            "809/809 [==============================] - 0s 136us/step - loss: 0.0371 - acc: 0.9864 - val_loss: 0.3011 - val_acc: 0.9600\n",
            "Epoch 93/1000\n",
            "809/809 [==============================] - 0s 149us/step - loss: 0.0270 - acc: 0.9938 - val_loss: 0.3072 - val_acc: 0.9700\n",
            "Epoch 94/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 0.0174 - acc: 0.9963 - val_loss: 0.3327 - val_acc: 0.9700\n",
            "Epoch 95/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0140 - acc: 0.9975 - val_loss: 0.3354 - val_acc: 0.9700\n",
            "Epoch 96/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0228 - acc: 0.9926 - val_loss: 0.3589 - val_acc: 0.9700\n",
            "Epoch 97/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0214 - acc: 0.9938 - val_loss: 0.2905 - val_acc: 0.9700\n",
            "Epoch 98/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0221 - acc: 0.9938 - val_loss: 0.3334 - val_acc: 0.9600\n",
            "Epoch 99/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0179 - acc: 0.9951 - val_loss: 0.2772 - val_acc: 0.9700\n",
            "Epoch 100/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 0.0158 - acc: 0.9963 - val_loss: 0.3602 - val_acc: 0.9500\n",
            "Epoch 101/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 0.0222 - acc: 0.9889 - val_loss: 0.3439 - val_acc: 0.9600\n",
            "Epoch 102/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0218 - acc: 0.9913 - val_loss: 0.2727 - val_acc: 0.9700\n",
            "Epoch 103/1000\n",
            "809/809 [==============================] - 0s 142us/step - loss: 0.0131 - acc: 0.9951 - val_loss: 0.3536 - val_acc: 0.9700\n",
            "Epoch 104/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0208 - acc: 0.9913 - val_loss: 0.3174 - val_acc: 0.9700\n",
            "Epoch 105/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 0.0221 - acc: 0.9938 - val_loss: 0.3216 - val_acc: 0.9600\n",
            "Epoch 106/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0212 - acc: 0.9963 - val_loss: 0.3105 - val_acc: 0.9700\n",
            "Epoch 107/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 0.0211 - acc: 0.9938 - val_loss: 0.3329 - val_acc: 0.9600\n",
            "Epoch 108/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0166 - acc: 0.9951 - val_loss: 0.3608 - val_acc: 0.9600\n",
            "Epoch 109/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0130 - acc: 0.9975 - val_loss: 0.4012 - val_acc: 0.9600\n",
            "Epoch 110/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 0.0251 - acc: 0.9901 - val_loss: 0.3372 - val_acc: 0.9700\n",
            "Epoch 111/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.0150 - acc: 0.9963 - val_loss: 0.3707 - val_acc: 0.9700\n",
            "Epoch 112/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0176 - acc: 0.9926 - val_loss: 0.3006 - val_acc: 0.9600\n",
            "Epoch 113/1000\n",
            "809/809 [==============================] - 0s 136us/step - loss: 0.0125 - acc: 0.9963 - val_loss: 0.3794 - val_acc: 0.9500\n",
            "Epoch 114/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.0159 - acc: 0.9963 - val_loss: 0.3775 - val_acc: 0.9700\n",
            "Epoch 115/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 0.0101 - acc: 0.9963 - val_loss: 0.3867 - val_acc: 0.9700\n",
            "Epoch 116/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0095 - acc: 0.9963 - val_loss: 0.3277 - val_acc: 0.9600\n",
            "Epoch 117/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0130 - acc: 0.9951 - val_loss: 0.4118 - val_acc: 0.9700\n",
            "Epoch 118/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 0.0103 - acc: 0.9975 - val_loss: 0.3824 - val_acc: 0.9600\n",
            "Epoch 119/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 0.0186 - acc: 0.9938 - val_loss: 0.3715 - val_acc: 0.9700\n",
            "Epoch 120/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 0.0144 - acc: 0.9926 - val_loss: 0.3795 - val_acc: 0.9500\n",
            "Epoch 121/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0178 - acc: 0.9938 - val_loss: 0.3588 - val_acc: 0.9700\n",
            "Epoch 122/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0175 - acc: 0.9938 - val_loss: 0.2918 - val_acc: 0.9600\n",
            "Epoch 123/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0142 - acc: 0.9963 - val_loss: 0.4064 - val_acc: 0.9600\n",
            "Epoch 124/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.3786 - val_acc: 0.9600\n",
            "Epoch 125/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0205 - acc: 0.9901 - val_loss: 0.3905 - val_acc: 0.9600\n",
            "Epoch 126/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.4302 - val_acc: 0.9700\n",
            "Epoch 127/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0164 - acc: 0.9951 - val_loss: 0.3920 - val_acc: 0.9700\n",
            "Epoch 128/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0178 - acc: 0.9938 - val_loss: 0.3808 - val_acc: 0.9700\n",
            "Epoch 129/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.3108 - val_acc: 0.9700\n",
            "Epoch 130/1000\n",
            "809/809 [==============================] - 0s 151us/step - loss: 0.0188 - acc: 0.9938 - val_loss: 0.3517 - val_acc: 0.9700\n",
            "Epoch 131/1000\n",
            "809/809 [==============================] - 0s 148us/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.4327 - val_acc: 0.9700\n",
            "Epoch 132/1000\n",
            "809/809 [==============================] - 0s 136us/step - loss: 0.0104 - acc: 0.9963 - val_loss: 0.3716 - val_acc: 0.9700\n",
            "Epoch 133/1000\n",
            "809/809 [==============================] - 0s 140us/step - loss: 0.0097 - acc: 0.9975 - val_loss: 0.3445 - val_acc: 0.9700\n",
            "Epoch 134/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 0.0096 - acc: 0.9963 - val_loss: 0.3998 - val_acc: 0.9600\n",
            "Epoch 135/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.0141 - acc: 0.9951 - val_loss: 0.3919 - val_acc: 0.9600\n",
            "Epoch 136/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 0.0143 - acc: 0.9963 - val_loss: 0.3640 - val_acc: 0.9600\n",
            "Epoch 137/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 0.0148 - acc: 0.9951 - val_loss: 0.4119 - val_acc: 0.9600\n",
            "Epoch 138/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 0.0096 - acc: 0.9938 - val_loss: 0.3502 - val_acc: 0.9600\n",
            "Epoch 139/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 0.0145 - acc: 0.9938 - val_loss: 0.4089 - val_acc: 0.9600\n",
            "Epoch 140/1000\n",
            "809/809 [==============================] - 0s 140us/step - loss: 0.0097 - acc: 0.9963 - val_loss: 0.4480 - val_acc: 0.9600\n",
            "Epoch 141/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 0.0095 - acc: 0.9963 - val_loss: 0.3913 - val_acc: 0.9600\n",
            "Epoch 142/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0123 - acc: 0.9938 - val_loss: 0.3400 - val_acc: 0.9700\n",
            "Epoch 143/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.0192 - acc: 0.9926 - val_loss: 0.3787 - val_acc: 0.9600\n",
            "Epoch 144/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.3243 - val_acc: 0.9700\n",
            "Epoch 145/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0098 - acc: 0.9963 - val_loss: 0.4311 - val_acc: 0.9600\n",
            "Epoch 146/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.3566 - val_acc: 0.9600\n",
            "Epoch 147/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.3483 - val_acc: 0.9700\n",
            "Epoch 148/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.3579 - val_acc: 0.9600\n",
            "Epoch 149/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 0.0129 - acc: 0.9938 - val_loss: 0.4799 - val_acc: 0.9500\n",
            "Epoch 150/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0314 - acc: 0.9938 - val_loss: 0.3405 - val_acc: 0.9500\n",
            "Epoch 151/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0227 - acc: 0.9913 - val_loss: 0.2991 - val_acc: 0.9700\n",
            "Epoch 152/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 0.0202 - acc: 0.9913 - val_loss: 0.3608 - val_acc: 0.9700\n",
            "Epoch 153/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0149 - acc: 0.9951 - val_loss: 0.3075 - val_acc: 0.9600\n",
            "Epoch 154/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0314 - acc: 0.9889 - val_loss: 0.2850 - val_acc: 0.9600\n",
            "Epoch 155/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0523 - acc: 0.9852 - val_loss: 0.3538 - val_acc: 0.9600\n",
            "Epoch 156/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.0320 - acc: 0.9876 - val_loss: 0.3098 - val_acc: 0.9400\n",
            "Epoch 157/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 0.0282 - acc: 0.9889 - val_loss: 0.4541 - val_acc: 0.9400\n",
            "Epoch 158/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0115 - acc: 0.9963 - val_loss: 0.3678 - val_acc: 0.9600\n",
            "Epoch 159/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.0280 - acc: 0.9963 - val_loss: 0.3190 - val_acc: 0.9700\n",
            "Epoch 160/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0107 - acc: 0.9963 - val_loss: 0.3640 - val_acc: 0.9700\n",
            "Epoch 161/1000\n",
            "809/809 [==============================] - 0s 149us/step - loss: 0.0114 - acc: 0.9975 - val_loss: 0.3540 - val_acc: 0.9700\n",
            "Epoch 162/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0085 - acc: 0.9988 - val_loss: 0.3585 - val_acc: 0.9700\n",
            "Epoch 163/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0062 - acc: 0.9975 - val_loss: 0.3740 - val_acc: 0.9600\n",
            "Epoch 164/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.4091 - val_acc: 0.9600\n",
            "Epoch 165/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.3712 - val_acc: 0.9700\n",
            "Epoch 166/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 0.0071 - acc: 0.9975 - val_loss: 0.3926 - val_acc: 0.9700\n",
            "Epoch 167/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0143 - acc: 0.9926 - val_loss: 0.4213 - val_acc: 0.9700\n",
            "Epoch 168/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.3997 - val_acc: 0.9700\n",
            "Epoch 169/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.3956 - val_acc: 0.9700\n",
            "Epoch 170/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.4026 - val_acc: 0.9600\n",
            "Epoch 171/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4212 - val_acc: 0.9600\n",
            "Epoch 172/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.4036 - val_acc: 0.9600\n",
            "Epoch 173/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.0059 - acc: 0.9975 - val_loss: 0.4104 - val_acc: 0.9700\n",
            "Epoch 174/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 0.0079 - acc: 0.9988 - val_loss: 0.4336 - val_acc: 0.9600\n",
            "Epoch 175/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0053 - acc: 0.9988 - val_loss: 0.4383 - val_acc: 0.9600\n",
            "Epoch 176/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.4378 - val_acc: 0.9600\n",
            "Epoch 177/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.4601 - val_acc: 0.9600\n",
            "Epoch 178/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 0.0065 - acc: 0.9975 - val_loss: 0.4273 - val_acc: 0.9600\n",
            "Epoch 179/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 0.0027 - acc: 0.9988 - val_loss: 0.4532 - val_acc: 0.9600\n",
            "Epoch 180/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0057 - acc: 0.9988 - val_loss: 0.4519 - val_acc: 0.9600\n",
            "Epoch 181/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0062 - acc: 0.9963 - val_loss: 0.4395 - val_acc: 0.9700\n",
            "Epoch 182/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0061 - acc: 0.9975 - val_loss: 0.4467 - val_acc: 0.9700\n",
            "Epoch 183/1000\n",
            "809/809 [==============================] - 0s 144us/step - loss: 0.0034 - acc: 0.9975 - val_loss: 0.4349 - val_acc: 0.9600\n",
            "Epoch 184/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.4156 - val_acc: 0.9600\n",
            "Epoch 185/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0030 - acc: 0.9988 - val_loss: 0.4199 - val_acc: 0.9600\n",
            "Epoch 186/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0043 - acc: 0.9975 - val_loss: 0.4886 - val_acc: 0.9600\n",
            "Epoch 187/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.0038 - acc: 0.9975 - val_loss: 0.4289 - val_acc: 0.9600\n",
            "Epoch 188/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 0.0094 - acc: 0.9951 - val_loss: 0.4052 - val_acc: 0.9600\n",
            "Epoch 189/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.4445 - val_acc: 0.9600\n",
            "Epoch 190/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.4517 - val_acc: 0.9600\n",
            "Epoch 191/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.4415 - val_acc: 0.9600\n",
            "Epoch 192/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4645 - val_acc: 0.9600\n",
            "Epoch 193/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.4600 - val_acc: 0.9600\n",
            "Epoch 194/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.4045 - val_acc: 0.9600\n",
            "Epoch 195/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.4572 - val_acc: 0.9600\n",
            "Epoch 196/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.4234 - val_acc: 0.9700\n",
            "Epoch 197/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0054 - acc: 0.9975 - val_loss: 0.4580 - val_acc: 0.9700\n",
            "Epoch 198/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4623 - val_acc: 0.9600\n",
            "Epoch 199/1000\n",
            "809/809 [==============================] - 0s 146us/step - loss: 0.0044 - acc: 0.9975 - val_loss: 0.4004 - val_acc: 0.9700\n",
            "Epoch 200/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.4132 - val_acc: 0.9600\n",
            "Epoch 201/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4682 - val_acc: 0.9600\n",
            "Epoch 202/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 8.4284e-04 - acc: 1.0000 - val_loss: 0.4658 - val_acc: 0.9600\n",
            "Epoch 203/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.4651 - val_acc: 0.9600\n",
            "Epoch 204/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0104 - acc: 0.9975 - val_loss: 0.4225 - val_acc: 0.9700\n",
            "Epoch 205/1000\n",
            "809/809 [==============================] - 0s 178us/step - loss: 0.0157 - acc: 0.9938 - val_loss: 0.4106 - val_acc: 0.9700\n",
            "Epoch 206/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 0.0209 - acc: 0.9963 - val_loss: 0.3812 - val_acc: 0.9600\n",
            "Epoch 207/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 0.0078 - acc: 0.9988 - val_loss: 0.3964 - val_acc: 0.9600\n",
            "Epoch 208/1000\n",
            "809/809 [==============================] - 0s 136us/step - loss: 0.0157 - acc: 0.9938 - val_loss: 0.4505 - val_acc: 0.9600\n",
            "Epoch 209/1000\n",
            "809/809 [==============================] - 0s 152us/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.4753 - val_acc: 0.9600\n",
            "Epoch 210/1000\n",
            "809/809 [==============================] - 0s 141us/step - loss: 0.0079 - acc: 0.9963 - val_loss: 0.4098 - val_acc: 0.9600\n",
            "Epoch 211/1000\n",
            "809/809 [==============================] - 0s 144us/step - loss: 0.0063 - acc: 0.9988 - val_loss: 0.4314 - val_acc: 0.9600\n",
            "Epoch 212/1000\n",
            "809/809 [==============================] - 0s 141us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.4475 - val_acc: 0.9600\n",
            "Epoch 213/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.4420 - val_acc: 0.9600\n",
            "Epoch 214/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 0.0060 - acc: 0.9988 - val_loss: 0.4630 - val_acc: 0.9600\n",
            "Epoch 215/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.9600\n",
            "Epoch 216/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0034 - acc: 0.9975 - val_loss: 0.4380 - val_acc: 0.9600\n",
            "Epoch 217/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.4412 - val_acc: 0.9600\n",
            "Epoch 218/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0128 - acc: 0.9975 - val_loss: 0.4152 - val_acc: 0.9600\n",
            "Epoch 219/1000\n",
            "809/809 [==============================] - 0s 106us/step - loss: 0.0072 - acc: 0.9975 - val_loss: 0.4058 - val_acc: 0.9600\n",
            "Epoch 220/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.0019 - acc: 0.9988 - val_loss: 0.4195 - val_acc: 0.9600\n",
            "Epoch 221/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.4295 - val_acc: 0.9600\n",
            "Epoch 222/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.4295 - val_acc: 0.9600\n",
            "Epoch 223/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4271 - val_acc: 0.9600\n",
            "Epoch 224/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 4.7922e-04 - acc: 1.0000 - val_loss: 0.4348 - val_acc: 0.9600\n",
            "Epoch 225/1000\n",
            "809/809 [==============================] - 0s 144us/step - loss: 0.0023 - acc: 0.9988 - val_loss: 0.4564 - val_acc: 0.9600\n",
            "Epoch 226/1000\n",
            "809/809 [==============================] - 0s 153us/step - loss: 9.4914e-04 - acc: 1.0000 - val_loss: 0.4552 - val_acc: 0.9600\n",
            "Epoch 227/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 6.5115e-04 - acc: 1.0000 - val_loss: 0.4539 - val_acc: 0.9600\n",
            "Epoch 228/1000\n",
            "809/809 [==============================] - 0s 152us/step - loss: 6.9075e-04 - acc: 1.0000 - val_loss: 0.4567 - val_acc: 0.9600\n",
            "Epoch 229/1000\n",
            "809/809 [==============================] - 0s 140us/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.4769 - val_acc: 0.9600\n",
            "Epoch 230/1000\n",
            "809/809 [==============================] - 0s 142us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4768 - val_acc: 0.9600\n",
            "Epoch 231/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.4671 - val_acc: 0.9600\n",
            "Epoch 232/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4641 - val_acc: 0.9600\n",
            "Epoch 233/1000\n",
            "809/809 [==============================] - 0s 106us/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.4412 - val_acc: 0.9600\n",
            "Epoch 234/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0054 - acc: 0.9988 - val_loss: 0.5048 - val_acc: 0.9600\n",
            "Epoch 235/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5070 - val_acc: 0.9600\n",
            "Epoch 236/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 0.0037 - acc: 0.9975 - val_loss: 0.4916 - val_acc: 0.9600\n",
            "Epoch 237/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.4339 - val_acc: 0.9600\n",
            "Epoch 238/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.4240 - val_acc: 0.9600\n",
            "Epoch 239/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.4435 - val_acc: 0.9600\n",
            "Epoch 240/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.4128 - val_acc: 0.9700\n",
            "Epoch 241/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.0095 - acc: 0.9963 - val_loss: 0.3777 - val_acc: 0.9700\n",
            "Epoch 242/1000\n",
            "809/809 [==============================] - 0s 142us/step - loss: 0.0094 - acc: 0.9963 - val_loss: 0.5433 - val_acc: 0.9500\n",
            "Epoch 243/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0247 - acc: 0.9963 - val_loss: 0.4091 - val_acc: 0.9600\n",
            "Epoch 244/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0096 - acc: 0.9963 - val_loss: 0.4594 - val_acc: 0.9600\n",
            "Epoch 245/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5152 - val_acc: 0.9600\n",
            "Epoch 246/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.9600\n",
            "Epoch 247/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 0.0084 - acc: 0.9951 - val_loss: 0.4703 - val_acc: 0.9600\n",
            "Epoch 248/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 0.0123 - acc: 0.9951 - val_loss: 0.4244 - val_acc: 0.9600\n",
            "Epoch 249/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0113 - acc: 0.9988 - val_loss: 0.3929 - val_acc: 0.9600\n",
            "Epoch 250/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 0.0081 - acc: 0.9963 - val_loss: 0.4185 - val_acc: 0.9600\n",
            "Epoch 251/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4480 - val_acc: 0.9600\n",
            "Epoch 252/1000\n",
            "809/809 [==============================] - 0s 141us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.4511 - val_acc: 0.9600\n",
            "Epoch 253/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4198 - val_acc: 0.9600\n",
            "Epoch 254/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4396 - val_acc: 0.9600\n",
            "Epoch 255/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 3.8453e-04 - acc: 1.0000 - val_loss: 0.4706 - val_acc: 0.9600\n",
            "Epoch 256/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 0.0020 - acc: 0.9988 - val_loss: 0.4927 - val_acc: 0.9600\n",
            "Epoch 257/1000\n",
            "809/809 [==============================] - 0s 146us/step - loss: 0.0055 - acc: 0.9975 - val_loss: 0.4906 - val_acc: 0.9600\n",
            "Epoch 258/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0054 - acc: 0.9963 - val_loss: 0.4816 - val_acc: 0.9600\n",
            "Epoch 259/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5292 - val_acc: 0.9600\n",
            "Epoch 260/1000\n",
            "809/809 [==============================] - 0s 141us/step - loss: 0.0056 - acc: 0.9975 - val_loss: 0.5049 - val_acc: 0.9600\n",
            "Epoch 261/1000\n",
            "809/809 [==============================] - 0s 151us/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.4733 - val_acc: 0.9600\n",
            "Epoch 262/1000\n",
            "809/809 [==============================] - 0s 141us/step - loss: 0.0103 - acc: 0.9988 - val_loss: 0.3995 - val_acc: 0.9600\n",
            "Epoch 263/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.3813 - val_acc: 0.9600\n",
            "Epoch 264/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4175 - val_acc: 0.9600\n",
            "Epoch 265/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 9.4809e-04 - acc: 1.0000 - val_loss: 0.4430 - val_acc: 0.9600\n",
            "Epoch 266/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 8.1038e-04 - acc: 1.0000 - val_loss: 0.4663 - val_acc: 0.9600\n",
            "Epoch 267/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 7.2547e-04 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.9600\n",
            "Epoch 268/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 1.8451e-04 - acc: 1.0000 - val_loss: 0.5000 - val_acc: 0.9600\n",
            "Epoch 269/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 1.9835e-04 - acc: 1.0000 - val_loss: 0.5072 - val_acc: 0.9600\n",
            "Epoch 270/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 2.3583e-04 - acc: 1.0000 - val_loss: 0.5100 - val_acc: 0.9600\n",
            "Epoch 271/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 3.6903e-04 - acc: 1.0000 - val_loss: 0.4964 - val_acc: 0.9600\n",
            "Epoch 272/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 6.2613e-04 - acc: 1.0000 - val_loss: 0.5120 - val_acc: 0.9600\n",
            "Epoch 273/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 7.5062e-04 - acc: 1.0000 - val_loss: 0.5150 - val_acc: 0.9600\n",
            "Epoch 274/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.0010 - acc: 0.9988 - val_loss: 0.4721 - val_acc: 0.9600\n",
            "Epoch 275/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 5.3905e-04 - acc: 1.0000 - val_loss: 0.4503 - val_acc: 0.9600\n",
            "Epoch 276/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 5.3508e-04 - acc: 1.0000 - val_loss: 0.4968 - val_acc: 0.9600\n",
            "Epoch 277/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 3.1430e-04 - acc: 1.0000 - val_loss: 0.5055 - val_acc: 0.9600\n",
            "Epoch 278/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 9.6772e-04 - acc: 1.0000 - val_loss: 0.5308 - val_acc: 0.9600\n",
            "Epoch 279/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 0.0059 - acc: 0.9975 - val_loss: 0.5295 - val_acc: 0.9500\n",
            "Epoch 280/1000\n",
            "809/809 [==============================] - 0s 140us/step - loss: 0.0318 - acc: 0.9938 - val_loss: 0.4898 - val_acc: 0.9600\n",
            "Epoch 281/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0098 - acc: 0.9963 - val_loss: 0.3690 - val_acc: 0.9700\n",
            "Epoch 282/1000\n",
            "809/809 [==============================] - 0s 138us/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.4002 - val_acc: 0.9700\n",
            "Epoch 283/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0102 - acc: 0.9951 - val_loss: 0.4162 - val_acc: 0.9600\n",
            "Epoch 284/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 0.0056 - acc: 0.9975 - val_loss: 0.4428 - val_acc: 0.9600\n",
            "Epoch 285/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 0.0074 - acc: 0.9963 - val_loss: 0.5441 - val_acc: 0.9400\n",
            "Epoch 286/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0348 - acc: 0.9889 - val_loss: 0.3975 - val_acc: 0.9400\n",
            "Epoch 287/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0456 - acc: 0.9839 - val_loss: 0.4314 - val_acc: 0.9500\n",
            "Epoch 288/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 0.0433 - acc: 0.9876 - val_loss: 0.4196 - val_acc: 0.9500\n",
            "Epoch 289/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0232 - acc: 0.9938 - val_loss: 0.3290 - val_acc: 0.9600\n",
            "Epoch 290/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0207 - acc: 0.9951 - val_loss: 0.3149 - val_acc: 0.9500\n",
            "Epoch 291/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.3703 - val_acc: 0.9600\n",
            "Epoch 292/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0064 - acc: 0.9963 - val_loss: 0.3122 - val_acc: 0.9600\n",
            "Epoch 293/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.0046 - acc: 0.9975 - val_loss: 0.3988 - val_acc: 0.9600\n",
            "Epoch 294/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.3358 - val_acc: 0.9600\n",
            "Epoch 295/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 0.0075 - acc: 0.9951 - val_loss: 0.4099 - val_acc: 0.9700\n",
            "Epoch 296/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 0.0064 - acc: 0.9988 - val_loss: 0.3776 - val_acc: 0.9600\n",
            "Epoch 297/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 0.0085 - acc: 0.9988 - val_loss: 0.4277 - val_acc: 0.9600\n",
            "Epoch 298/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0053 - acc: 0.9975 - val_loss: 0.4093 - val_acc: 0.9500\n",
            "Epoch 299/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0144 - acc: 0.9963 - val_loss: 0.2932 - val_acc: 0.9700\n",
            "Epoch 300/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.0079 - acc: 0.9975 - val_loss: 0.3778 - val_acc: 0.9600\n",
            "Epoch 301/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3875 - val_acc: 0.9600\n",
            "Epoch 302/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4044 - val_acc: 0.9600\n",
            "Epoch 303/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 6.6931e-04 - acc: 1.0000 - val_loss: 0.4029 - val_acc: 0.9600\n",
            "Epoch 304/1000\n",
            "809/809 [==============================] - 0s 140us/step - loss: 5.0482e-04 - acc: 1.0000 - val_loss: 0.3991 - val_acc: 0.9600\n",
            "Epoch 305/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 8.8899e-04 - acc: 1.0000 - val_loss: 0.4202 - val_acc: 0.9600\n",
            "Epoch 306/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4311 - val_acc: 0.9700\n",
            "Epoch 307/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.0056 - acc: 0.9975 - val_loss: 0.3641 - val_acc: 0.9600\n",
            "Epoch 308/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3576 - val_acc: 0.9600\n",
            "Epoch 309/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.3744 - val_acc: 0.9600\n",
            "Epoch 310/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0062 - acc: 0.9975 - val_loss: 0.3878 - val_acc: 0.9600\n",
            "Epoch 311/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 0.0110 - acc: 0.9951 - val_loss: 0.4463 - val_acc: 0.9700\n",
            "Epoch 312/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 0.0027 - acc: 0.9988 - val_loss: 0.4223 - val_acc: 0.9600\n",
            "Epoch 313/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4471 - val_acc: 0.9600\n",
            "Epoch 314/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 0.0113 - acc: 0.9951 - val_loss: 0.4762 - val_acc: 0.9600\n",
            "Epoch 315/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 0.0072 - acc: 0.9975 - val_loss: 0.4218 - val_acc: 0.9500\n",
            "Epoch 316/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.3492 - val_acc: 0.9600\n",
            "Epoch 317/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 9.6578e-04 - acc: 1.0000 - val_loss: 0.4804 - val_acc: 0.9600\n",
            "Epoch 318/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0019 - acc: 0.9988 - val_loss: 0.5106 - val_acc: 0.9600\n",
            "Epoch 319/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 0.0050 - acc: 0.9975 - val_loss: 0.4826 - val_acc: 0.9600\n",
            "Epoch 320/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.9700\n",
            "Epoch 321/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0187 - acc: 0.9926 - val_loss: 0.4025 - val_acc: 0.9600\n",
            "Epoch 322/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.4408 - val_acc: 0.9600\n",
            "Epoch 323/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0093 - acc: 0.9963 - val_loss: 0.3555 - val_acc: 0.9600\n",
            "Epoch 324/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.3941 - val_acc: 0.9600\n",
            "Epoch 325/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.4277 - val_acc: 0.9600\n",
            "Epoch 326/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0022 - acc: 0.9988 - val_loss: 0.4146 - val_acc: 0.9600\n",
            "Epoch 327/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.4150 - val_acc: 0.9600\n",
            "Epoch 328/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 6.3297e-04 - acc: 1.0000 - val_loss: 0.4109 - val_acc: 0.9600\n",
            "Epoch 329/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 6.0101e-04 - acc: 1.0000 - val_loss: 0.4265 - val_acc: 0.9600\n",
            "Epoch 330/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0022 - acc: 0.9988 - val_loss: 0.4233 - val_acc: 0.9600\n",
            "Epoch 331/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.4386 - val_acc: 0.9600\n",
            "Epoch 332/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 0.0105 - acc: 0.9975 - val_loss: 0.4175 - val_acc: 0.9600\n",
            "Epoch 333/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 0.0081 - acc: 0.9988 - val_loss: 0.3763 - val_acc: 0.9600\n",
            "Epoch 334/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 0.0087 - acc: 0.9963 - val_loss: 0.4103 - val_acc: 0.9600\n",
            "Epoch 335/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.3907 - val_acc: 0.9500\n",
            "Epoch 336/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.0057 - acc: 0.9975 - val_loss: 0.4503 - val_acc: 0.9500\n",
            "Epoch 337/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 0.0095 - acc: 0.9975 - val_loss: 0.3445 - val_acc: 0.9600\n",
            "Epoch 338/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 0.0163 - acc: 0.9951 - val_loss: 0.3113 - val_acc: 0.9700\n",
            "Epoch 339/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0153 - acc: 0.9963 - val_loss: 0.4428 - val_acc: 0.9600\n",
            "Epoch 340/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.3008 - val_acc: 0.9600\n",
            "Epoch 341/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0153 - acc: 0.9951 - val_loss: 0.2604 - val_acc: 0.9700\n",
            "Epoch 342/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0066 - acc: 0.9975 - val_loss: 0.2786 - val_acc: 0.9700\n",
            "Epoch 343/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0031 - acc: 0.9988 - val_loss: 0.3518 - val_acc: 0.9700\n",
            "Epoch 344/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.3665 - val_acc: 0.9600\n",
            "Epoch 345/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 6.1484e-04 - acc: 1.0000 - val_loss: 0.3841 - val_acc: 0.9600\n",
            "Epoch 346/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4221 - val_acc: 0.9600\n",
            "Epoch 347/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 0.0018 - acc: 0.9988 - val_loss: 0.4313 - val_acc: 0.9600\n",
            "Epoch 348/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4395 - val_acc: 0.9600\n",
            "Epoch 349/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.4435 - val_acc: 0.9600\n",
            "Epoch 350/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 8.6204e-04 - acc: 1.0000 - val_loss: 0.4462 - val_acc: 0.9600\n",
            "Epoch 351/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 8.3238e-04 - acc: 1.0000 - val_loss: 0.4345 - val_acc: 0.9600\n",
            "Epoch 352/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 5.4803e-04 - acc: 1.0000 - val_loss: 0.4339 - val_acc: 0.9600\n",
            "Epoch 353/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 6.0815e-04 - acc: 1.0000 - val_loss: 0.4494 - val_acc: 0.9600\n",
            "Epoch 354/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 1.1545e-04 - acc: 1.0000 - val_loss: 0.4625 - val_acc: 0.9600\n",
            "Epoch 355/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 2.2417e-04 - acc: 1.0000 - val_loss: 0.4684 - val_acc: 0.9600\n",
            "Epoch 356/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 1.8149e-04 - acc: 1.0000 - val_loss: 0.4669 - val_acc: 0.9600\n",
            "Epoch 357/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 1.5244e-04 - acc: 1.0000 - val_loss: 0.4673 - val_acc: 0.9600\n",
            "Epoch 358/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 3.1671e-04 - acc: 1.0000 - val_loss: 0.4664 - val_acc: 0.9600\n",
            "Epoch 359/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 0.0021 - acc: 0.9988 - val_loss: 0.4876 - val_acc: 0.9600\n",
            "Epoch 360/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0063 - acc: 0.9988 - val_loss: 0.4762 - val_acc: 0.9600\n",
            "Epoch 361/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 0.0028 - acc: 0.9988 - val_loss: 0.4084 - val_acc: 0.9600\n",
            "Epoch 362/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 0.0239 - acc: 0.9926 - val_loss: 0.2285 - val_acc: 0.9600\n",
            "Epoch 363/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.3733 - val_acc: 0.9600\n",
            "Epoch 364/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.4363 - val_acc: 0.9700\n",
            "Epoch 365/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0106 - acc: 0.9963 - val_loss: 0.4419 - val_acc: 0.9600\n",
            "Epoch 366/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.4344 - val_acc: 0.9600\n",
            "Epoch 367/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.4402 - val_acc: 0.9600\n",
            "Epoch 368/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4644 - val_acc: 0.9600\n",
            "Epoch 369/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 8.2197e-04 - acc: 1.0000 - val_loss: 0.4613 - val_acc: 0.9600\n",
            "Epoch 370/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 3.4863e-04 - acc: 1.0000 - val_loss: 0.4594 - val_acc: 0.9600\n",
            "Epoch 371/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 6.6602e-04 - acc: 1.0000 - val_loss: 0.4627 - val_acc: 0.9600\n",
            "Epoch 372/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 0.0033 - acc: 0.9988 - val_loss: 0.4572 - val_acc: 0.9500\n",
            "Epoch 373/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 0.0100 - acc: 0.9988 - val_loss: 0.3941 - val_acc: 0.9600\n",
            "Epoch 374/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3842 - val_acc: 0.9600\n",
            "Epoch 375/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.3813 - val_acc: 0.9600\n",
            "Epoch 376/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4390 - val_acc: 0.9600\n",
            "Epoch 377/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 0.0025 - acc: 0.9988 - val_loss: 0.4326 - val_acc: 0.9600\n",
            "Epoch 378/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0028 - acc: 0.9988 - val_loss: 0.4134 - val_acc: 0.9600\n",
            "Epoch 379/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 4.2524e-04 - acc: 1.0000 - val_loss: 0.4111 - val_acc: 0.9600\n",
            "Epoch 380/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 3.6450e-04 - acc: 1.0000 - val_loss: 0.4223 - val_acc: 0.9600\n",
            "Epoch 381/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4715 - val_acc: 0.9600\n",
            "Epoch 382/1000\n",
            "809/809 [==============================] - 0s 136us/step - loss: 1.3988e-04 - acc: 1.0000 - val_loss: 0.4928 - val_acc: 0.9600\n",
            "Epoch 383/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 2.3361e-04 - acc: 1.0000 - val_loss: 0.4963 - val_acc: 0.9600\n",
            "Epoch 384/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 5.1105e-04 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.9600\n",
            "Epoch 385/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 2.2729e-04 - acc: 1.0000 - val_loss: 0.4755 - val_acc: 0.9600\n",
            "Epoch 386/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 2.3486e-04 - acc: 1.0000 - val_loss: 0.4696 - val_acc: 0.9600\n",
            "Epoch 387/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 4.1836e-04 - acc: 1.0000 - val_loss: 0.4725 - val_acc: 0.9600\n",
            "Epoch 388/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 3.1544e-04 - acc: 1.0000 - val_loss: 0.4910 - val_acc: 0.9600\n",
            "Epoch 389/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 4.8464e-04 - acc: 1.0000 - val_loss: 0.5075 - val_acc: 0.9600\n",
            "Epoch 390/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 7.1230e-05 - acc: 1.0000 - val_loss: 0.5051 - val_acc: 0.9600\n",
            "Epoch 391/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 1.0548e-04 - acc: 1.0000 - val_loss: 0.5032 - val_acc: 0.9600\n",
            "Epoch 392/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 1.5023e-04 - acc: 1.0000 - val_loss: 0.5042 - val_acc: 0.9600\n",
            "Epoch 393/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 3.4893e-04 - acc: 1.0000 - val_loss: 0.5082 - val_acc: 0.9600\n",
            "Epoch 394/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 4.3767e-05 - acc: 1.0000 - val_loss: 0.5088 - val_acc: 0.9600\n",
            "Epoch 395/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 1.9471e-04 - acc: 1.0000 - val_loss: 0.5073 - val_acc: 0.9600\n",
            "Epoch 396/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 3.6287e-04 - acc: 1.0000 - val_loss: 0.5115 - val_acc: 0.9600\n",
            "Epoch 397/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 3.6813e-04 - acc: 1.0000 - val_loss: 0.5117 - val_acc: 0.9600\n",
            "Epoch 398/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 1.3658e-04 - acc: 1.0000 - val_loss: 0.5075 - val_acc: 0.9600\n",
            "Epoch 399/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 2.0609e-04 - acc: 1.0000 - val_loss: 0.5062 - val_acc: 0.9600\n",
            "Epoch 400/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 1.6085e-04 - acc: 1.0000 - val_loss: 0.5095 - val_acc: 0.9600\n",
            "Epoch 401/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 1.7370e-04 - acc: 1.0000 - val_loss: 0.5119 - val_acc: 0.9600\n",
            "Epoch 402/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 3.7490e-04 - acc: 1.0000 - val_loss: 0.5147 - val_acc: 0.9600\n",
            "Epoch 403/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 1.6448e-04 - acc: 1.0000 - val_loss: 0.5168 - val_acc: 0.9600\n",
            "Epoch 404/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 6.1342e-05 - acc: 1.0000 - val_loss: 0.5173 - val_acc: 0.9600\n",
            "Epoch 405/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 5.1049e-05 - acc: 1.0000 - val_loss: 0.5175 - val_acc: 0.9600\n",
            "Epoch 406/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 8.4912e-05 - acc: 1.0000 - val_loss: 0.5177 - val_acc: 0.9600\n",
            "Epoch 407/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0020 - acc: 0.9988 - val_loss: 0.4984 - val_acc: 0.9400\n",
            "Epoch 408/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.5285 - val_acc: 0.9600\n",
            "Epoch 409/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 0.0093 - acc: 0.9975 - val_loss: 0.5635 - val_acc: 0.9500\n",
            "Epoch 410/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 0.0312 - acc: 0.9938 - val_loss: 0.4082 - val_acc: 0.9600\n",
            "Epoch 411/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0289 - acc: 0.9901 - val_loss: 0.3373 - val_acc: 0.9600\n",
            "Epoch 412/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.0192 - acc: 0.9926 - val_loss: 0.3259 - val_acc: 0.9700\n",
            "Epoch 413/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0081 - acc: 0.9963 - val_loss: 0.2766 - val_acc: 0.9600\n",
            "Epoch 414/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 0.0082 - acc: 0.9963 - val_loss: 0.3374 - val_acc: 0.9600\n",
            "Epoch 415/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.4376 - val_acc: 0.9600\n",
            "Epoch 416/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 0.0079 - acc: 0.9951 - val_loss: 0.3233 - val_acc: 0.9600\n",
            "Epoch 417/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4452 - val_acc: 0.9600\n",
            "Epoch 418/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.4555 - val_acc: 0.9600\n",
            "Epoch 419/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 0.0018 - acc: 0.9988 - val_loss: 0.4288 - val_acc: 0.9600\n",
            "Epoch 420/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0049 - acc: 0.9975 - val_loss: 0.3497 - val_acc: 0.9600\n",
            "Epoch 421/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.4058 - val_acc: 0.9600\n",
            "Epoch 422/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 8.4931e-04 - acc: 1.0000 - val_loss: 0.4178 - val_acc: 0.9600\n",
            "Epoch 423/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 9.4983e-04 - acc: 1.0000 - val_loss: 0.4204 - val_acc: 0.9600\n",
            "Epoch 424/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4293 - val_acc: 0.9600\n",
            "Epoch 425/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 5.4542e-04 - acc: 1.0000 - val_loss: 0.4339 - val_acc: 0.9600\n",
            "Epoch 426/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 4.9770e-04 - acc: 1.0000 - val_loss: 0.4440 - val_acc: 0.9600\n",
            "Epoch 427/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 6.5742e-04 - acc: 1.0000 - val_loss: 0.4608 - val_acc: 0.9600\n",
            "Epoch 428/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0011 - acc: 0.9988 - val_loss: 0.4917 - val_acc: 0.9600\n",
            "Epoch 429/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 6.5162e-04 - acc: 1.0000 - val_loss: 0.4916 - val_acc: 0.9600\n",
            "Epoch 430/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 8.4356e-04 - acc: 1.0000 - val_loss: 0.4824 - val_acc: 0.9600\n",
            "Epoch 431/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 6.3525e-04 - acc: 1.0000 - val_loss: 0.4822 - val_acc: 0.9600\n",
            "Epoch 432/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 3.7778e-04 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.9600\n",
            "Epoch 433/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 2.1878e-04 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.9600\n",
            "Epoch 434/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 6.5508e-04 - acc: 1.0000 - val_loss: 0.4930 - val_acc: 0.9600\n",
            "Epoch 435/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 3.3315e-04 - acc: 1.0000 - val_loss: 0.4926 - val_acc: 0.9600\n",
            "Epoch 436/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 5.7699e-04 - acc: 1.0000 - val_loss: 0.4918 - val_acc: 0.9600\n",
            "Epoch 437/1000\n",
            "809/809 [==============================] - 0s 141us/step - loss: 2.7772e-04 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.9600\n",
            "Epoch 438/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 6.0182e-04 - acc: 1.0000 - val_loss: 0.4884 - val_acc: 0.9600\n",
            "Epoch 439/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 2.2886e-04 - acc: 1.0000 - val_loss: 0.4761 - val_acc: 0.9600\n",
            "Epoch 440/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 1.3752e-04 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.9600\n",
            "Epoch 441/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 1.1767e-04 - acc: 1.0000 - val_loss: 0.4867 - val_acc: 0.9600\n",
            "Epoch 442/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 2.2264e-04 - acc: 1.0000 - val_loss: 0.4954 - val_acc: 0.9600\n",
            "Epoch 443/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 4.3385e-04 - acc: 1.0000 - val_loss: 0.5020 - val_acc: 0.9600\n",
            "Epoch 444/1000\n",
            "809/809 [==============================] - 0s 96us/step - loss: 4.4451e-04 - acc: 1.0000 - val_loss: 0.5099 - val_acc: 0.9600\n",
            "Epoch 445/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 2.1945e-04 - acc: 1.0000 - val_loss: 0.5104 - val_acc: 0.9600\n",
            "Epoch 446/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 2.0858e-04 - acc: 1.0000 - val_loss: 0.5154 - val_acc: 0.9600\n",
            "Epoch 447/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 1.3075e-04 - acc: 1.0000 - val_loss: 0.5198 - val_acc: 0.9600\n",
            "Epoch 448/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 1.2620e-04 - acc: 1.0000 - val_loss: 0.5181 - val_acc: 0.9600\n",
            "Epoch 449/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 4.1636e-04 - acc: 1.0000 - val_loss: 0.5164 - val_acc: 0.9600\n",
            "Epoch 450/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 1.2500e-04 - acc: 1.0000 - val_loss: 0.5198 - val_acc: 0.9600\n",
            "Epoch 451/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 1.7782e-04 - acc: 1.0000 - val_loss: 0.5217 - val_acc: 0.9600\n",
            "Epoch 452/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 4.0537e-04 - acc: 1.0000 - val_loss: 0.5282 - val_acc: 0.9600\n",
            "Epoch 453/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 8.7953e-05 - acc: 1.0000 - val_loss: 0.5254 - val_acc: 0.9600\n",
            "Epoch 454/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 6.7094e-05 - acc: 1.0000 - val_loss: 0.5238 - val_acc: 0.9600\n",
            "Epoch 455/1000\n",
            "809/809 [==============================] - 0s 144us/step - loss: 6.8382e-04 - acc: 1.0000 - val_loss: 0.5077 - val_acc: 0.9600\n",
            "Epoch 456/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 2.7496e-04 - acc: 1.0000 - val_loss: 0.5106 - val_acc: 0.9600\n",
            "Epoch 457/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 3.7130e-05 - acc: 1.0000 - val_loss: 0.5108 - val_acc: 0.9500\n",
            "Epoch 458/1000\n",
            "809/809 [==============================] - 0s 146us/step - loss: 9.7686e-05 - acc: 1.0000 - val_loss: 0.5079 - val_acc: 0.9500\n",
            "Epoch 459/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 3.7983e-04 - acc: 1.0000 - val_loss: 0.5228 - val_acc: 0.9500\n",
            "Epoch 460/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4780 - val_acc: 0.9600\n",
            "Epoch 461/1000\n",
            "809/809 [==============================] - 0s 140us/step - loss: 7.0379e-04 - acc: 1.0000 - val_loss: 0.5061 - val_acc: 0.9600\n",
            "Epoch 462/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 1.5828e-04 - acc: 1.0000 - val_loss: 0.5173 - val_acc: 0.9600\n",
            "Epoch 463/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 2.7318e-04 - acc: 1.0000 - val_loss: 0.5185 - val_acc: 0.9600\n",
            "Epoch 464/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 8.0745e-04 - acc: 1.0000 - val_loss: 0.4957 - val_acc: 0.9600\n",
            "Epoch 465/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 2.1857e-04 - acc: 1.0000 - val_loss: 0.4752 - val_acc: 0.9600\n",
            "Epoch 466/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 4.8411e-04 - acc: 1.0000 - val_loss: 0.4793 - val_acc: 0.9600\n",
            "Epoch 467/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 3.0387e-04 - acc: 1.0000 - val_loss: 0.4733 - val_acc: 0.9600\n",
            "Epoch 468/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 6.2712e-05 - acc: 1.0000 - val_loss: 0.4752 - val_acc: 0.9600\n",
            "Epoch 469/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 6.6444e-05 - acc: 1.0000 - val_loss: 0.4840 - val_acc: 0.9600\n",
            "Epoch 470/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 2.7273e-04 - acc: 1.0000 - val_loss: 0.5108 - val_acc: 0.9600\n",
            "Epoch 471/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 8.6255e-05 - acc: 1.0000 - val_loss: 0.5216 - val_acc: 0.9600\n",
            "Epoch 472/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 8.7176e-05 - acc: 1.0000 - val_loss: 0.5193 - val_acc: 0.9600\n",
            "Epoch 473/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 2.1686e-04 - acc: 1.0000 - val_loss: 0.5201 - val_acc: 0.9600\n",
            "Epoch 474/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 4.4231e-05 - acc: 1.0000 - val_loss: 0.5206 - val_acc: 0.9600\n",
            "Epoch 475/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 7.2085e-05 - acc: 1.0000 - val_loss: 0.5211 - val_acc: 0.9600\n",
            "Epoch 476/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 9.7291e-05 - acc: 1.0000 - val_loss: 0.5209 - val_acc: 0.9600\n",
            "Epoch 477/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 1.5310e-05 - acc: 1.0000 - val_loss: 0.5208 - val_acc: 0.9600\n",
            "Epoch 478/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 6.4105e-05 - acc: 1.0000 - val_loss: 0.5192 - val_acc: 0.9600\n",
            "Epoch 479/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 5.7292e-05 - acc: 1.0000 - val_loss: 0.5184 - val_acc: 0.9600\n",
            "Epoch 480/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 4.4225e-04 - acc: 1.0000 - val_loss: 0.5228 - val_acc: 0.9600\n",
            "Epoch 481/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 1.3796e-04 - acc: 1.0000 - val_loss: 0.5276 - val_acc: 0.9600\n",
            "Epoch 482/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 4.5884e-05 - acc: 1.0000 - val_loss: 0.5276 - val_acc: 0.9600\n",
            "Epoch 483/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 4.7547e-05 - acc: 1.0000 - val_loss: 0.5279 - val_acc: 0.9600\n",
            "Epoch 484/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 1.6975e-05 - acc: 1.0000 - val_loss: 0.5286 - val_acc: 0.9600\n",
            "Epoch 485/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 4.4810e-05 - acc: 1.0000 - val_loss: 0.5287 - val_acc: 0.9600\n",
            "Epoch 486/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 2.6267e-05 - acc: 1.0000 - val_loss: 0.5289 - val_acc: 0.9600\n",
            "Epoch 487/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 5.7781e-05 - acc: 1.0000 - val_loss: 0.5291 - val_acc: 0.9600\n",
            "Epoch 488/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 9.2141e-05 - acc: 1.0000 - val_loss: 0.5279 - val_acc: 0.9600\n",
            "Epoch 489/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 3.8094e-04 - acc: 1.0000 - val_loss: 0.5269 - val_acc: 0.9600\n",
            "Epoch 490/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 4.2306e-05 - acc: 1.0000 - val_loss: 0.5265 - val_acc: 0.9600\n",
            "Epoch 491/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 4.7155e-05 - acc: 1.0000 - val_loss: 0.5259 - val_acc: 0.9600\n",
            "Epoch 492/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 1.5171e-04 - acc: 1.0000 - val_loss: 0.5283 - val_acc: 0.9600\n",
            "Epoch 493/1000\n",
            "809/809 [==============================] - 0s 138us/step - loss: 7.4190e-05 - acc: 1.0000 - val_loss: 0.5305 - val_acc: 0.9600\n",
            "Epoch 494/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 4.3920e-05 - acc: 1.0000 - val_loss: 0.5312 - val_acc: 0.9600\n",
            "Epoch 495/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 1.3216e-04 - acc: 1.0000 - val_loss: 0.5293 - val_acc: 0.9600\n",
            "Epoch 496/1000\n",
            "809/809 [==============================] - 0s 95us/step - loss: 7.1029e-05 - acc: 1.0000 - val_loss: 0.5263 - val_acc: 0.9600\n",
            "Epoch 497/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 3.7326e-04 - acc: 1.0000 - val_loss: 0.5255 - val_acc: 0.9600\n",
            "Epoch 498/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 4.6728e-05 - acc: 1.0000 - val_loss: 0.5144 - val_acc: 0.9600\n",
            "Epoch 499/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 2.4866e-05 - acc: 1.0000 - val_loss: 0.5124 - val_acc: 0.9600\n",
            "Epoch 500/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 9.7989e-05 - acc: 1.0000 - val_loss: 0.5149 - val_acc: 0.9600\n",
            "Epoch 501/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 9.1977e-05 - acc: 1.0000 - val_loss: 0.5188 - val_acc: 0.9600\n",
            "Epoch 502/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 8.1316e-05 - acc: 1.0000 - val_loss: 0.5265 - val_acc: 0.9600\n",
            "Epoch 503/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 5.1810e-05 - acc: 1.0000 - val_loss: 0.5298 - val_acc: 0.9600\n",
            "Epoch 504/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 8.6715e-05 - acc: 1.0000 - val_loss: 0.5279 - val_acc: 0.9600\n",
            "Epoch 505/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 1.0426e-04 - acc: 1.0000 - val_loss: 0.5247 - val_acc: 0.9600\n",
            "Epoch 506/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 8.3128e-05 - acc: 1.0000 - val_loss: 0.5224 - val_acc: 0.9600\n",
            "Epoch 507/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 1.5939e-04 - acc: 1.0000 - val_loss: 0.5207 - val_acc: 0.9600\n",
            "Epoch 508/1000\n",
            "809/809 [==============================] - 0s 95us/step - loss: 1.3660e-05 - acc: 1.0000 - val_loss: 0.5206 - val_acc: 0.9600\n",
            "Epoch 509/1000\n",
            "809/809 [==============================] - 0s 94us/step - loss: 1.8866e-04 - acc: 1.0000 - val_loss: 0.5285 - val_acc: 0.9600\n",
            "Epoch 510/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 4.1936e-05 - acc: 1.0000 - val_loss: 0.5330 - val_acc: 0.9600\n",
            "Epoch 511/1000\n",
            "809/809 [==============================] - 0s 96us/step - loss: 2.2810e-04 - acc: 1.0000 - val_loss: 0.5111 - val_acc: 0.9600\n",
            "Epoch 512/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 3.8094e-04 - acc: 1.0000 - val_loss: 0.5132 - val_acc: 0.9600\n",
            "Epoch 513/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 3.2633e-05 - acc: 1.0000 - val_loss: 0.5252 - val_acc: 0.9600\n",
            "Epoch 514/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 5.7735e-05 - acc: 1.0000 - val_loss: 0.5274 - val_acc: 0.9600\n",
            "Epoch 515/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 2.2727e-05 - acc: 1.0000 - val_loss: 0.5273 - val_acc: 0.9600\n",
            "Epoch 516/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 2.2742e-04 - acc: 1.0000 - val_loss: 0.5250 - val_acc: 0.9600\n",
            "Epoch 517/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 5.1823e-05 - acc: 1.0000 - val_loss: 0.5219 - val_acc: 0.9600\n",
            "Epoch 518/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 7.5543e-05 - acc: 1.0000 - val_loss: 0.5205 - val_acc: 0.9600\n",
            "Epoch 519/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 2.6255e-04 - acc: 1.0000 - val_loss: 0.5072 - val_acc: 0.9600\n",
            "Epoch 520/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 2.3275e-04 - acc: 1.0000 - val_loss: 0.4997 - val_acc: 0.9600\n",
            "Epoch 521/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 1.6990e-05 - acc: 1.0000 - val_loss: 0.5026 - val_acc: 0.9600\n",
            "Epoch 522/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 9.5412e-05 - acc: 1.0000 - val_loss: 0.5053 - val_acc: 0.9600\n",
            "Epoch 523/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 6.1515e-04 - acc: 1.0000 - val_loss: 0.5292 - val_acc: 0.9600\n",
            "Epoch 524/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0279 - acc: 0.9951 - val_loss: 0.3057 - val_acc: 0.9600\n",
            "Epoch 525/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0217 - acc: 0.9926 - val_loss: 0.4411 - val_acc: 0.9500\n",
            "Epoch 526/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.0375 - acc: 0.9901 - val_loss: 0.4576 - val_acc: 0.9600\n",
            "Epoch 527/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.4433 - val_acc: 0.9700\n",
            "Epoch 528/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0092 - acc: 0.9938 - val_loss: 0.2735 - val_acc: 0.9600\n",
            "Epoch 529/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0103 - acc: 0.9963 - val_loss: 0.4251 - val_acc: 0.9600\n",
            "Epoch 530/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 0.0260 - acc: 0.9913 - val_loss: 0.2765 - val_acc: 0.9600\n",
            "Epoch 531/1000\n",
            "809/809 [==============================] - 0s 106us/step - loss: 0.0160 - acc: 0.9926 - val_loss: 0.4204 - val_acc: 0.9600\n",
            "Epoch 532/1000\n",
            "809/809 [==============================] - 0s 96us/step - loss: 0.0198 - acc: 0.9938 - val_loss: 0.4345 - val_acc: 0.9600\n",
            "Epoch 533/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 0.0117 - acc: 0.9951 - val_loss: 0.3307 - val_acc: 0.9700\n",
            "Epoch 534/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 0.0183 - acc: 0.9938 - val_loss: 0.3269 - val_acc: 0.9600\n",
            "Epoch 535/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.0249 - acc: 0.9926 - val_loss: 0.3435 - val_acc: 0.9500\n",
            "Epoch 536/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0390 - acc: 0.9901 - val_loss: 0.3230 - val_acc: 0.9500\n",
            "Epoch 537/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0271 - acc: 0.9913 - val_loss: 0.3219 - val_acc: 0.9700\n",
            "Epoch 538/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 0.0140 - acc: 0.9938 - val_loss: 0.3524 - val_acc: 0.9600\n",
            "Epoch 539/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0064 - acc: 0.9975 - val_loss: 0.3645 - val_acc: 0.9600\n",
            "Epoch 540/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.3691 - val_acc: 0.9700\n",
            "Epoch 541/1000\n",
            "809/809 [==============================] - 0s 141us/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.3974 - val_acc: 0.9700\n",
            "Epoch 542/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4356 - val_acc: 0.9700\n",
            "Epoch 543/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.0018 - acc: 0.9988 - val_loss: 0.4225 - val_acc: 0.9700\n",
            "Epoch 544/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4131 - val_acc: 0.9600\n",
            "Epoch 545/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.0027 - acc: 0.9988 - val_loss: 0.4139 - val_acc: 0.9600\n",
            "Epoch 546/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3687 - val_acc: 0.9600\n",
            "Epoch 547/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0060 - acc: 0.9975 - val_loss: 0.5071 - val_acc: 0.9500\n",
            "Epoch 548/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0051 - acc: 0.9963 - val_loss: 0.4479 - val_acc: 0.9600\n",
            "Epoch 549/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 6.2311e-04 - acc: 1.0000 - val_loss: 0.4525 - val_acc: 0.9700\n",
            "Epoch 550/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 7.4360e-04 - acc: 1.0000 - val_loss: 0.4529 - val_acc: 0.9600\n",
            "Epoch 551/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4482 - val_acc: 0.9600\n",
            "Epoch 552/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 6.1412e-04 - acc: 1.0000 - val_loss: 0.4470 - val_acc: 0.9600\n",
            "Epoch 553/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 6.6688e-04 - acc: 1.0000 - val_loss: 0.4500 - val_acc: 0.9600\n",
            "Epoch 554/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0012 - acc: 0.9988 - val_loss: 0.4377 - val_acc: 0.9600\n",
            "Epoch 555/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.0142 - acc: 0.9963 - val_loss: 0.4904 - val_acc: 0.9600\n",
            "Epoch 556/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0328 - acc: 0.9975 - val_loss: 0.3455 - val_acc: 0.9600\n",
            "Epoch 557/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.2223 - val_acc: 0.9600\n",
            "Epoch 558/1000\n",
            "809/809 [==============================] - 0s 149us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.2738 - val_acc: 0.9600\n",
            "Epoch 559/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.3287 - val_acc: 0.9600\n",
            "Epoch 560/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 9.5294e-04 - acc: 1.0000 - val_loss: 0.3518 - val_acc: 0.9600\n",
            "Epoch 561/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3649 - val_acc: 0.9600\n",
            "Epoch 562/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 9.2965e-04 - acc: 1.0000 - val_loss: 0.3619 - val_acc: 0.9600\n",
            "Epoch 563/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0029 - acc: 0.9988 - val_loss: 0.4161 - val_acc: 0.9600\n",
            "Epoch 564/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4397 - val_acc: 0.9600\n",
            "Epoch 565/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 6.1343e-04 - acc: 1.0000 - val_loss: 0.4410 - val_acc: 0.9600\n",
            "Epoch 566/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 6.7024e-04 - acc: 1.0000 - val_loss: 0.4399 - val_acc: 0.9600\n",
            "Epoch 567/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 3.5792e-04 - acc: 1.0000 - val_loss: 0.4401 - val_acc: 0.9600\n",
            "Epoch 568/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 9.5974e-04 - acc: 1.0000 - val_loss: 0.4334 - val_acc: 0.9600\n",
            "Epoch 569/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 7.4464e-04 - acc: 1.0000 - val_loss: 0.4163 - val_acc: 0.9600\n",
            "Epoch 570/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 3.2180e-04 - acc: 1.0000 - val_loss: 0.4125 - val_acc: 0.9600\n",
            "Epoch 571/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4331 - val_acc: 0.9600\n",
            "Epoch 572/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 3.5626e-04 - acc: 1.0000 - val_loss: 0.4424 - val_acc: 0.9600\n",
            "Epoch 573/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 7.1744e-04 - acc: 1.0000 - val_loss: 0.4421 - val_acc: 0.9600\n",
            "Epoch 574/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 3.8618e-04 - acc: 1.0000 - val_loss: 0.4380 - val_acc: 0.9600\n",
            "Epoch 575/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 1.3540e-04 - acc: 1.0000 - val_loss: 0.4329 - val_acc: 0.9600\n",
            "Epoch 576/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 1.5424e-04 - acc: 1.0000 - val_loss: 0.4374 - val_acc: 0.9600\n",
            "Epoch 577/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 5.9279e-04 - acc: 1.0000 - val_loss: 0.4426 - val_acc: 0.9600\n",
            "Epoch 578/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 8.1357e-05 - acc: 1.0000 - val_loss: 0.4430 - val_acc: 0.9600\n",
            "Epoch 579/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 8.5351e-05 - acc: 1.0000 - val_loss: 0.4429 - val_acc: 0.9600\n",
            "Epoch 580/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 0.0014 - acc: 0.9988 - val_loss: 0.4653 - val_acc: 0.9600\n",
            "Epoch 581/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.0025 - acc: 0.9988 - val_loss: 0.5076 - val_acc: 0.9600\n",
            "Epoch 582/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 0.0031 - acc: 0.9988 - val_loss: 0.3026 - val_acc: 0.9600\n",
            "Epoch 583/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.0018 - acc: 0.9988 - val_loss: 0.2842 - val_acc: 0.9600\n",
            "Epoch 584/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3490 - val_acc: 0.9600\n",
            "Epoch 585/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 9.1658e-04 - acc: 1.0000 - val_loss: 0.4031 - val_acc: 0.9600\n",
            "Epoch 586/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 4.1759e-04 - acc: 1.0000 - val_loss: 0.4285 - val_acc: 0.9600\n",
            "Epoch 587/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 3.1412e-04 - acc: 1.0000 - val_loss: 0.4221 - val_acc: 0.9600\n",
            "Epoch 588/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0014 - acc: 0.9988 - val_loss: 0.3891 - val_acc: 0.9600\n",
            "Epoch 589/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.4131 - val_acc: 0.9600\n",
            "Epoch 590/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 2.0642e-04 - acc: 1.0000 - val_loss: 0.4320 - val_acc: 0.9600\n",
            "Epoch 591/1000\n",
            "809/809 [==============================] - 0s 93us/step - loss: 4.8174e-04 - acc: 1.0000 - val_loss: 0.4489 - val_acc: 0.9600\n",
            "Epoch 592/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0013 - acc: 0.9988 - val_loss: 0.4754 - val_acc: 0.9600\n",
            "Epoch 593/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 3.4877e-04 - acc: 1.0000 - val_loss: 0.4914 - val_acc: 0.9600\n",
            "Epoch 594/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 3.5110e-04 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.9600\n",
            "Epoch 595/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 2.1661e-04 - acc: 1.0000 - val_loss: 0.4859 - val_acc: 0.9600\n",
            "Epoch 596/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 6.8172e-04 - acc: 1.0000 - val_loss: 0.4836 - val_acc: 0.9600\n",
            "Epoch 597/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 4.2008e-04 - acc: 1.0000 - val_loss: 0.4981 - val_acc: 0.9600\n",
            "Epoch 598/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 3.3011e-04 - acc: 1.0000 - val_loss: 0.4949 - val_acc: 0.9600\n",
            "Epoch 599/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 9.2710e-04 - acc: 1.0000 - val_loss: 0.4996 - val_acc: 0.9600\n",
            "Epoch 600/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 6.3183e-05 - acc: 1.0000 - val_loss: 0.5161 - val_acc: 0.9600\n",
            "Epoch 601/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 4.7919e-04 - acc: 1.0000 - val_loss: 0.5139 - val_acc: 0.9600\n",
            "Epoch 602/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 5.6188e-04 - acc: 1.0000 - val_loss: 0.5086 - val_acc: 0.9600\n",
            "Epoch 603/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 6.6787e-05 - acc: 1.0000 - val_loss: 0.4588 - val_acc: 0.9600\n",
            "Epoch 604/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 3.0124e-04 - acc: 1.0000 - val_loss: 0.4559 - val_acc: 0.9600\n",
            "Epoch 605/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 1.1953e-04 - acc: 1.0000 - val_loss: 0.4572 - val_acc: 0.9600\n",
            "Epoch 606/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 8.0856e-05 - acc: 1.0000 - val_loss: 0.4595 - val_acc: 0.9600\n",
            "Epoch 607/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 1.0959e-04 - acc: 1.0000 - val_loss: 0.4616 - val_acc: 0.9600\n",
            "Epoch 608/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 6.4897e-05 - acc: 1.0000 - val_loss: 0.4631 - val_acc: 0.9600\n",
            "Epoch 609/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 1.1868e-05 - acc: 1.0000 - val_loss: 0.4640 - val_acc: 0.9600\n",
            "Epoch 610/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 4.6411e-05 - acc: 1.0000 - val_loss: 0.4633 - val_acc: 0.9600\n",
            "Epoch 611/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 1.5896e-05 - acc: 1.0000 - val_loss: 0.4631 - val_acc: 0.9600\n",
            "Epoch 612/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 8.6143e-05 - acc: 1.0000 - val_loss: 0.4631 - val_acc: 0.9600\n",
            "Epoch 613/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4726 - val_acc: 0.9600\n",
            "Epoch 614/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 1.7495e-04 - acc: 1.0000 - val_loss: 0.4843 - val_acc: 0.9600\n",
            "Epoch 615/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 4.9831e-05 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.9600\n",
            "Epoch 616/1000\n",
            "809/809 [==============================] - 0s 106us/step - loss: 4.9109e-04 - acc: 1.0000 - val_loss: 0.5161 - val_acc: 0.9600\n",
            "Epoch 617/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 7.4565e-05 - acc: 1.0000 - val_loss: 0.5210 - val_acc: 0.9600\n",
            "Epoch 618/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 1.6929e-04 - acc: 1.0000 - val_loss: 0.5212 - val_acc: 0.9600\n",
            "Epoch 619/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 1.4991e-04 - acc: 1.0000 - val_loss: 0.5160 - val_acc: 0.9600\n",
            "Epoch 620/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 1.9771e-04 - acc: 1.0000 - val_loss: 0.5088 - val_acc: 0.9600\n",
            "Epoch 621/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 2.3422e-05 - acc: 1.0000 - val_loss: 0.4826 - val_acc: 0.9600\n",
            "Epoch 622/1000\n",
            "809/809 [==============================] - 0s 96us/step - loss: 5.8618e-05 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.9600\n",
            "Epoch 623/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 3.6205e-05 - acc: 1.0000 - val_loss: 0.4750 - val_acc: 0.9600\n",
            "Epoch 624/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 8.9477e-04 - acc: 1.0000 - val_loss: 0.5084 - val_acc: 0.9600\n",
            "Epoch 625/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 2.7805e-05 - acc: 1.0000 - val_loss: 0.5058 - val_acc: 0.9600\n",
            "Epoch 626/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.0010 - acc: 0.9988 - val_loss: 0.4950 - val_acc: 0.9600\n",
            "Epoch 627/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.4528 - val_acc: 0.9600\n",
            "Epoch 628/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 9.7079e-04 - acc: 1.0000 - val_loss: 0.4727 - val_acc: 0.9600\n",
            "Epoch 629/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.4929 - val_acc: 0.9600\n",
            "Epoch 630/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 2.6228e-04 - acc: 1.0000 - val_loss: 0.4772 - val_acc: 0.9600\n",
            "Epoch 631/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 5.0287e-04 - acc: 1.0000 - val_loss: 0.4634 - val_acc: 0.9600\n",
            "Epoch 632/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 1.5560e-04 - acc: 1.0000 - val_loss: 0.4450 - val_acc: 0.9600\n",
            "Epoch 633/1000\n",
            "809/809 [==============================] - 0s 95us/step - loss: 3.8738e-04 - acc: 1.0000 - val_loss: 0.4430 - val_acc: 0.9600\n",
            "Epoch 634/1000\n",
            "809/809 [==============================] - 0s 96us/step - loss: 3.4740e-04 - acc: 1.0000 - val_loss: 0.4486 - val_acc: 0.9600\n",
            "Epoch 635/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 9.1226e-05 - acc: 1.0000 - val_loss: 0.4570 - val_acc: 0.9600\n",
            "Epoch 636/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 0.0018 - acc: 0.9988 - val_loss: 0.4865 - val_acc: 0.9600\n",
            "Epoch 637/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 0.0014 - acc: 0.9988 - val_loss: 0.5025 - val_acc: 0.9600\n",
            "Epoch 638/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 2.7648e-04 - acc: 1.0000 - val_loss: 0.4203 - val_acc: 0.9600\n",
            "Epoch 639/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 6.2770e-04 - acc: 1.0000 - val_loss: 0.4437 - val_acc: 0.9600\n",
            "Epoch 640/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.5602 - val_acc: 0.9600\n",
            "Epoch 641/1000\n",
            "809/809 [==============================] - 0s 106us/step - loss: 1.8987e-04 - acc: 1.0000 - val_loss: 0.5293 - val_acc: 0.9600\n",
            "Epoch 642/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5203 - val_acc: 0.9600\n",
            "Epoch 643/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 4.5360e-04 - acc: 1.0000 - val_loss: 0.4963 - val_acc: 0.9600\n",
            "Epoch 644/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 3.8773e-04 - acc: 1.0000 - val_loss: 0.4930 - val_acc: 0.9600\n",
            "Epoch 645/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 9.2741e-04 - acc: 1.0000 - val_loss: 0.4777 - val_acc: 0.9600\n",
            "Epoch 646/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4695 - val_acc: 0.9600\n",
            "Epoch 647/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0173 - acc: 0.9988 - val_loss: 0.3963 - val_acc: 0.9500\n",
            "Epoch 648/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.4031 - val_acc: 0.9700\n",
            "Epoch 649/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0085 - acc: 0.9963 - val_loss: 0.4817 - val_acc: 0.9600\n",
            "Epoch 650/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.0094 - acc: 0.9975 - val_loss: 0.4469 - val_acc: 0.9600\n",
            "Epoch 651/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 0.0100 - acc: 0.9963 - val_loss: 0.4919 - val_acc: 0.9600\n",
            "Epoch 652/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.5023 - val_acc: 0.9600\n",
            "Epoch 653/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.4874 - val_acc: 0.9600\n",
            "Epoch 654/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 3.5118e-04 - acc: 1.0000 - val_loss: 0.4595 - val_acc: 0.9600\n",
            "Epoch 655/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 5.0830e-04 - acc: 1.0000 - val_loss: 0.4480 - val_acc: 0.9600\n",
            "Epoch 656/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 3.0513e-04 - acc: 1.0000 - val_loss: 0.4324 - val_acc: 0.9600\n",
            "Epoch 657/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 5.7295e-04 - acc: 1.0000 - val_loss: 0.4325 - val_acc: 0.9600\n",
            "Epoch 658/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 2.3519e-04 - acc: 1.0000 - val_loss: 0.4356 - val_acc: 0.9600\n",
            "Epoch 659/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 3.2357e-04 - acc: 1.0000 - val_loss: 0.4329 - val_acc: 0.9600\n",
            "Epoch 660/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 4.9319e-04 - acc: 1.0000 - val_loss: 0.4393 - val_acc: 0.9600\n",
            "Epoch 661/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 1.9927e-04 - acc: 1.0000 - val_loss: 0.4510 - val_acc: 0.9600\n",
            "Epoch 662/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 6.8228e-05 - acc: 1.0000 - val_loss: 0.4577 - val_acc: 0.9600\n",
            "Epoch 663/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 3.9595e-04 - acc: 1.0000 - val_loss: 0.4507 - val_acc: 0.9600\n",
            "Epoch 664/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 1.1103e-04 - acc: 1.0000 - val_loss: 0.4513 - val_acc: 0.9600\n",
            "Epoch 665/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 1.2799e-04 - acc: 1.0000 - val_loss: 0.4541 - val_acc: 0.9600\n",
            "Epoch 666/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 8.0718e-05 - acc: 1.0000 - val_loss: 0.4591 - val_acc: 0.9600\n",
            "Epoch 667/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 1.2754e-04 - acc: 1.0000 - val_loss: 0.4649 - val_acc: 0.9600\n",
            "Epoch 668/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 2.1936e-04 - acc: 1.0000 - val_loss: 0.4732 - val_acc: 0.9600\n",
            "Epoch 669/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 8.5886e-04 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.9600\n",
            "Epoch 670/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 6.7648e-04 - acc: 1.0000 - val_loss: 0.4783 - val_acc: 0.9600\n",
            "Epoch 671/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 2.8222e-04 - acc: 1.0000 - val_loss: 0.4731 - val_acc: 0.9600\n",
            "Epoch 672/1000\n",
            "809/809 [==============================] - 0s 142us/step - loss: 2.7447e-05 - acc: 1.0000 - val_loss: 0.4714 - val_acc: 0.9600\n",
            "Epoch 673/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 1.9942e-04 - acc: 1.0000 - val_loss: 0.4655 - val_acc: 0.9600\n",
            "Epoch 674/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.0026 - acc: 0.9988 - val_loss: 0.4912 - val_acc: 0.9600\n",
            "Epoch 675/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 6.5353e-04 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.9600\n",
            "Epoch 676/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 2.8131e-04 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.9600\n",
            "Epoch 677/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.5244 - val_acc: 0.9600\n",
            "Epoch 678/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.0235 - acc: 0.9951 - val_loss: 0.5032 - val_acc: 0.9600\n",
            "Epoch 679/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.0358 - acc: 0.9913 - val_loss: 0.2470 - val_acc: 0.9700\n",
            "Epoch 680/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 0.0339 - acc: 0.9889 - val_loss: 0.2523 - val_acc: 0.9600\n",
            "Epoch 681/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0188 - acc: 0.9938 - val_loss: 0.4578 - val_acc: 0.9600\n",
            "Epoch 682/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0149 - acc: 0.9963 - val_loss: 0.3661 - val_acc: 0.9600\n",
            "Epoch 683/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.2925 - val_acc: 0.9700\n",
            "Epoch 684/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0033 - acc: 0.9988 - val_loss: 0.3456 - val_acc: 0.9600\n",
            "Epoch 685/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 7.1148e-04 - acc: 1.0000 - val_loss: 0.3791 - val_acc: 0.9600\n",
            "Epoch 686/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.3874 - val_acc: 0.9600\n",
            "Epoch 687/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 8.4876e-04 - acc: 1.0000 - val_loss: 0.3846 - val_acc: 0.9600\n",
            "Epoch 688/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 5.3131e-04 - acc: 1.0000 - val_loss: 0.3896 - val_acc: 0.9600\n",
            "Epoch 689/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 3.5736e-04 - acc: 1.0000 - val_loss: 0.3965 - val_acc: 0.9600\n",
            "Epoch 690/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 2.3221e-04 - acc: 1.0000 - val_loss: 0.4085 - val_acc: 0.9600\n",
            "Epoch 691/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 2.8022e-04 - acc: 1.0000 - val_loss: 0.4176 - val_acc: 0.9600\n",
            "Epoch 692/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 4.4961e-04 - acc: 1.0000 - val_loss: 0.4129 - val_acc: 0.9600\n",
            "Epoch 693/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 1.1878e-04 - acc: 1.0000 - val_loss: 0.4114 - val_acc: 0.9600\n",
            "Epoch 694/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 1.1076e-04 - acc: 1.0000 - val_loss: 0.4142 - val_acc: 0.9600\n",
            "Epoch 695/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 1.7946e-04 - acc: 1.0000 - val_loss: 0.4201 - val_acc: 0.9600\n",
            "Epoch 696/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 8.9557e-05 - acc: 1.0000 - val_loss: 0.4240 - val_acc: 0.9600\n",
            "Epoch 697/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 1.0975e-04 - acc: 1.0000 - val_loss: 0.4286 - val_acc: 0.9600\n",
            "Epoch 698/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 3.3148e-04 - acc: 1.0000 - val_loss: 0.4368 - val_acc: 0.9600\n",
            "Epoch 699/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 8.1413e-05 - acc: 1.0000 - val_loss: 0.4420 - val_acc: 0.9600\n",
            "Epoch 700/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 1.4566e-04 - acc: 1.0000 - val_loss: 0.4430 - val_acc: 0.9600\n",
            "Epoch 701/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 4.5101e-04 - acc: 1.0000 - val_loss: 0.4352 - val_acc: 0.9600\n",
            "Epoch 702/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 6.0737e-05 - acc: 1.0000 - val_loss: 0.4343 - val_acc: 0.9600\n",
            "Epoch 703/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 7.6801e-05 - acc: 1.0000 - val_loss: 0.4349 - val_acc: 0.9600\n",
            "Epoch 704/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 7.1436e-05 - acc: 1.0000 - val_loss: 0.4369 - val_acc: 0.9600\n",
            "Epoch 705/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 3.1246e-04 - acc: 1.0000 - val_loss: 0.4478 - val_acc: 0.9600\n",
            "Epoch 706/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 1.0745e-04 - acc: 1.0000 - val_loss: 0.4712 - val_acc: 0.9600\n",
            "Epoch 707/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 2.3477e-04 - acc: 1.0000 - val_loss: 0.4782 - val_acc: 0.9600\n",
            "Epoch 708/1000\n",
            "809/809 [==============================] - 0s 98us/step - loss: 4.3345e-04 - acc: 1.0000 - val_loss: 0.4907 - val_acc: 0.9600\n",
            "Epoch 709/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 1.5995e-04 - acc: 1.0000 - val_loss: 0.5008 - val_acc: 0.9600\n",
            "Epoch 710/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 4.5230e-05 - acc: 1.0000 - val_loss: 0.5085 - val_acc: 0.9600\n",
            "Epoch 711/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 2.3092e-04 - acc: 1.0000 - val_loss: 0.5032 - val_acc: 0.9600\n",
            "Epoch 712/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 5.5088e-04 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.9600\n",
            "Epoch 713/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 7.0983e-04 - acc: 1.0000 - val_loss: 0.5072 - val_acc: 0.9600\n",
            "Epoch 714/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 7.4159e-04 - acc: 1.0000 - val_loss: 0.4815 - val_acc: 0.9600\n",
            "Epoch 715/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5344 - val_acc: 0.9600\n",
            "Epoch 716/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 0.0083 - acc: 0.9988 - val_loss: 0.4770 - val_acc: 0.9600\n",
            "Epoch 717/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 0.0285 - acc: 0.9926 - val_loss: 0.4559 - val_acc: 0.9500\n",
            "Epoch 718/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 0.0206 - acc: 0.9938 - val_loss: 0.3669 - val_acc: 0.9700\n",
            "Epoch 719/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 0.0213 - acc: 0.9889 - val_loss: 0.3805 - val_acc: 0.9600\n",
            "Epoch 720/1000\n",
            "809/809 [==============================] - 0s 95us/step - loss: 0.0218 - acc: 0.9951 - val_loss: 0.2995 - val_acc: 0.9600\n",
            "Epoch 721/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 0.0149 - acc: 0.9938 - val_loss: 0.3090 - val_acc: 0.9600\n",
            "Epoch 722/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.4603 - val_acc: 0.9700\n",
            "Epoch 723/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 0.0107 - acc: 0.9975 - val_loss: 0.4252 - val_acc: 0.9500\n",
            "Epoch 724/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 0.0038 - acc: 0.9975 - val_loss: 0.3713 - val_acc: 0.9500\n",
            "Epoch 725/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 0.0075 - acc: 0.9988 - val_loss: 0.3775 - val_acc: 0.9600\n",
            "Epoch 726/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 0.0041 - acc: 0.9975 - val_loss: 0.3751 - val_acc: 0.9500\n",
            "Epoch 727/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3578 - val_acc: 0.9600\n",
            "Epoch 728/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.3783 - val_acc: 0.9600\n",
            "Epoch 729/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3943 - val_acc: 0.9500\n",
            "Epoch 730/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 4.7170e-04 - acc: 1.0000 - val_loss: 0.3980 - val_acc: 0.9600\n",
            "Epoch 731/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3762 - val_acc: 0.9600\n",
            "Epoch 732/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 3.5780e-04 - acc: 1.0000 - val_loss: 0.3685 - val_acc: 0.9600\n",
            "Epoch 733/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 8.3008e-04 - acc: 1.0000 - val_loss: 0.4218 - val_acc: 0.9600\n",
            "Epoch 734/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 1.9303e-04 - acc: 1.0000 - val_loss: 0.4474 - val_acc: 0.9600\n",
            "Epoch 735/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 8.5433e-04 - acc: 1.0000 - val_loss: 0.4546 - val_acc: 0.9600\n",
            "Epoch 736/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 2.5180e-04 - acc: 1.0000 - val_loss: 0.4649 - val_acc: 0.9600\n",
            "Epoch 737/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 2.8872e-04 - acc: 1.0000 - val_loss: 0.4797 - val_acc: 0.9600\n",
            "Epoch 738/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 5.5123e-04 - acc: 1.0000 - val_loss: 0.4812 - val_acc: 0.9600\n",
            "Epoch 739/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 2.4979e-04 - acc: 1.0000 - val_loss: 0.4758 - val_acc: 0.9600\n",
            "Epoch 740/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 9.4773e-05 - acc: 1.0000 - val_loss: 0.4749 - val_acc: 0.9600\n",
            "Epoch 741/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 5.2432e-04 - acc: 1.0000 - val_loss: 0.4709 - val_acc: 0.9600\n",
            "Epoch 742/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0012 - acc: 0.9988 - val_loss: 0.4357 - val_acc: 0.9600\n",
            "Epoch 743/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 1.0119e-04 - acc: 1.0000 - val_loss: 0.4282 - val_acc: 0.9600\n",
            "Epoch 744/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 3.8344e-04 - acc: 1.0000 - val_loss: 0.4350 - val_acc: 0.9600\n",
            "Epoch 745/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 3.7681e-04 - acc: 1.0000 - val_loss: 0.4423 - val_acc: 0.9600\n",
            "Epoch 746/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 5.6334e-05 - acc: 1.0000 - val_loss: 0.4427 - val_acc: 0.9600\n",
            "Epoch 747/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 2.7154e-04 - acc: 1.0000 - val_loss: 0.4525 - val_acc: 0.9600\n",
            "Epoch 748/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 5.1819e-04 - acc: 1.0000 - val_loss: 0.4514 - val_acc: 0.9600\n",
            "Epoch 749/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 1.5388e-04 - acc: 1.0000 - val_loss: 0.4522 - val_acc: 0.9600\n",
            "Epoch 750/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 7.0564e-05 - acc: 1.0000 - val_loss: 0.4551 - val_acc: 0.9600\n",
            "Epoch 751/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 3.9498e-04 - acc: 1.0000 - val_loss: 0.4547 - val_acc: 0.9600\n",
            "Epoch 752/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 2.0479e-04 - acc: 1.0000 - val_loss: 0.4550 - val_acc: 0.9600\n",
            "Epoch 753/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 3.3333e-04 - acc: 1.0000 - val_loss: 0.4624 - val_acc: 0.9600\n",
            "Epoch 754/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 2.9619e-04 - acc: 1.0000 - val_loss: 0.5020 - val_acc: 0.9600\n",
            "Epoch 755/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 2.1471e-04 - acc: 1.0000 - val_loss: 0.5131 - val_acc: 0.9600\n",
            "Epoch 756/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 4.2496e-04 - acc: 1.0000 - val_loss: 0.5228 - val_acc: 0.9600\n",
            "Epoch 757/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 2.0000e-04 - acc: 1.0000 - val_loss: 0.5230 - val_acc: 0.9600\n",
            "Epoch 758/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 1.6939e-05 - acc: 1.0000 - val_loss: 0.5226 - val_acc: 0.9600\n",
            "Epoch 759/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 2.9056e-04 - acc: 1.0000 - val_loss: 0.5254 - val_acc: 0.9600\n",
            "Epoch 760/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 8.4148e-05 - acc: 1.0000 - val_loss: 0.5298 - val_acc: 0.9600\n",
            "Epoch 761/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 6.7813e-05 - acc: 1.0000 - val_loss: 0.5309 - val_acc: 0.9600\n",
            "Epoch 762/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 5.0872e-05 - acc: 1.0000 - val_loss: 0.5307 - val_acc: 0.9600\n",
            "Epoch 763/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 1.0013e-04 - acc: 1.0000 - val_loss: 0.5298 - val_acc: 0.9600\n",
            "Epoch 764/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 3.4752e-05 - acc: 1.0000 - val_loss: 0.5286 - val_acc: 0.9600\n",
            "Epoch 765/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 2.2567e-04 - acc: 1.0000 - val_loss: 0.5267 - val_acc: 0.9600\n",
            "Epoch 766/1000\n",
            "809/809 [==============================] - 0s 138us/step - loss: 1.1149e-04 - acc: 1.0000 - val_loss: 0.5270 - val_acc: 0.9600\n",
            "Epoch 767/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 1.2261e-04 - acc: 1.0000 - val_loss: 0.5270 - val_acc: 0.9600\n",
            "Epoch 768/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 3.3098e-05 - acc: 1.0000 - val_loss: 0.5271 - val_acc: 0.9600\n",
            "Epoch 769/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 4.3403e-04 - acc: 1.0000 - val_loss: 0.5233 - val_acc: 0.9600\n",
            "Epoch 770/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 8.6500e-05 - acc: 1.0000 - val_loss: 0.5203 - val_acc: 0.9600\n",
            "Epoch 771/1000\n",
            "809/809 [==============================] - 0s 136us/step - loss: 5.9014e-05 - acc: 1.0000 - val_loss: 0.5181 - val_acc: 0.9600\n",
            "Epoch 772/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 1.1730e-04 - acc: 1.0000 - val_loss: 0.5203 - val_acc: 0.9600\n",
            "Epoch 773/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 2.0735e-05 - acc: 1.0000 - val_loss: 0.5210 - val_acc: 0.9600\n",
            "Epoch 774/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 4.5529e-05 - acc: 1.0000 - val_loss: 0.5212 - val_acc: 0.9600\n",
            "Epoch 775/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 1.3363e-05 - acc: 1.0000 - val_loss: 0.5218 - val_acc: 0.9600\n",
            "Epoch 776/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 5.0723e-05 - acc: 1.0000 - val_loss: 0.5226 - val_acc: 0.9600\n",
            "Epoch 777/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 1.4116e-04 - acc: 1.0000 - val_loss: 0.5241 - val_acc: 0.9600\n",
            "Epoch 778/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 1.1602e-05 - acc: 1.0000 - val_loss: 0.5249 - val_acc: 0.9600\n",
            "Epoch 779/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 6.7503e-05 - acc: 1.0000 - val_loss: 0.5248 - val_acc: 0.9600\n",
            "Epoch 780/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 6.3220e-05 - acc: 1.0000 - val_loss: 0.5226 - val_acc: 0.9600\n",
            "Epoch 781/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 2.3935e-05 - acc: 1.0000 - val_loss: 0.5215 - val_acc: 0.9600\n",
            "Epoch 782/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 5.4693e-04 - acc: 1.0000 - val_loss: 0.5228 - val_acc: 0.9600\n",
            "Epoch 783/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 6.1570e-04 - acc: 1.0000 - val_loss: 0.5234 - val_acc: 0.9600\n",
            "Epoch 784/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 1.8142e-04 - acc: 1.0000 - val_loss: 0.5279 - val_acc: 0.9600\n",
            "Epoch 785/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 1.7255e-04 - acc: 1.0000 - val_loss: 0.5309 - val_acc: 0.9600\n",
            "Epoch 786/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 1.6218e-05 - acc: 1.0000 - val_loss: 0.5313 - val_acc: 0.9600\n",
            "Epoch 787/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 4.0591e-05 - acc: 1.0000 - val_loss: 0.5318 - val_acc: 0.9600\n",
            "Epoch 788/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 5.0945e-05 - acc: 1.0000 - val_loss: 0.5332 - val_acc: 0.9600\n",
            "Epoch 789/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 6.5428e-05 - acc: 1.0000 - val_loss: 0.5336 - val_acc: 0.9600\n",
            "Epoch 790/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 8.0929e-05 - acc: 1.0000 - val_loss: 0.5323 - val_acc: 0.9600\n",
            "Epoch 791/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 8.7414e-05 - acc: 1.0000 - val_loss: 0.5337 - val_acc: 0.9600\n",
            "Epoch 792/1000\n",
            "809/809 [==============================] - 0s 99us/step - loss: 1.9901e-04 - acc: 1.0000 - val_loss: 0.5398 - val_acc: 0.9600\n",
            "Epoch 793/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 1.5509e-04 - acc: 1.0000 - val_loss: 0.5355 - val_acc: 0.9600\n",
            "Epoch 794/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 5.2572e-05 - acc: 1.0000 - val_loss: 0.5322 - val_acc: 0.9600\n",
            "Epoch 795/1000\n",
            "809/809 [==============================] - 0s 138us/step - loss: 2.2296e-05 - acc: 1.0000 - val_loss: 0.5320 - val_acc: 0.9600\n",
            "Epoch 796/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 4.7987e-05 - acc: 1.0000 - val_loss: 0.5318 - val_acc: 0.9600\n",
            "Epoch 797/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 2.3435e-05 - acc: 1.0000 - val_loss: 0.5316 - val_acc: 0.9600\n",
            "Epoch 798/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 5.6905e-05 - acc: 1.0000 - val_loss: 0.5312 - val_acc: 0.9600\n",
            "Epoch 799/1000\n",
            "809/809 [==============================] - 0s 106us/step - loss: 6.4287e-05 - acc: 1.0000 - val_loss: 0.5335 - val_acc: 0.9600\n",
            "Epoch 800/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 5.6733e-05 - acc: 1.0000 - val_loss: 0.5356 - val_acc: 0.9600\n",
            "Epoch 801/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 1.0209e-04 - acc: 1.0000 - val_loss: 0.5363 - val_acc: 0.9600\n",
            "Epoch 802/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0011 - acc: 0.9988 - val_loss: 0.5028 - val_acc: 0.9600\n",
            "Epoch 803/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 5.6952e-04 - acc: 1.0000 - val_loss: 0.4988 - val_acc: 0.9600\n",
            "Epoch 804/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 3.1582e-05 - acc: 1.0000 - val_loss: 0.4992 - val_acc: 0.9600\n",
            "Epoch 805/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 1.8076e-04 - acc: 1.0000 - val_loss: 0.5027 - val_acc: 0.9600\n",
            "Epoch 806/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 3.6022e-05 - acc: 1.0000 - val_loss: 0.5052 - val_acc: 0.9600\n",
            "Epoch 807/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 5.6858e-05 - acc: 1.0000 - val_loss: 0.5087 - val_acc: 0.9600\n",
            "Epoch 808/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 1.1729e-05 - acc: 1.0000 - val_loss: 0.5114 - val_acc: 0.9600\n",
            "Epoch 809/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 1.1359e-04 - acc: 1.0000 - val_loss: 0.5109 - val_acc: 0.9600\n",
            "Epoch 810/1000\n",
            "809/809 [==============================] - 0s 95us/step - loss: 4.9937e-05 - acc: 1.0000 - val_loss: 0.5074 - val_acc: 0.9600\n",
            "Epoch 811/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 4.2679e-05 - acc: 1.0000 - val_loss: 0.5068 - val_acc: 0.9600\n",
            "Epoch 812/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 2.6716e-05 - acc: 1.0000 - val_loss: 0.5082 - val_acc: 0.9600\n",
            "Epoch 813/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 5.6680e-05 - acc: 1.0000 - val_loss: 0.5074 - val_acc: 0.9600\n",
            "Epoch 814/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 6.6547e-06 - acc: 1.0000 - val_loss: 0.5076 - val_acc: 0.9600\n",
            "Epoch 815/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 2.6829e-05 - acc: 1.0000 - val_loss: 0.5082 - val_acc: 0.9600\n",
            "Epoch 816/1000\n",
            "809/809 [==============================] - 0s 136us/step - loss: 2.1850e-05 - acc: 1.0000 - val_loss: 0.5086 - val_acc: 0.9600\n",
            "Epoch 817/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 5.4558e-05 - acc: 1.0000 - val_loss: 0.5092 - val_acc: 0.9600\n",
            "Epoch 818/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 2.9241e-05 - acc: 1.0000 - val_loss: 0.5095 - val_acc: 0.9600\n",
            "Epoch 819/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 5.4735e-06 - acc: 1.0000 - val_loss: 0.5101 - val_acc: 0.9600\n",
            "Epoch 820/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 5.0001e-06 - acc: 1.0000 - val_loss: 0.5103 - val_acc: 0.9600\n",
            "Epoch 821/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 3.0998e-05 - acc: 1.0000 - val_loss: 0.5117 - val_acc: 0.9600\n",
            "Epoch 822/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 2.8875e-05 - acc: 1.0000 - val_loss: 0.5123 - val_acc: 0.9600\n",
            "Epoch 823/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 1.1605e-04 - acc: 1.0000 - val_loss: 0.5144 - val_acc: 0.9600\n",
            "Epoch 824/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 4.1791e-05 - acc: 1.0000 - val_loss: 0.5160 - val_acc: 0.9600\n",
            "Epoch 825/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 2.1790e-05 - acc: 1.0000 - val_loss: 0.5166 - val_acc: 0.9600\n",
            "Epoch 826/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 4.3848e-05 - acc: 1.0000 - val_loss: 0.5174 - val_acc: 0.9600\n",
            "Epoch 827/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 2.9251e-05 - acc: 1.0000 - val_loss: 0.5180 - val_acc: 0.9600\n",
            "Epoch 828/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 2.0161e-05 - acc: 1.0000 - val_loss: 0.5208 - val_acc: 0.9600\n",
            "Epoch 829/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 3.2537e-06 - acc: 1.0000 - val_loss: 0.5230 - val_acc: 0.9600\n",
            "Epoch 830/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 7.0824e-06 - acc: 1.0000 - val_loss: 0.5236 - val_acc: 0.9600\n",
            "Epoch 831/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 1.2465e-04 - acc: 1.0000 - val_loss: 0.5326 - val_acc: 0.9600\n",
            "Epoch 832/1000\n",
            "809/809 [==============================] - 0s 100us/step - loss: 1.8799e-05 - acc: 1.0000 - val_loss: 0.5359 - val_acc: 0.9600\n",
            "Epoch 833/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 1.3740e-05 - acc: 1.0000 - val_loss: 0.5369 - val_acc: 0.9600\n",
            "Epoch 834/1000\n",
            "809/809 [==============================] - 0s 111us/step - loss: 8.2489e-06 - acc: 1.0000 - val_loss: 0.5372 - val_acc: 0.9600\n",
            "Epoch 835/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 2.2871e-05 - acc: 1.0000 - val_loss: 0.5373 - val_acc: 0.9600\n",
            "Epoch 836/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 1.1133e-05 - acc: 1.0000 - val_loss: 0.5375 - val_acc: 0.9600\n",
            "Epoch 837/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 2.2575e-05 - acc: 1.0000 - val_loss: 0.5366 - val_acc: 0.9600\n",
            "Epoch 838/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 1.8619e-05 - acc: 1.0000 - val_loss: 0.5361 - val_acc: 0.9600\n",
            "Epoch 839/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 2.8759e-06 - acc: 1.0000 - val_loss: 0.5360 - val_acc: 0.9600\n",
            "Epoch 840/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 4.3372e-06 - acc: 1.0000 - val_loss: 0.5359 - val_acc: 0.9600\n",
            "Epoch 841/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 2.3075e-04 - acc: 1.0000 - val_loss: 0.5354 - val_acc: 0.9600\n",
            "Epoch 842/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 3.6492e-05 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.9600\n",
            "Epoch 843/1000\n",
            "809/809 [==============================] - 0s 138us/step - loss: 4.8876e-06 - acc: 1.0000 - val_loss: 0.4593 - val_acc: 0.9600\n",
            "Epoch 844/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 1.5711e-05 - acc: 1.0000 - val_loss: 0.4552 - val_acc: 0.9600\n",
            "Epoch 845/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 4.5760e-05 - acc: 1.0000 - val_loss: 0.4515 - val_acc: 0.9600\n",
            "Epoch 846/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 7.3490e-06 - acc: 1.0000 - val_loss: 0.4485 - val_acc: 0.9600\n",
            "Epoch 847/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 4.2752e-06 - acc: 1.0000 - val_loss: 0.4486 - val_acc: 0.9600\n",
            "Epoch 848/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 1.6703e-05 - acc: 1.0000 - val_loss: 0.4549 - val_acc: 0.9600\n",
            "Epoch 849/1000\n",
            "809/809 [==============================] - 0s 140us/step - loss: 1.2791e-05 - acc: 1.0000 - val_loss: 0.4591 - val_acc: 0.9600\n",
            "Epoch 850/1000\n",
            "809/809 [==============================] - 0s 144us/step - loss: 5.3480e-06 - acc: 1.0000 - val_loss: 0.4648 - val_acc: 0.9600\n",
            "Epoch 851/1000\n",
            "809/809 [==============================] - 0s 158us/step - loss: 1.2627e-05 - acc: 1.0000 - val_loss: 0.4660 - val_acc: 0.9600\n",
            "Epoch 852/1000\n",
            "809/809 [==============================] - 0s 148us/step - loss: 2.9028e-05 - acc: 1.0000 - val_loss: 0.4713 - val_acc: 0.9600\n",
            "Epoch 853/1000\n",
            "809/809 [==============================] - 0s 141us/step - loss: 1.3334e-05 - acc: 1.0000 - val_loss: 0.4831 - val_acc: 0.9600\n",
            "Epoch 854/1000\n",
            "809/809 [==============================] - 0s 136us/step - loss: 6.1286e-06 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.9600\n",
            "Epoch 855/1000\n",
            "809/809 [==============================] - 0s 142us/step - loss: 3.0470e-05 - acc: 1.0000 - val_loss: 0.4908 - val_acc: 0.9600\n",
            "Epoch 856/1000\n",
            "809/809 [==============================] - 0s 138us/step - loss: 1.2091e-04 - acc: 1.0000 - val_loss: 0.5379 - val_acc: 0.9600\n",
            "Epoch 857/1000\n",
            "809/809 [==============================] - 0s 138us/step - loss: 5.4582e-05 - acc: 1.0000 - val_loss: 0.5424 - val_acc: 0.9600\n",
            "Epoch 858/1000\n",
            "809/809 [==============================] - 0s 142us/step - loss: 9.6016e-06 - acc: 1.0000 - val_loss: 0.5432 - val_acc: 0.9600\n",
            "Epoch 859/1000\n",
            "809/809 [==============================] - 0s 138us/step - loss: 2.1192e-05 - acc: 1.0000 - val_loss: 0.5433 - val_acc: 0.9600\n",
            "Epoch 860/1000\n",
            "809/809 [==============================] - 0s 141us/step - loss: 4.3886e-06 - acc: 1.0000 - val_loss: 0.5438 - val_acc: 0.9600\n",
            "Epoch 861/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 1.6582e-04 - acc: 1.0000 - val_loss: 0.5369 - val_acc: 0.9600\n",
            "Epoch 862/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 1.7730e-06 - acc: 1.0000 - val_loss: 0.5309 - val_acc: 0.9600\n",
            "Epoch 863/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 1.1375e-04 - acc: 1.0000 - val_loss: 0.5287 - val_acc: 0.9600\n",
            "Epoch 864/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 2.5221e-05 - acc: 1.0000 - val_loss: 0.5275 - val_acc: 0.9600\n",
            "Epoch 865/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 5.0701e-06 - acc: 1.0000 - val_loss: 0.5273 - val_acc: 0.9600\n",
            "Epoch 866/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 5.1148e-06 - acc: 1.0000 - val_loss: 0.5274 - val_acc: 0.9600\n",
            "Epoch 867/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 4.6840e-06 - acc: 1.0000 - val_loss: 0.5274 - val_acc: 0.9600\n",
            "Epoch 868/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 5.3829e-06 - acc: 1.0000 - val_loss: 0.5275 - val_acc: 0.9600\n",
            "Epoch 869/1000\n",
            "809/809 [==============================] - 0s 112us/step - loss: 2.6498e-06 - acc: 1.0000 - val_loss: 0.5273 - val_acc: 0.9600\n",
            "Epoch 870/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 9.5230e-06 - acc: 1.0000 - val_loss: 0.5280 - val_acc: 0.9600\n",
            "Epoch 871/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 6.2768e-06 - acc: 1.0000 - val_loss: 0.5281 - val_acc: 0.9600\n",
            "Epoch 872/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 4.4260e-05 - acc: 1.0000 - val_loss: 0.5272 - val_acc: 0.9600\n",
            "Epoch 873/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 7.7992e-06 - acc: 1.0000 - val_loss: 0.5235 - val_acc: 0.9600\n",
            "Epoch 874/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 6.1299e-05 - acc: 1.0000 - val_loss: 0.5243 - val_acc: 0.9600\n",
            "Epoch 875/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 9.8974e-06 - acc: 1.0000 - val_loss: 0.5259 - val_acc: 0.9600\n",
            "Epoch 876/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 2.3927e-05 - acc: 1.0000 - val_loss: 0.5257 - val_acc: 0.9600\n",
            "Epoch 877/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 2.6606e-06 - acc: 1.0000 - val_loss: 0.5263 - val_acc: 0.9600\n",
            "Epoch 878/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 1.7185e-05 - acc: 1.0000 - val_loss: 0.5258 - val_acc: 0.9600\n",
            "Epoch 879/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 3.6144e-06 - acc: 1.0000 - val_loss: 0.5258 - val_acc: 0.9600\n",
            "Epoch 880/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 1.0055e-06 - acc: 1.0000 - val_loss: 0.5260 - val_acc: 0.9600\n",
            "Epoch 881/1000\n",
            "809/809 [==============================] - 0s 146us/step - loss: 3.2333e-06 - acc: 1.0000 - val_loss: 0.5266 - val_acc: 0.9600\n",
            "Epoch 882/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 4.7519e-06 - acc: 1.0000 - val_loss: 0.5271 - val_acc: 0.9600\n",
            "Epoch 883/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 4.8905e-05 - acc: 1.0000 - val_loss: 0.5277 - val_acc: 0.9600\n",
            "Epoch 884/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 1.0540e-05 - acc: 1.0000 - val_loss: 0.5282 - val_acc: 0.9600\n",
            "Epoch 885/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 9.0012e-06 - acc: 1.0000 - val_loss: 0.5290 - val_acc: 0.9600\n",
            "Epoch 886/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 8.3054e-06 - acc: 1.0000 - val_loss: 0.5305 - val_acc: 0.9600\n",
            "Epoch 887/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 8.3554e-07 - acc: 1.0000 - val_loss: 0.5311 - val_acc: 0.9600\n",
            "Epoch 888/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 5.6106e-05 - acc: 1.0000 - val_loss: 0.5385 - val_acc: 0.9600\n",
            "Epoch 889/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 1.1286e-05 - acc: 1.0000 - val_loss: 0.5401 - val_acc: 0.9600\n",
            "Epoch 890/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 4.9455e-06 - acc: 1.0000 - val_loss: 0.5401 - val_acc: 0.9600\n",
            "Epoch 891/1000\n",
            "809/809 [==============================] - 0s 141us/step - loss: 0.0011 - acc: 0.9988 - val_loss: 0.6017 - val_acc: 0.9500\n",
            "Epoch 892/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 0.0227 - acc: 0.9926 - val_loss: 0.5758 - val_acc: 0.9500\n",
            "Epoch 893/1000\n",
            "809/809 [==============================] - 0s 106us/step - loss: 0.0241 - acc: 0.9938 - val_loss: 0.5013 - val_acc: 0.9500\n",
            "Epoch 894/1000\n",
            "809/809 [==============================] - 0s 103us/step - loss: 0.0265 - acc: 0.9938 - val_loss: 0.4538 - val_acc: 0.9600\n",
            "Epoch 895/1000\n",
            "809/809 [==============================] - 0s 106us/step - loss: 0.0196 - acc: 0.9963 - val_loss: 0.3844 - val_acc: 0.9600\n",
            "Epoch 896/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 0.0087 - acc: 0.9963 - val_loss: 0.5755 - val_acc: 0.9400\n",
            "Epoch 897/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0337 - acc: 0.9951 - val_loss: 0.4476 - val_acc: 0.9700\n",
            "Epoch 898/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 0.0189 - acc: 0.9938 - val_loss: 0.4167 - val_acc: 0.9700\n",
            "Epoch 899/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0248 - acc: 0.9975 - val_loss: 0.4382 - val_acc: 0.9600\n",
            "Epoch 900/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 0.0062 - acc: 0.9975 - val_loss: 0.5165 - val_acc: 0.9600\n",
            "Epoch 901/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.4299 - val_acc: 0.9600\n",
            "Epoch 902/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.0024 - acc: 0.9988 - val_loss: 0.3988 - val_acc: 0.9600\n",
            "Epoch 903/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 0.0025 - acc: 0.9988 - val_loss: 0.4424 - val_acc: 0.9600\n",
            "Epoch 904/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0023 - acc: 0.9988 - val_loss: 0.4741 - val_acc: 0.9600\n",
            "Epoch 905/1000\n",
            "809/809 [==============================] - 0s 114us/step - loss: 8.7423e-04 - acc: 1.0000 - val_loss: 0.5025 - val_acc: 0.9600\n",
            "Epoch 906/1000\n",
            "809/809 [==============================] - 0s 135us/step - loss: 2.7710e-04 - acc: 1.0000 - val_loss: 0.5090 - val_acc: 0.9600\n",
            "Epoch 907/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 2.7134e-04 - acc: 1.0000 - val_loss: 0.5145 - val_acc: 0.9600\n",
            "Epoch 908/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 3.9656e-04 - acc: 1.0000 - val_loss: 0.5254 - val_acc: 0.9600\n",
            "Epoch 909/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 2.9094e-04 - acc: 1.0000 - val_loss: 0.5304 - val_acc: 0.9600\n",
            "Epoch 910/1000\n",
            "809/809 [==============================] - 0s 134us/step - loss: 1.2531e-04 - acc: 1.0000 - val_loss: 0.5381 - val_acc: 0.9600\n",
            "Epoch 911/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0019 - acc: 0.9988 - val_loss: 0.4925 - val_acc: 0.9600\n",
            "Epoch 912/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 5.6570e-04 - acc: 1.0000 - val_loss: 0.4733 - val_acc: 0.9600\n",
            "Epoch 913/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 1.6861e-04 - acc: 1.0000 - val_loss: 0.4614 - val_acc: 0.9600\n",
            "Epoch 914/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 3.3829e-04 - acc: 1.0000 - val_loss: 0.4743 - val_acc: 0.9600\n",
            "Epoch 915/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 5.6796e-04 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.9600\n",
            "Epoch 916/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 1.7224e-04 - acc: 1.0000 - val_loss: 0.4981 - val_acc: 0.9600\n",
            "Epoch 917/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 1.2924e-04 - acc: 1.0000 - val_loss: 0.5059 - val_acc: 0.9600\n",
            "Epoch 918/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 3.3473e-04 - acc: 1.0000 - val_loss: 0.5100 - val_acc: 0.9600\n",
            "Epoch 919/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 2.1994e-04 - acc: 1.0000 - val_loss: 0.5153 - val_acc: 0.9600\n",
            "Epoch 920/1000\n",
            "809/809 [==============================] - 0s 145us/step - loss: 6.0746e-04 - acc: 1.0000 - val_loss: 0.4947 - val_acc: 0.9600\n",
            "Epoch 921/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 4.1382e-04 - acc: 1.0000 - val_loss: 0.5039 - val_acc: 0.9600\n",
            "Epoch 922/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 3.0948e-05 - acc: 1.0000 - val_loss: 0.5391 - val_acc: 0.9600\n",
            "Epoch 923/1000\n",
            "809/809 [==============================] - 0s 139us/step - loss: 4.4628e-04 - acc: 1.0000 - val_loss: 0.5538 - val_acc: 0.9600\n",
            "Epoch 924/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 1.0714e-04 - acc: 1.0000 - val_loss: 0.5577 - val_acc: 0.9600\n",
            "Epoch 925/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 3.4574e-05 - acc: 1.0000 - val_loss: 0.5561 - val_acc: 0.9600\n",
            "Epoch 926/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 3.6988e-05 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.9600\n",
            "Epoch 927/1000\n",
            "809/809 [==============================] - 0s 128us/step - loss: 4.4953e-05 - acc: 1.0000 - val_loss: 0.5545 - val_acc: 0.9600\n",
            "Epoch 928/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 1.3013e-04 - acc: 1.0000 - val_loss: 0.5577 - val_acc: 0.9600\n",
            "Epoch 929/1000\n",
            "809/809 [==============================] - 0s 130us/step - loss: 7.8949e-05 - acc: 1.0000 - val_loss: 0.5619 - val_acc: 0.9600\n",
            "Epoch 930/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 2.8456e-05 - acc: 1.0000 - val_loss: 0.5626 - val_acc: 0.9600\n",
            "Epoch 931/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 4.2500e-05 - acc: 1.0000 - val_loss: 0.5625 - val_acc: 0.9600\n",
            "Epoch 932/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 3.6327e-05 - acc: 1.0000 - val_loss: 0.5636 - val_acc: 0.9600\n",
            "Epoch 933/1000\n",
            "809/809 [==============================] - 0s 137us/step - loss: 1.1249e-04 - acc: 1.0000 - val_loss: 0.5644 - val_acc: 0.9600\n",
            "Epoch 934/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 2.7756e-05 - acc: 1.0000 - val_loss: 0.5645 - val_acc: 0.9600\n",
            "Epoch 935/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 2.4413e-05 - acc: 1.0000 - val_loss: 0.5649 - val_acc: 0.9600\n",
            "Epoch 936/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 1.4697e-05 - acc: 1.0000 - val_loss: 0.5649 - val_acc: 0.9600\n",
            "Epoch 937/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 3.4308e-05 - acc: 1.0000 - val_loss: 0.5651 - val_acc: 0.9600\n",
            "Epoch 938/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 1.0749e-04 - acc: 1.0000 - val_loss: 0.5645 - val_acc: 0.9600\n",
            "Epoch 939/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0028 - acc: 0.9988 - val_loss: 0.6085 - val_acc: 0.9500\n",
            "Epoch 940/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 7.7920e-04 - acc: 1.0000 - val_loss: 0.5553 - val_acc: 0.9500\n",
            "Epoch 941/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 5.3862e-04 - acc: 1.0000 - val_loss: 0.4666 - val_acc: 0.9600\n",
            "Epoch 942/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 1.6395e-04 - acc: 1.0000 - val_loss: 0.4509 - val_acc: 0.9600\n",
            "Epoch 943/1000\n",
            "809/809 [==============================] - 0s 126us/step - loss: 1.3017e-04 - acc: 1.0000 - val_loss: 0.4602 - val_acc: 0.9600\n",
            "Epoch 944/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 5.9248e-05 - acc: 1.0000 - val_loss: 0.4668 - val_acc: 0.9600\n",
            "Epoch 945/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0031 - acc: 0.9988 - val_loss: 0.5570 - val_acc: 0.9600\n",
            "Epoch 946/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 0.0157 - acc: 0.9975 - val_loss: 0.5407 - val_acc: 0.9600\n",
            "Epoch 947/1000\n",
            "809/809 [==============================] - 0s 124us/step - loss: 0.0066 - acc: 0.9975 - val_loss: 0.3449 - val_acc: 0.9700\n",
            "Epoch 948/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0257 - acc: 0.9913 - val_loss: 0.3356 - val_acc: 0.9600\n",
            "Epoch 949/1000\n",
            "809/809 [==============================] - 0s 140us/step - loss: 0.0098 - acc: 0.9975 - val_loss: 0.4117 - val_acc: 0.9600\n",
            "Epoch 950/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0132 - acc: 0.9975 - val_loss: 0.3748 - val_acc: 0.9700\n",
            "Epoch 951/1000\n",
            "809/809 [==============================] - 0s 110us/step - loss: 0.0201 - acc: 0.9963 - val_loss: 0.4827 - val_acc: 0.9500\n",
            "Epoch 952/1000\n",
            "809/809 [==============================] - 0s 107us/step - loss: 0.0147 - acc: 0.9951 - val_loss: 0.4432 - val_acc: 0.9600\n",
            "Epoch 953/1000\n",
            "809/809 [==============================] - 0s 116us/step - loss: 0.0105 - acc: 0.9963 - val_loss: 0.3053 - val_acc: 0.9700\n",
            "Epoch 954/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 0.0131 - acc: 0.9951 - val_loss: 0.3704 - val_acc: 0.9700\n",
            "Epoch 955/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0125 - acc: 0.9951 - val_loss: 0.5254 - val_acc: 0.9500\n",
            "Epoch 956/1000\n",
            "809/809 [==============================] - 0s 122us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5431 - val_acc: 0.9500\n",
            "Epoch 957/1000\n",
            "809/809 [==============================] - 0s 131us/step - loss: 0.0098 - acc: 0.9975 - val_loss: 0.4830 - val_acc: 0.9500\n",
            "Epoch 958/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.4888 - val_acc: 0.9700\n",
            "Epoch 959/1000\n",
            "809/809 [==============================] - 0s 108us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.4779 - val_acc: 0.9600\n",
            "Epoch 960/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0098 - acc: 0.9951 - val_loss: 0.5044 - val_acc: 0.9600\n",
            "Epoch 961/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 0.0035 - acc: 0.9975 - val_loss: 0.4942 - val_acc: 0.9600\n",
            "Epoch 962/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 0.0017 - acc: 0.9988 - val_loss: 0.4726 - val_acc: 0.9600\n",
            "Epoch 963/1000\n",
            "809/809 [==============================] - 0s 105us/step - loss: 4.8723e-04 - acc: 1.0000 - val_loss: 0.4779 - val_acc: 0.9600\n",
            "Epoch 964/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 3.3531e-04 - acc: 1.0000 - val_loss: 0.4838 - val_acc: 0.9600\n",
            "Epoch 965/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 2.1194e-04 - acc: 1.0000 - val_loss: 0.4872 - val_acc: 0.9600\n",
            "Epoch 966/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 8.0907e-04 - acc: 1.0000 - val_loss: 0.4939 - val_acc: 0.9600\n",
            "Epoch 967/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 9.2527e-04 - acc: 1.0000 - val_loss: 0.4946 - val_acc: 0.9600\n",
            "Epoch 968/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 1.4742e-04 - acc: 1.0000 - val_loss: 0.4934 - val_acc: 0.9600\n",
            "Epoch 969/1000\n",
            "809/809 [==============================] - 0s 115us/step - loss: 1.1066e-04 - acc: 1.0000 - val_loss: 0.4939 - val_acc: 0.9600\n",
            "Epoch 970/1000\n",
            "809/809 [==============================] - 0s 109us/step - loss: 1.0862e-04 - acc: 1.0000 - val_loss: 0.4941 - val_acc: 0.9600\n",
            "Epoch 971/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.4937 - val_acc: 0.9600\n",
            "Epoch 972/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 4.8162e-04 - acc: 1.0000 - val_loss: 0.4970 - val_acc: 0.9600\n",
            "Epoch 973/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 3.4176e-04 - acc: 1.0000 - val_loss: 0.5030 - val_acc: 0.9600\n",
            "Epoch 974/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 6.1121e-04 - acc: 1.0000 - val_loss: 0.5016 - val_acc: 0.9600\n",
            "Epoch 975/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 4.8247e-05 - acc: 1.0000 - val_loss: 0.4914 - val_acc: 0.9600\n",
            "Epoch 976/1000\n",
            "809/809 [==============================] - 0s 127us/step - loss: 7.9427e-05 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.9700\n",
            "Epoch 977/1000\n",
            "809/809 [==============================] - 0s 104us/step - loss: 2.9752e-04 - acc: 1.0000 - val_loss: 0.4924 - val_acc: 0.9600\n",
            "Epoch 978/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 7.1498e-05 - acc: 1.0000 - val_loss: 0.4993 - val_acc: 0.9600\n",
            "Epoch 979/1000\n",
            "809/809 [==============================] - 0s 95us/step - loss: 3.7342e-05 - acc: 1.0000 - val_loss: 0.5016 - val_acc: 0.9600\n",
            "Epoch 980/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 1.4264e-04 - acc: 1.0000 - val_loss: 0.5026 - val_acc: 0.9600\n",
            "Epoch 981/1000\n",
            "809/809 [==============================] - 0s 102us/step - loss: 1.7640e-04 - acc: 1.0000 - val_loss: 0.5041 - val_acc: 0.9600\n",
            "Epoch 982/1000\n",
            "809/809 [==============================] - 0s 120us/step - loss: 6.8490e-04 - acc: 1.0000 - val_loss: 0.5048 - val_acc: 0.9600\n",
            "Epoch 983/1000\n",
            "809/809 [==============================] - 0s 97us/step - loss: 5.1674e-05 - acc: 1.0000 - val_loss: 0.5061 - val_acc: 0.9600\n",
            "Epoch 984/1000\n",
            "809/809 [==============================] - 0s 138us/step - loss: 7.9130e-04 - acc: 1.0000 - val_loss: 0.5214 - val_acc: 0.9600\n",
            "Epoch 985/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 0.0021 - acc: 0.9988 - val_loss: 0.5226 - val_acc: 0.9600\n",
            "Epoch 986/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 8.5441e-04 - acc: 1.0000 - val_loss: 0.5115 - val_acc: 0.9600\n",
            "Epoch 987/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5242 - val_acc: 0.9600\n",
            "Epoch 988/1000\n",
            "809/809 [==============================] - 0s 121us/step - loss: 0.0016 - acc: 0.9988 - val_loss: 0.5271 - val_acc: 0.9600\n",
            "Epoch 989/1000\n",
            "809/809 [==============================] - 0s 117us/step - loss: 8.7210e-05 - acc: 1.0000 - val_loss: 0.5270 - val_acc: 0.9600\n",
            "Epoch 990/1000\n",
            "809/809 [==============================] - 0s 119us/step - loss: 3.3831e-04 - acc: 1.0000 - val_loss: 0.5325 - val_acc: 0.9600\n",
            "Epoch 991/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 6.9219e-05 - acc: 1.0000 - val_loss: 0.5381 - val_acc: 0.9600\n",
            "Epoch 992/1000\n",
            "809/809 [==============================] - 0s 123us/step - loss: 1.0053e-04 - acc: 1.0000 - val_loss: 0.5386 - val_acc: 0.9600\n",
            "Epoch 993/1000\n",
            "809/809 [==============================] - 0s 118us/step - loss: 3.7259e-04 - acc: 1.0000 - val_loss: 0.5392 - val_acc: 0.9600\n",
            "Epoch 994/1000\n",
            "809/809 [==============================] - 0s 129us/step - loss: 1.3959e-04 - acc: 1.0000 - val_loss: 0.5406 - val_acc: 0.9600\n",
            "Epoch 995/1000\n",
            "809/809 [==============================] - 0s 125us/step - loss: 2.7269e-05 - acc: 1.0000 - val_loss: 0.5434 - val_acc: 0.9600\n",
            "Epoch 996/1000\n",
            "809/809 [==============================] - 0s 133us/step - loss: 5.0716e-04 - acc: 1.0000 - val_loss: 0.5461 - val_acc: 0.9600\n",
            "Epoch 997/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 6.3526e-05 - acc: 1.0000 - val_loss: 0.5454 - val_acc: 0.9600\n",
            "Epoch 998/1000\n",
            "809/809 [==============================] - 0s 132us/step - loss: 8.3382e-06 - acc: 1.0000 - val_loss: 0.5454 - val_acc: 0.9600\n",
            "Epoch 999/1000\n",
            "809/809 [==============================] - 0s 113us/step - loss: 5.2503e-05 - acc: 1.0000 - val_loss: 0.5459 - val_acc: 0.9600\n",
            "Epoch 1000/1000\n",
            "809/809 [==============================] - 0s 101us/step - loss: 4.2470e-05 - acc: 1.0000 - val_loss: 0.5467 - val_acc: 0.9600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ac4i34v-3XD",
        "colab_type": "code",
        "outputId": "7dcdf6aa-0798-46ca-98a9-555061b432b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "pred_cnn1 = cnn.predict_classes(X_test1_nn)\n",
        "loss, accuracy = cnn.evaluate(X_test1_nn, y_test1)\n",
        "print(accuracy)#preci=0.99,0.99 lstm = 0.9934688930783733\n",
        "\n",
        "# Python script for confusion matrix creation. \n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        " \n",
        "results = confusion_matrix(y_test, pred_cnn1) \n",
        "print('Confusion Matrix :')\n",
        "print(results) \n",
        "print('Accuracy Score :',accuracy_score(y_test, pred_cnn1))\n",
        "print('Report : ')\n",
        "print(classification_report(y_test, pred_cnn1))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 123us/step\n",
            "0.9803921568627451\n",
            "Confusion Matrix :\n",
            "[[33  0  0  0  0]\n",
            " [ 0 55  0  0  1]\n",
            " [ 0  0 10  0  0]\n",
            " [ 0  0  0  2  0]\n",
            " [ 0  1  0  0  0]]\n",
            "Accuracy Score : 0.9803921568627451\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       0.98      0.98      0.98        56\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       1.00      1.00      1.00         2\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.98       102\n",
            "   macro avg       0.80      0.80      0.80       102\n",
            "weighted avg       0.98      0.98      0.98       102\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqv5FB-7Sylf",
        "colab_type": "code",
        "outputId": "db544b4a-cdc4-4504-e821-4e203ef29bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(cnn, to_file='drive/My Drive/BE FINAL/nsl-kdd_final-code_results/nsl_model.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAQJCAIAAADU6CPoAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsEF7jyRS8ni",
        "colab_type": "code",
        "outputId": "aa73056b-f74e-4bc6-c94f-5da7a8d1d268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n540eAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2dd5hcVdnAf+/M1iSbbHpILwRCSCCE\nJYRmQCkhCIiigIB0BOUDRNRYwaAUFRAQFZCOEIqAoUYEQpGQRkJ6r5u6SbYl2TY75/vj3LtzZ3Zm\n+93Z3Xl/zzPPvffcdu7cmfOet5z3iDEGRVEUJXUJJLsCiqIoSnJRQaAoipLiqCBQFEVJcVQQKIqi\npDgqCBRFUVIcFQSKoigpjgoCRWkAIjJURIyIpDXg2MtF5NPmXkdRWgsVBEqHQ0Q2ikiliPSKKV/o\nNMJDk1MzRWmbqCBQOiobgIvcDREZC3RKXnUUpe2igkDpqDwLfM+zfRnwjPcAEekmIs+ISIGIbBKR\nX4lIwNkXFJE/ichuEVkPnBXn3MdFZLuIbBWR34lIsLGVFJH+IjJDRPaKyFoRucazb4KIzBeREhHZ\nKSL3OeVZIvKciOwRkSIRmScifRt7b0VxUUGgdFQ+B7qKyGFOA30h8FzMMQ8B3YDhwCSs4LjC2XcN\n8HXgKCAPOD/m3KeAEHCwc8zpwNVNqOd0IB/o79zjThH5qrPvAeABY0xXYATwklN+mVPvQUBP4Dqg\nrAn3VhRABYHSsXG1gtOAFcBWd4dHOPzcGFNqjNkI3Atc6hzyHeDPxpgtxpi9wF2ec/sCU4CbjTH7\njTG7gPud6zUYERkEnAD8zBhTboxZBPyDiCZTBRwsIr2MMfuMMZ97ynsCBxtjqo0xC4wxJY25t6J4\nUUGgdGSeBb4LXE6MWQjoBaQDmzxlm4ABznp/YEvMPpchzrnbHdNMEfAI0KeR9esP7DXGlCaow1XA\nIcBKx/zzdc9zzQSmi8g2EfmDiKQ38t6KUoMKAqXDYozZhHUaTwFejdm9G9uzHuIpG0xEa9iONb14\n97lsASqAXsaYXOfT1RhzeCOruA3oISI58epgjFljjLkIK2DuAV4Rkc7GmCpjzG+NMaOB47EmrO+h\nKE1EBYHS0bkK+KoxZr+30BhTjbW5/15EckRkCHALET/CS8CNIjJQRLoDUz3nbgf+A9wrIl1FJCAi\nI0RkUmMqZozZAnwG3OU4gI9w6vscgIhcIiK9jTFhoMg5LSwip4jIWMe8VYIVaOHG3FtRvKggUDo0\nxph1xpj5CXb/H7AfWA98CjwPPOHsewxrfvkS+ILaGsX3gAxgOVAIvAIc1IQqXgQMxWoHrwG3GWP+\n6+ybDCwTkX1Yx/GFxpgyoJ9zvxKs7+MjrLlIUZqE6MQ0iqIoqY1qBIqiKCmOCgJFUZQURwWBoihK\niqOCQFEUJcVpd6lwe/XqZYYOHZrsaiiKorQrFixYsNsY0zvevnYnCIYOHcr8+YmiARVFUZR4iMim\nRPvUNKQoipLiqCBQFEVJcVQQKIqipDjtzkcQj6qqKvLz8ykvL092VVqNrKwsBg4cSHq6Jp1UFKV5\ndAhBkJ+fT05ODkOHDkVEkl0d3zHGsGfPHvLz8xk2bFiyq6MoSjunQ5iGysvL6dmzZ0oIAQARoWfP\nnimlASmK4h8dQhAAKSMEXFLteRVF8Y8OIwjqY39FiB3F5YQ126qiKEoUqSMIKkPsKi3HDzmwZ88e\nxo0bx7hx4+jXrx8DBgyo2a6srGzQNa644gpWrVrV8pVTFEWphw7hLG4IfhpSevbsyaJFiwC4/fbb\n6dKlC7feemvUMcYYjDEEAvFl75NPPuljDRVFURKTMhpBMli7di2jR4/m4osv5vDDD2f79u1ce+21\n5OXlcfjhhzNt2rSaY0888UQWLVpEKBQiNzeXqVOncuSRR3Lcccexa9euJD6FoigdnQ6nEfz2jWUs\n31ZSq7yqOkxlKEznzMY/8uj+Xbnt7MbOS25ZuXIlzzzzDHl5eQDcfffd9OjRg1AoxCmnnML555/P\n6NGjo84pLi5m0qRJ3H333dxyyy088cQTTJ06Nd7lFUVRmo1qBD4zYsSIGiEA8MILLzB+/HjGjx/P\nihUrWL58ea1zsrOzOfPMMwE4+uij2bhxY2tVV1GUFKTDaQSJeu4FpRVsLy7j8P5dCSaw0/tB586d\na9bXrFnDAw88wNy5c8nNzeWSSy6JOxYgIyOjZj0YDBIKhVqlroqipCYppxEkM3i0pKSEnJwcunbt\nyvbt25k5c2YSa6MoimLpcBpBvSRREowfP57Ro0czatQohgwZwgknnJC8yiiKojiIaWcDrPLy8kzs\nxDQrVqzgsMMOq/O83aUVbCsuY/RBXUkLdgxFqCHPrSiKAiAiC4wxefH2dYwWsSFoRgZFUZS4pI4g\nUBRFUeKigkBRFCXFUUGgKIqS4qScIGhfrnFFURT/SRlBoL5iRVGU+KSMIPCTlkhDDfDEE0+wY8cO\nH2uqKIpSm9QbUOYDDUlD3RCeeOIJxo8fT79+/Vq6ioqiKAnxTSMQkSdEZJeILE2wX0TkQRFZKyKL\nRWS8X3VJJk8//TQTJkxg3Lhx/OAHPyAcDhMKhbj00ksZO3YsY8aM4cEHH+TFF19k0aJFXHDBBY3W\nJBRFUZqDnxrBU8BfgGcS7D8TGOl8jgX+5iybxztTYceSWsVdq8NkhsIEM4LQ2Pl++42FM+9udFWW\nLl3Ka6+9xmeffUZaWhrXXnst06dPZ8SIEezevZslS2w9i4qKyM3N5aGHHuIvf/kL48aNa/S9FEVR\nmopvGoEx5mNgbx2HnAs8YyyfA7kicpBf9UmGt/i///0v8+bNIy8vj3HjxvHRRx+xbt06Dj74YFat\nWsWNN97IzJkz6datW+tXTlEUxSGZPoIBwBbPdr5Ttj32QBG5FrgWYPDgwXVfNUHPvXR/BfmFZYzq\n15WMtNbxkRtjuPLKK7njjjtq7Vu8eDHvvPMODz/8MP/617949NFHW6VOiqIosbSLqCFjzKPGmDxj\nTF7v3r2TXZ0Gc+qpp/LSSy+xe/duwEYXbd68mYKCAowxfPvb32batGl88cUXAOTk5FBaWprMKiuK\nkoIkUyPYCgzybA90yjoMY8eO5bbbbuPUU08lHA6Tnp7O3//+d4LBIFdddRXGGESEe+65B4ArrriC\nq6++muzsbObOnRs1QY2iKIpf+JqGWkSGAm8aY8bE2XcWcAMwBeskftAYM6G+azY1DfXe/ZXkFx5g\nVL8cMtKCDX6GtoymoVYUpaHUlYbaN41ARF4ATgZ6iUg+cBuQDmCM+TvwNlYIrAUOAFf4VRdFURQl\nMb4JAmPMRfXsN8AP/bq/oiiK0jDahbO4ITTUxNVRks61t5nlFEVpu3QIQZCVlcWePXvqbBw7UtI5\nYwx79uwhKysr2VVRFKUD0CFyDQ0cOJD8/HwKCgoSHnOgMsTe/VVIUWaHmLM4KyuLgQMHJrsaiqJ0\nADqEIEhPT2fYsGF1HvPawnx+NONLPrz1ZIb16txKNVMURWn7tP+ucQORDmUcUhRFaTlSRhC4qJNV\nURQlmpQRBG7CURUDiqIo0aSMIHBRhUBRFCWalBEEUjMHgUoCRVEUL6kjCJylagSKoijRpI4gUB+B\noihKXFJHEDg6gWoEiqIo0aSOINBhBIqiKHFJGUHgYtQ4pCiKEkXKCAJ1FiuKosQndQSB6yxWQaAo\nihJFyggCVydQ05CiKEo0KSMIVCNQFEWJT+oIgmRXQFEUpY2SOoJAdByBoihKPFJHEDhL9REoiqJE\nkzqCQG1DiqIocUkZQeCipiFFUZRoUkYQaNI5RVGU+KSOIKhJOqeiQFEUxUvKCAJUI1AURYlLyggC\nzTWkKIoSH18FgYhMFpFVIrJWRKbG2T9YRD4UkYUislhEpvhYF2dNJYGiKIoX3wSBiASBh4EzgdHA\nRSIyOuawXwEvGWOOAi4E/upbfZylagSKoijR+KkRTADWGmPWG2MqgenAuTHHGKCrs94N2OZXZTRq\nSFEUJT5+CoIBwBbPdr5T5uV24BIRyQfeBv4v3oVE5FoRmS8i8wsKCppUGdFsQ4qiKHFJtrP4IuAp\nY8xAYArwrIjUqpMx5lFjTJ4xJq93797NuqGahhRFUaLxUxBsBQZ5tgc6ZV6uAl4CMMbMBrKAXn5U\nJpKGWiWBoiiKFz8FwTxgpIgME5EMrDN4Rswxm4GvAYjIYVhB0DTbTz1ozJCiKEp8fBMExpgQcAMw\nE1iBjQ5aJiLTROQc57AfA9eIyJfAC8Dlxq8uu05MoyiKEpc0Py9ujHkb6wT2lv3Gs74cOMHPOriI\nTlWpKIoSl2Q7i1sNHU+mKIoSn9QRBM5S5YCiKEo0qSMIdKpKRVGUuKSQIEh2DRRFUdomKSMIXNRZ\nrCiKEk3KCAJNOqcoihKf1BEEmnROURQlLikjCNCpKhVFUeKSMoJANQJFUZT4pI4gcFdUEiiKokSR\nOoJANMWEoihKPFJHECS7AoqiKG2UlBEELuorVhRFiSZlBIFoGmpFUZS4pI4gqElDrSiKonhJHUGg\nU1UqiqLEJWUEgYuKAUVRlGhSRhCoj0BRFCU+KSMIghUlDJKdYKqTXRVFUZQ2RcoIgu4rn+eTzB8h\noYpkV0VRFKVNkTKCwB1ZLKoRKIqiRJEygsCI+6jqJFAURfGSMoIACQJgwuEkV0RRFKVtkTKCQALO\no6ppSFEUJYqUEQSuRoBRjUBRFMVLCgkCVyNQQaAoiuLFV0EgIpNFZJWIrBWRqQmO+Y6ILBeRZSLy\nvH+VcR41rKYhRVEUL2l+XVhEgsDDwGlAPjBPRGYYY5Z7jhkJ/Bw4wRhTKCJ9fKtP0HEWq49AUdo2\nO5ZAdnfoNjDZNUkZ/NQIJgBrjTHrjTGVwHTg3JhjrgEeNsYUAhhjdvlVmWDACoJwtYaPKg77dkHB\n6mTXQonl7yfCg+OTXYuUokGCQERGiEims36yiNwoIrn1nDYA2OLZznfKvBwCHCIi/xORz0VkcoL7\nXysi80VkfkFBQUOqXPsaTtRQOFzVpPOVDsifx8LDxyS7Fh2bRc/D7rW1y4vz4R+nwiOT4OGJ8OYt\nUF5iPwDVbSQDwLzHYeXbsHUBPPtN6KCZCRpqGvoXkCciBwOPAv8GngemtMD9RwInAwOBj0VkrDGm\nyHuQMeZR577k5eU1qUsfCNhHVY1AqSFUnuwatCzhapj/BIz/HqRlJrs2sGk2vH499B8PV79vv+8P\nfw8l22DLXCjJh2Ffgb0bYf7jkJ0LGz5p3TruWArp2dBzRPz9b91il10H2voWboLeh7Re/VqJhgqC\nsDEmJCLnAQ8ZYx4SkYX1nLMVGOTZHuiUeckH5hhjqoANIrIaKxjmNbBeDSaiEYRa+tKK0jb44hl4\n+1aoKIWTbklePSpKoboKPnvIbm/7Au7oGYnYcxvVPqPhezOg6gDc2R8+uReCrgBrhVnGy4rg7yfA\nQUfC9z+O3heuhqqyyHZJvlOtVqiXMfDRPbBlDpx6u62fzzRUEFSJyEXAZcDZTll6PefMA0aKyDCs\nALgQ+G7MMa8DFwFPikgvrKlofQPr1CgCjo/AVKuzWGmn7HNcaF0SxFS8ebNdehuw1qJiH+xZC5k5\n8JDHvt/vCDjmKpj/JBzYA8MnwbkPQ+lOyOxiG9aMzpHjv/FX2Lveag7VVRCsr5lpBjuX2uX2L2vv\nm9Yj/jnVlf7Vx2XDRzDrLru+7gP47stwyOm+3rKhguAK4Drg98aYDU7j/mxdJzgaxA3ATCAIPGGM\nWSYi04D5xpgZzr7TRWQ5UA38xBizp6kPUxdu1FC1pphQ2gvlJfDctyCnL3Qfanv8gTS4eUl04wlQ\nXhxZz+jUqtUE4MVLYP2HtcvPvAeGHA9HXx5dntM3ejvvSljyCow+F+Y8Ysv+82vIuwJ6H+pLldn4\nqV12jhGsdU1aUlaUeJ8x1vyVnt28eu1ZZ5fXfwbPnW+1vG3ftULo0LNg4NHNu34cGiQInJDPGwFE\npDuQY4y5pwHnvQ28HVP2G8+6AW5xPr4SdExDRscRKI0hVGH/iKf8qnbj5RfFW2H9LNtjzZ9rywLp\nNj2KCVvH5bCvRJ+zd0NkPT1GSPhNuNr2YgEmfB/KCmHJS3Y7q1vDrjHlXph8t9UAXEE2529QUWK1\nhJbAGNvIzn7Ivtdti2x5rFCtriOg5KkpMOhYOPtB6DMq+pyXLoNN/4ORp8PE62BAExvs4nwr8HuP\ngvGXWjPRrLtsWbdByRMEIjILOMc5fgGwS0T+Z4xJoiGycbimobAKAqUxrHnP9sTLiuCCOpXg5rPx\nf7DkZVj4HLjRbUNPgm8/BWlZULkf7j0Edq2MCIKSbdClL5TuiFwntmHzi3A1lGy19TVh+OZjcMR3\nYPHLjRcEgQAEHP+AV5C1pE/v/Wnw6X22QfVet3CD1b6yutrtUD2mtS1z4JGT4ILnoGgzfPxH2Lcz\nsn/JS/aTO9h2ID65F0afY99ZvyOsUzwRxVttHTNyIBCEr/wUhk2CfmMa/l02gYaahroZY0pE5Grg\nGWPMbSKy2Lda+UAgqNlHlSaQmWOXB/b6d49Nn8Hsh2Hlm7bBP+zrdjBVRSmcNi3SAGR0tvuLN9vt\nbYvg0ZOh7+G29+jiRgytngnv/AyOuhj6joGRZ9gGtyVY9jq8fBlk5UK5Yy4ZcoJdenusWfVFmcfB\na9pqrr9j6xd2gNqRF8Kif9qym5fY9/nlCzD7L7Zs5i/gXGe9qgHRZNWV8Px3ostOuNkKwoKVsPCf\nsO59eO1au+/jP9rPMVfDWfdaAbLyLatBbJoNwxyB/8m99vhjv2+XwTQYekKzvoKG0FBBkCYiBwHf\nAX7pY318QzUCpUkEM+yyrNC/e/z7Bti7Dk7+OZxwU2Ibs4j1FbgmjVVvA8aakHYutUIiVB6JznEb\nqg9+Z5fnPQpHXtC8upYV2RDV939rt10hcOHz0M0ZJtRjOJx1H+xa3jTtJN0jCA7EuAx/2wNGngbf\nfTH+uYUbYV8BDDrG+hg+e9CWv3GjXZ7+O+ja3376/R6Wz7CCtdxj+68vrPirv4acfvDvH9rtoy+3\nn/5H2e2+h8OYb1ltbfNsyB1ihc7il60ALS+JaEwZXaxGt+w1GH6yDaPNHQxf+3XddWhhGioIpmEd\nu/8zxswTkeHAGv+q1fLURA2pIOi4rP0vfPkifPPRlgvzc000FaUtcz2wETMLn7UN3vjv2SiZk38B\nJ/+s/nNHnm57ses+gAVPQU5/OPFHsGMxHHcD/PXYxPm01r1ve6xN+W5CldYhvGam3c7oApX77Pp3\nnoVRZ0Uff8xVjb+HS/ehkfX9u6P3mWpY/W7ic/92gq3XbwojQsCrtYyMjb5xHMNpjvCddXdt4RPL\nqLOgz2FWYJdsh2Ovsz33WLr2twIBYGAeHHYOPH9BRAhc8BwcOsXe74Fx8MZNtvych+q+vw801Fn8\nMvCyZ3s98C2/KuULNc5iNQ11WJ5zfpJn/7nl7OSu47Al5ErBauv8dXuSADN/bpeDj23YNXoMtz3+\nZ8+z2wPy4FjH/FC4yS5NtXU2x7L4Reg+DE75ef332Vdge/4jvgr7C2DFDCsEjrgAJl5ve79bv7Bm\nqL6HN6zuDaX7sMj6fk8mgeLYYUhYIZqVC52ccE9XOP1ppF0eez2ceTcs/7dNRR8bgeRGCAXSrAnJ\nDdusC9cMN6aRTeDwSTB1k31/Jdsig9i69IGv32e/78l3Nd3J3Awa6iweCDwEuMaqT4CbjDH5flWs\nxRF3QJlqBO2WUKV17NUXTnhgb92CYMMn8L8/N+yeNREkLSAJEqWzGHO+dQo3hK4xWVq8I2IdrZe9\nG6KFDVizUTAzEjtfH//5FSyeDrPujC4/75GIRjHAp3xAgQD8qgA+/gN8/CeoPADv/sw67WN58Cir\nFf14hW3UJWAb2gO7oXPviK19dGyaM4dRZ8HcR6yW8WUDkh93H9Y8bdP138SOZD7yQvtJEg31HD0J\nzAD6O583nLL2g6ahbhif3AvPXxh/kI1LeXF0uGJrsPRVO1Dp4Qn1O27rsuevfBue/ro1I8XytxNr\nNzauacj9/RRtgRVvNLzeLt6oHpcr/2Mdl+c/HmnE62PAeJuZM6MLdOoFR18R2edOvhRPG0jLtOfG\nq4dL8dZIDPvm2ZHr9R4FPUbApa+1zshagLQMa1vHwJ0H2ffSx6N5bPzUOsoBSrfZ5Qd3WCFw7PVw\n2RtwywroMSz2ytGc4Qi6sji/qXMeguP/L7os4FvC5qTS0KfqbYzxNvxPicjNflTIN8R1FqtpKCHh\nMLx/B2Bg9TtwwT9tBEssT5wJu5bBbUX+NQzlJdYu322AjRx5xdPg7d0QMQXEI96f2mXhczbFwZXv\nwp/HRMor98POJTDj/6zd3sUdSeo+57+usuGDP17duHEF8QRrQ81BXjr3ghsX2WimWOHhbm+dH//c\nnINgdx2uvftH2+XtxVC6HY6/ASb+wDozW0sAeBnzTesLCQStSWrkafDEZBtx81SMT6K6yo5eHnKi\nNa80tL7BtGgfgpfBx1sfgJezG6hJtjMaqhHsEZFLRCTofC4BfBkB7Bs1piEVBAkpyQcMjLvYbi98\nLv5xu5bZZeFG/+ry2Fdtw1RWZG23Xoo21T7eOxrUzWAZj92rbM841sTi9pRje3zvT3NWnIYl4KQ8\nmP9EndWndCfMfcymXgBry/Yy8Qd1n18X2bnxNQiJUzbmfGdfwEa67NthBX5dhCqtAMzIseckQwiA\nNe99+0n41j+sEADoNzY6Zt9l6au2A3DcDxtf36oD8cu7HmQ1E5eLXoShJzbu2u2EhmoEV2J9BPdj\n3eyfAZf7VCd/qJmqUk1DCdnt5OYf91074GbDxzaSIS3LpgqA6EZk+6L6Ve+mssfpuf7z/EhYnkus\n6ef2bnDY2ZHtqjI7EOyf58Ph37QNf96V8MKFNh/O4d+sHU9f6vT8MrtGynatiAg79/eTOxg2eeoX\nS1U5PH12ZERwdncYe37E5AJw5h8jDt6WJN4Ygc697DLvSujSz77XA3ugYAUMmhhp6Co9jaH7/WZ2\nafk6Npe0zPiDzNx4/YO/1vhrxuYPGnoSbPzECqKgJ4trRR0djHZOgzQCY8wmY8w5xpjexpg+xphv\n0O6ihlI86ZwxNpdLXfnU131o4+b7jbWNb+l2G6I45+92f3G+7VG67Fzma5UByJ8Hcx+NLqs6YMMK\nizZHyrx2+6r9kTwyy161js//PWgFG9hIGICTbo008K5GkJljr/vGTfCUxyzm9jKr9tul109hTMT3\n9MUzVggcfKrddhvVveutzfvoK+wALz+IpxFk5sAvdzgpMvrZsk2fWmHlNbd5o3MKVthlRhsUBIE6\nktB9/f6WSb998ctwqzOHglcjiE3r0YFozjDDdpNeAqj5w6fsVJXr3rf27Q/uiJTFxsaveMM2klnd\nYPgp0fsq9sH9h0dCNKH+eOumEs904Y2qqSqzz/LnsfEdx1VlkQb4FGf84+dOvpq+Y2HwRLsugUgj\n7trOizbZ6y54ykaeuLgCw+05e5/9jZtsuGLBKptzp+fBcOELdp+bpGzfThtm2ZKhrbHEMxcF0m28\neyBgfQRgNR2wI5m/fNFue+P1X7rMLtuiRpAoG2nfMVbraQnSs6FLb+d+jmDJ6R8RpB2Q5giCJBkO\nm4jTo0u5cQSVB2w2x/1Ow+XGYu9YCncNtLZVl307I6GZ3oRaEGn4di2PlNWVibE5vBkTh5CVC4Mm\neOqyNxIZE89fUOloDH0Oh0k/tT4PV62//I1I714CgLFpGD66u55KCSx6Ada+F6kDQHUIvnjafj8P\nT7DRNj1H2p5keqeIEzIc8jelMsTXCLwDnbo6gsBrpnrtWvjrxIjdffBxkTpn5PhTz+aQSCPoOyZ+\neUM46hK7/N6/7QhpL21hgp9WoDmCoH1N9eVGDZkUEgShSjvhxzs/tcnMvLg2cdfsYow1GwU9qvBV\n79n8NBBtOgA765RfaRe+eDp6u1OP6B7ryrci66VxHIcf/g5WvRXJ2z/6G5F92d0j624v/8sX6q+T\nBOD16yLbrmDcuiD6uAN77KAvsD3L2X+x32s4FL+hbkkSaQQuXfra54gXwVTidBC+9Y9IWd/RLVs/\nP2mOr+rsB635bPjJtUdI1/wf2ldz11jqFAQiUioiJXE+pdjxBO0H1zQUSpEZyjZ8DL/rTc0P2GtP\nh0hPZ/Nsuzyw1x7rdY4NmhD5Y/zD44Q74Sbo1DN+yF1TWPySHfkZqoQvp9fen90D+o+LbBd7nqWu\nnrzrDxk0wabvPTcmnbGrGTTEVCMxf5VQmdU8Cp3xFDcssCGOEGmUXGGx8DlrfvI7Bj2uRpAevT7k\nhPiO7gVPW6GR0x+unWVDh7u2o794c3rugWDi/E4pohHU+cs0xrRB3bCJOH/k6o40oMzt2cWbyu61\n66O33YFRLrGREo85PgGvcwzi/xG69LVD5BNFztTHzuU2/PLMP9jtV6+xSwnGj+rKzrVO1hFftQ7c\n4i02b8uKGfE1ApfjfhA5/0dxRtS6giC9jolcjrnGak/x4u8P7ImEtnbtb0NCl71ee8RtIM0RBH5r\nBHH6dbHCx40iimXnEhsRFQjYQIHYSK22jl9C1tUI6pqspgPQQjlp2wHOnzDU3qKGwuHEP8JHvmI/\n8Yi1R9cIQOda3sk3qsojtvZgjCCI3Qbb6GV3b7iPYM86eOPmSB2e/w7Me8yaIz7yzG+UyJGf2TWS\nedNtTI+5ypqt3FGlYH0CxztZJsddEh1SGg+3l+9ec8y3avf8TdhqS7tXRcpcwbF/l9Vgeh1qUyf3\nHwe/2BrJFTPlT5HnMq0gCOIR+zsI1tHDjR1b0SZJ8F8YkOfP7Wo6QioIOgbugLLqdmQaqiiFad3h\nfw/YbWOi471dirZE5rN1cfPoT77HZlZ0G2ETRxC8fLnnxJgYgHgaQY/hzmjM4voHJ4HNW7/gyWhH\nM9jG1TXtfOUnic/3Rq9cNN0+0/CTa5u7TvlFxAfQkEk83Eb/IMfsdO7DNo2Cl+5DYPNn0WVpWXa5\neqaNLJr008g+b8PrOiHLilrHRxCPWOdqrMbnpT2ZgrzcugaGHOfPtV2zYbz/XQcidQSBozqa9iQI\n3MZ9wVN2+b8HbN6V2JDJv+4DVMoAACAASURBVB4H98ZE+RRttpNgTLyu9oxMEG0aWv1OZD22Vx5X\nIxjgNLgGKopr74/FtdW7jZIrjD71DNc//kabOiEe3kFefQ6zzwS1Z5IyYTjyIhj1dTjpx/XXyxV6\n1ZXWLJLuEZj9j4Kv/sqmGI4Vjm7CsI/usc/kjnqNJS3Lfn/lRa3jI4hHYzSC3of5W5eWIJ527AYF\n+EEfx2HuhpN2UDpmBqV4tEdB4DbebgMy9zG7LCuMzrVTGTMeoGKfbXy6DbTbQa8gMNHXrnXPBpjO\n0jIj0+2VFUZH4sTDFQSx99z4iV3essJOE+j20NOyoxv5RAObQh5hFkiHQ86wdbvwn/U/A0Tut2KG\nFQQAvQ6xy2OujvTo3e/szD/YdzHiFJv1EuzMUom0DxGP5hRKjmkoVvjU5fwc6JN5pT2TlglXvGOD\nDTowqSMI3J5RrNO0LbFvV3Tvxp2mz/0zu1E69c2gdJdj63Ub0EBa7RHFn94f/9zY8Np44bbBzEjj\n3xA/gWuGSjSq2TVJZHaBW1banvnMX9jnX/Zq4oFN1Z7rnfuXxkd4eP0BrpkpdxD8enf8mP9xF9u6\neIXleY/WPs5Ldq79jkw4ORpBrCO8rrEMfqWV9oOjL49oyn4z5PjWuU8SSR3TkGPikLYqCNb+145O\nXf2fSFmlk87AbUDcSTfmPBL/GmVF0TZ7NyRuf0HtPCkFKyPr7ohTqG0aiqchBNMjc9GWFdp8PB/9\nAe49LL4t1TVD1TcpONhBT9m58I2/RgRAIo3gDE+u/KY0somSkyVqLF17cSAIP1kHv95Tv8kgqxss\nf91+/7GO6NYgq2v0diLT0ODjfJ0cvcXp7KM5KAVJHUHgNBRS3UYFwRYnSdm2LyJlbhx6rEnhi6fh\n6XNqX+OeIdGZFF2nZixeO+tB4yKDy6C28zeeRiAS0Qj2rLPT7H34exvBs2dt7eNdTaCqHDZ/Hr0v\nr44pDd3zEsV4H3mhzYsETRQEnp9/Xee70TRewdG5V/zpCWPxTt6eDI0gMyYCPJGzeNgk/+vSInTs\n6J1kkYKmoTbqI3AFlNvoh8Pw0qXOvkobfullw0fxr+Nt1OM1oMZEO5tj8/rH5tivNcergysI3kkQ\n7bPqHdvwffzHiA9j/hN2xK+XrgfVPtfFNY3VZfJxe7hNSd/g/S3U1UhfO8uOXWgKrp8GWsdHcNo0\n2LUyMttWrCBIpBEkK9V0U2lv9W3jpI4gcCNW2qpGEOsY9mb53LW8duhlImZ4ZlRKpBF4RwR36hlZ\nz+xq4++9JOpB1hWpYYxN+RzLtoW1y46/KfF1XI0g0XNARNg1xezi1XbqymrZpU/TI1Mm/dSGzkLr\naAQnON/n4hetmS8zxjSUSKgWxsnZ1BY55hrInw8Tro0eg6I0i9QxDTk9xoCporyqDQ4qc23xboO0\n6bPEx9aFmzICEptUnpgcWfc2ToedHX90ajxEoicZ95Io9UR1jLO4U8+649pdp3hdGoHb447NhdQQ\nvP6Phph5mkLX/pFBbq05jsCdoD5WEMQLB87uHj0rW1umc0+45JXEI6SVJpE6gkCEsKSRRoiiA21Q\nK4jVCOLNO1sfsXHg8XrJ+3bZEbEubirqLn3h1N827n4l2+IUJhj0BrXTVtfnnHTNGrGNmZcRTg6k\nzk2I8/YKgro0gubiRu60Zgr0r/zETjkZK+DiCdWfbfRvQJaffO03dl5hpdn4KghEZLKIrBKRtSIy\ntY7jviUiRkR8DWQ2gTTSqKbwQGX9B7c24RgfQaLZkBL1wk+7A74ZE00UL1xzi8dZe+YfIs7lcx5q\n/KCZeDbv6lDiqf8guv51NfBgs0KecWckZUM8jvg2XP8ZHDI58TGJ8DbMfpptXM2sqgFRU34TTyNo\nr5z04/ajybRxfBMEIhIEHgbOBEYDF4lIrby2IpID3ATM8asuLiaQRjrVbVMjcH0XrtMz0by77qQq\nYCdZcenSN9reP/GHNtNkXfQ+NBKG1xRVO57GUV0ZCXuNx6FTIuv11a9zz4bNQdv38KY5D8OtJQgc\njaBNCgJ1uir+agQTgLXGmPXGmEpgOnBunOPuAO4B6hkl1QIEM0gnxIHKNhg55DZKn95vM2qu/9Bm\n2zzr3ujj3JGvAMM9IX9HfMeOyHWZfGf9du9gJkz5A5z3SN297mtn2fw+3lBIiG/zDldFawQHx6Rf\nGHK8tZmfdZ+NcEkmURqBj3+FtqQRxJqGkjHaWWlz+CkIBgDemLt8p6wGERkPDDLGxMQURiMi14rI\nfBGZX1DQBKegSyCdNKo5UJlkZ3Gowk5r6MU1DRVuhHudxj69U/RgL4ieOMPtxfYcaXvEiZzDiUjL\nsHb6I+NE+Hjpf5TN7/PjlfALT3jq8DiZT6srYcMnke2DT7UjdV16DIfT77DZQ/1y0DaUqMFyPvaM\nawRBG0hcFqsRJGOQm9LmSNqvQEQCwH1AvdnBjDGPGmPyjDF5vXs3I/lTMI10qaYs2YJg1t12WkPv\nlIHxxjcYE5nt6vTfW+efO5XkwAkRQeD28uoKs4xHY+3F6dk23bJLvPQKi16AWZ4Rv9m50WaX7kMa\nd08/8WoEfjaIbck0FKsRdKT5OZQm42eXbCvgzdQ00ClzyQHGALPE2nf7ATNE5BxjzHw/KiSOaagw\n2aYhd1arLXNs6N68x2HrF7WPC6bbbJs3LrK5+F1+usE2ym72Ttev0FjzRl2ZKBtCRpwJXdxnc+k+\nNNp+79fE7U3BO4raV0HgaAQNSbHhN67wdycBas1IJqXN4qdGMA8YKSLDRCQDuBCY4e40xhQbY3oZ\nY4YaY4YCnwO+CQEAScskkyoOJHscQSfHMVu5H96+1c6xG28SdvdP22NYdGPaqYdtXNyedn3x6afe\nHr/cj8nUY3u9/cbGP64t0FoaQR8nrHfM+f7do6G47zxR/iYlJfHt12+MCQE3ADOBFcBLxphlIjJN\nROIkyvEfyehEllQm3zTkmoEkEInjj8dBR9R9HdfRV1/Ey2Ger1sC0NVNe+BD3pbCjZH1qVvalgYQ\ni9cc52fKgpx+cFsRjL/Uv3s0FFfgteX3orQ6vnrrjDFvA2/HlP0mwbEn+1kXAEnPppMUJj981G2A\nTDjxqNm+Y20IaF3UaAQeeX7lzNrpELw9/9sK4ckpUJLvzyAqr0O0rrmA2wLhVtIIoO3kxqkRBG38\n3SitSurkGgJIy6JnRohP1+6u/9iWZMkrMGhCZPITN8eNCSd28A6fVL/N3x2Z67U9e8cZuMQ6hb/z\njE17nevzZBvJjgqqD9NKPoI2hSOQ3E5EfZMKKSlBG/+ntjDp2XQJhlp3ZLEx8K+r7ICvW1fbMjc/\nf10RG4lGFntxB5DFSxXtJVbYdO5Vf8hoY/n6/fDmj1r2mn7TWj6CtkSvQ2zCtmOusRlVveNSlJQl\nRX79DunZZJhK9pWHMPHmPvUDt9Hft9Mu130IS16266baCgiAaz6MPq8hk2W7E7ek1TN+oDUcg01J\n8ZBsvIJ44vXJq0drEgjAlD9C70Pg4K/5rxUq7YLUEgRpWWSYckJhQ0Wonl50S+GdVrKqDJ77VmQ7\nXG1TS2R3h96jEp+XiC797PLgr9V9XGuYaJIx6UpzGfvtyPq47yavHoqSZNrhv7cZpHeic+VuMqmk\ntDxEVnorDK/3TrA+97Foc4QJ2wY/Lav2UP+GDD7qMwp+ONeOLE42XkFw+u/szGdtnfoEqKKkCKml\nETiTpB8XWE5peStFDnlz8FfH+CZMtZ12snR77bEADdEIwI409jNPTkPx2tgPnQLDTkpeXRRFaRRt\noAVpRcZ8E4A+UsjaXfta557eVNCxg8bKPBO4xGoEY9vA4KPGEEizE9tA9PSMiqK0eVLLNOQ4ZvtS\nyIrtpZx+eD9/7/fU16Pj6r94Jnr/7L/Y5aCJ0XHmv97T8lkhT729/vz/zSGQBt/8h9Vu4o2NuHVN\n+/QjKEoKkFr/zLRM6NST/vuK2Nga+YY2flL/MWAzcXrxw7l7os+hnYE0W+8eCSbOaeqcv4qi+E5q\nmYYAcg7ioEAR+1tKEIQq4cO7ak/GsndD/OPj4WdPvbXQvPaK0m5JLY0AIKcffXZt4LO1e+o/tiEs\neQk+uhuq9ttomRe+Cz2HR+fkr4+sDiAI2koKBUVRGk3qCYIu/egRXsD63fvZUVxOv26NzOEfizsw\nrWA1lGyHVXXOsRMfHd2ZPK79qOERWorSQUlB01A/+kkhP0p7hX0VIbi9G8z8ZdOv5+aaXzMT7htV\n97HxOPvByHzBE74PF01vel2SwcWvwNFXJLsWTaf/uPj5mRQlhUhJQQBwU9qr9H3NGVnqRu8AHNhr\nhcMXz8CcR2HHkpa573c8EUOX/CuyfvRlkfUpf4BDz2yZ+7UWI0+Ds/+c7FooitIMUs801P+omtWc\n7Z/V3u/OsDXvcdi+yK7fXhzZv30x9BltI2TC1TDzF4nvld4pEj46+lzbe173oZ3HV1EUpY2QehrB\nwDy2fvXBxPvdXHTxpvDbVwCPnASvX2e3dyyJJJOLx4k/gktfhxsX2u2Rp8HkOxMfryiKkgRSTxAA\nmZ3jROmUFcGr34cDTjRRKE6q6n077HLJy1C4yeb0r4vcITDilMgE9IqiKG2Q1DMNAV275tYu/PQ+\nWDwdyh0zkDdHkMt+z4Q2D9QzjSRAl95Nq6CiKEorkpIaQUanOBrBxv+5O+3SO/euy4FGjj3orIJA\nUZS2T0oKgrgTtWydb5fxJpMv2W4/62fFv971syPrvQ+Dn6yzvoF+Y5tdVUVRFL9JSdMQ2T0S79tf\nULusvvEB3YdG1gNBOy5gxClNqpqiKEprk5oaQZfeNhtmPPbFEQR1cfIv7KAyNx//oGObVzdFUZRW\nJjUFAUCXPhxR/hhVJiZZWkl+w86ffDd0HQATrrF5dm4rhOs/s+WKoijtiNQVBMBd3z2JH1Td1LST\nj7oUblkOnTxmpr6HQ1pGw84PpEHfMU27t6IoSguSmj4Ch7OOOIiZS8+C1fdF7wikQTgmTfWIr8H4\n78Gos+yYg8w4DufG8KtGmqAURVF8IqUFAUD3zlmczD+YdX4AOvWEZ86FnIOgeIs94OjL4Wu3Rff8\nW2J8QFuYZ1hRFAWfBYGITAYeAILAP4wxd8fsvwW4GggBBcCVxphNtS7kI7mdMthU0Ynq0VMICnZK\nx0POhPUfQq+RmhdIUZQOj2+CQESCwMPAaUA+ME9EZhhjlnsOWwjkGWMOiMj1wB+AC/yqUzxyO6Vj\nDOzZX0GfnKzIlI59mpBSWlEUpR3ip31iArDWGLPeGFMJTAfO9R5gjPnQGOPO7v45MNDH+sSlVxc7\n0fqE37/f2rdWFEVpE/gpCAYAWzzb+U5ZIq4C3om3Q0SuFZH5IjK/oKBlnaxDenaqWa8MhVv02oqi\nKO2BNuGxFJFLgDzgj/H2G2MeNcbkGWPyevdu2fw9Q3t1rll/bWEDxxAoiqJ0IPwUBFuBQZ7tgU5Z\nFCJyKvBL4BxjTJyUn/7SNSude799JAA/+9cSFm4ubO0qKIqiJBU/BcE8YKSIDBORDOBCYIb3ABE5\nCngEKwR2+ViXOvFOYL+tSCcyVxQltfBNEBhjQsANwExgBfCSMWaZiEwTkXOcw/4IdAFeFpFFIjIj\nweV85fD+kbTUJeVVyaiCoihK0vB1HIEx5m3g7Ziy33jW20SQfm6nDJb+9gzG3DaTkjIVBIqipBZt\nwlncFuicYZPP3fXOSj5clTQrlaIoSqujgsBBRGrWr3hyHh+uVGGgKEpqoILAw0vfP65m/Yqn5iWx\nJoqiKK2HCgIP4wbFmdReURSlg6OCwENGWoBvjY9kuXh36Q7KKquTWCNFURT/EWNMsuvQKPLy8sz8\n+fN9u355VTXzNu7llpe+pKC0gsy0AOcc2Z9+3bL48emH+nZfRVEUPxGRBcaYvHj7VCOIISs9yEkj\ne3Pc8J4AVITCvLwgn4c+WJvkmimKoviDCoIEXHHC0Fpl7U17UhRFaQgqCBJw1ODu3PGN6DmFy6s0\nO6miKB0PFQR1cFRMFFGppp9QFKUDooKgDrw5iABKK0IJjlQURWm/qCCoA+9oY4B95SoIFEXpeKgg\naASamVRRlI6ICoJGsKO4nPKqasqrdJCZoigdBxUE9XDdpBF8+2g72vjTtbsZ9et3mfTHD5NcK0VR\nlJZDBUE9TD1zFH90prL896JtAOwsqeCDlTuTWS1FUZQWQwVBA7l04pCo7auens/ufa0+xXKb440v\ntzF3w95kV0NRlGaggqCB3Hb26Jr1jGAAY+Dix+YksUZtg/97YSHfeWR2squhKEozUEHQQNKCATbe\nfRYrpk3muknDAVi1s5Rl24rZsvdAkmunNIVQdZhZOhudoqggaCzZGUGu+crwmu2zHvyUk/6gzuP2\nyN9mrePyJ+fx0eqCZFdFaQQaxt3yqCBoAjlZ6ay/cwqH9s2pKbv08Tkc/pt3df6CdsQmR5PbVlSW\n5JooDWX2uj0ccft/+GSNCu+WRAVBEwkEhDPG9KvZ/mTNbvZXVnPHW8sZOvUtZny5jcL9lcxZvyfu\n+fsqQvz81SXsaccO56rqxifhe2vxdoZOfavFGt+C0grmb2yaszo9aEeOh5rwHEpy+GJzIWD/b0rL\noYKgGXxjXH8ARvWLaAbPz9kMwI0vLOSB99dwwaOfs2BTYdR5n6/fw5jbZvLC3M28MHdzk+9vjEnq\n4LayJtz7pflbAOtfaQnuensF5/99Nmt3Nf56aQH78w+F/Usvft97q5m9Ln5nQGk8WelBACp0UGeL\nooKgGQzv3YX1d07h3Zu/wpe/Ob3W/iVbiwFYnF8E2Ib75ukLufDRz2uO2VXadI3gzrdXMOrX7yZN\nGJTHmMH+Nmsd0+sRbC3d5K7cYQXAqh37Gn1umqMRbCsqI+yDMDhQGeLB99dw0WOf139wK1FaXsW/\nF21NdjWajKu9LdtW0ir3W72zlKFT3+LzBJp9R0EFQTMJBGxj0q1TOotvjxYGriYwa5W1Z85aXcDr\nzqA0l2dmb+LDlU2LXHnskw0A7NlfWedx5VXVXPnUPL7cUtSk+yRiS2EkWiocNtzz7kqmvrqkznPc\nyX2qq1um4e2SmQbAjpLyRp8bdJIKPvbJBv79Zcs3jusL9tes3/fe6ha/fjwqQtXsLCnn4wQO8Glv\nLOem6YtqOiftjaIy6yheV9B4wd8UXNPu6wvbr/BsCCoIWpCuWeks+s1pDOvVOar8o9UF/Pr1pVzx\n5LyasitPGMZPJ9s5kF1zSXFZVZPs7sUH7J8jHDZMn7u5lsN61qoCPli5i0sfn8PaXS33B/poVaSx\naezguv2VLZPJ1bHusKsJgsBr2lq5vWVMVV427YkIygffX8Ou0sbXsbF886+fceyd7/O9J+ayPE6v\neavjm1mytZh97TCteoGjQRcesJpNSzxD0YHEHSm3o9cUM2h7QgVBC5PbKYMPbz2Z+y+waSl+coZt\n7J/9fFPUcecdNYAfnHww3xw/gLkb9rJ6Zynjpv2He95ZWeuasaafwv2VTP3X4prtojL7Q35zyXam\nvrqEv3+0rmafMYZfvGZ76SXlIU6976MWm3Jzk2f8xKIYbWPh5kJunr4woSP2lpe+THjdfRUhfvrK\nlw1ypJc6qcG/zC9qtNN3f0WIQT2y6ZKZxvrd+zHG8MmaghYLT8wvjB5fsrXQ/+gkr8lkydbavf5s\nx8b+y9eWMua2mTwX87ts6+wojgjTm6Yv4o43ljfreluLyhg37T2GTn2L376xrNb+X762FPDXj9QW\n8FUQiMhkEVklImtFZGqc/Zki8qKzf46IDPWzPq3JeUcNZOPdZ3H9pBEcOSiXIT078cI1E1n7+zNZ\nMW0yYwd2A+CEEb3Ys7+S0+//GGPgH59u4JQ/zeKZ2Rspr6rm9YVbGfXrd3l36XaqnR/jY5+sZ/q8\nLTX3euPLbZRVVvPWYmt28vZeVmwvZW+M6ejMBz7hB/9cwJa9B9i9r4IvtxSxo7icjbv3E49Ne/bz\n7tIdUWXlVdX8e9E2crKsaebudyMCbHtxGef99TNeX7SNz9btoehAJUOnvsW4af+pifaoruOP9ezs\nTbw0P5+jf/dfzvnLpwmPK6usZrPT6/58/d5awrY+du+rpFeXTDLTAry3fCcX/2MOlz4+l7vjCOOm\nsCVGEGzee4D3V+z0be7r2A7Dv2PMkAAHYrTF1xdu5fP1e1i2rdiXOrU024rKyEyLNFv5Rc0bzOn9\nzT/5v40Jjyvt4HORiF8/ShEJAquB04B8YB5wkTFmueeYHwBHGGOuE5ELgfOMMRfUdd28vDwzf/58\nX+rsJ8aYWhPdgHV+/er1pUyft4UBudnsLCmvs/eRkRagMlR/z/db4weSHhTeWbqD4rIqMtICfHfC\nYJ76bGOd591y2iHccMrBGKxAWb6thCufmse+ihDDenVm4vCe/PSMQ/n92yt4ZUE+YwZ0JVRtapy2\n8fjFlFHc+XbtxvWiCYO5dOIQhvfuTNgYOmWksWxbMWc9GN34r/n9maQHa/dZ7ntvNQ++vyaq7Lmr\njqV/bhZ9u2bRKSNY852HwwaR6MmGzrj/Ywb37MRh/XJ48IO1Ude58asHc8nEIazfvZ+/zlrHKYf2\n5pwj+5MWDNAlM41goPa7jOXyJ+eys6SCgd2zeW95JEnh4B6duPO8sUwY1oOMtECNYIj3+/CS6Dfk\nsmZnKafd/3HNdnZ6kDu+MYaiA5VcMnEIWelBTvnTLDZ4Gr/s9GBNx+HpKycw6ZDe9T5XsthfEWLM\n7TO58JhBvDA30hG65bRD+MHJI0iL8xtxMcZgTMTU4/Ly/C385JWIdv3OTSeRmRZg5rKdPP3Zxijf\n01cO6U12eoCHvzuetKD9H2aktR+jiogsMMbkxd3noyA4DrjdGHOGs/1zAGPMXZ5jZjrHzBaRNGAH\n0NvUUan2Kgjqo6C0gh6dMwgGhB3F5dz7n1W88kU+h/bN4bCDurJ6Zyk7S8rJ7ZTB2AHdEGBRfhGP\nX3YMlz0xl80eM02a82N3Bcrw3p354McnY4zhnaU72FZUxryNe5m5rPkZVM87agBjB3Rj2pvLOWZo\nd/ZXVLN8ewlXnTiMxz/dEPeci48dzGfr9kQ1SABZ6QGqqk1cbaFXlwwqqsJUVIfpmpVORlDYVlzO\niN6deeaqY7nw0dls2RttegkIdM1OpzpsqAiFyQwG6JyZRkZagOqwYWtRGZdOHMLVJw1j0h9nNfiZ\nRaBvThbBgBAIQEAEwTbkNc2MWGfxlLH9+OvFR3PHm8vjfh+9czIpLa8iOz1IZ8fx7bb1gljhBZRX\nhSk8UEn/3GyimjJnwxhqvs+D+3QhLSCs3lmK+1WmB4WuWelRgQUXHzuYf86JjvLqk5NZc//MtGDN\nb8ngNKbOvQy2YTUGwsaQmRYgFDakBwM0QEbW0JjWZ3tROWVV1Tx/9bGs2bWPF+ZujuqA9Opi6x4Q\n+04CIvYdiQ2oCAaE3Ox0Au6XamB9Ai3YyyF9u7B6Z7RvbUBuNtuLy+jVJZNgQAiFDeGwoVNmkLDT\nT8tMTyAkjH3uWJnuVInyymoqQmG6ZqfjqSoAN596COcc2b8B31ZtkiUIzgcmG2OudrYvBY41xtzg\nOWapc0y+s73OOWZ3zLWuBa4FGDx48NGbNrUvu6ZfuD1EYwxhA6FwmMw0awMuLa9i+bYSMtODDO/d\nma5Z6bXOX1+wj86ZafTqksmcDXsIVRuWby9hd2kF+Y49Oys9wHEjetKjcyZvL9nOUYNzKdxfRZes\nNLplp3PG4X3JyUpne3EZfXOyKCmvYuGWIk4+pDf7KkK8vmgbXbPS6Ns1i4Hds8lMC9I7J5PqsOHd\npTuYuWwHPTpn0KNzBkUHqhCBy44bSnZGkA2797Niewmb9x6gvKqazLQg6UGhpLyKilCYThlBLj9+\nGAf36cL+ihBzN+zlrSXb6ZOTSVlVdU0j5TYI5VXVVFWHqQyFERE6Zwa5btIIBnbvxJz1e9hRUs6E\nYT1Yub2UVTtLOVBZTag6zNcO68OzszcRCEjN97i/IkTY2HdQ7fQ2jee9GGxywusmjeDQfjmEqsPM\n31TIYf26snhrEWt27qt5ruyMIGWV1VRWh2su4ja87nowIAhij/Hcx0t6MMAhfXO4btJwRISlW4t5\nc/F2DlSGqA4bp8EOcsnEIRhjOLhPF1ZsL2V/ZYgtew+wdGsJBypDhJ3rVobCNZ0JqRF2RAm9QMAu\ny0Nh0gJCVXW40SHCjZAbDMjN5meTRxFw7vXawq1UhsKs3FFCZShMMCAYY02P7nupDkc6F8GAYLC/\nC/c5vjaqD984agCrdpTyry/yrd9gYC5nH9mf3fsqGNyzE/e/t9pqFCI1zuUthQcY2L0TaQEhzRGA\nZZXVNb89Nzw57jOL1NQBogVidnqQ9GCAfRWhGk0G53u/4JhBnDSyaVpbuxcEXjqqRqAoiuIndQkC\nPw1cW4FBnu2BTlncYxzTUDegY4/cUBRFaWP4KQjmASNFZJiIZAAXAjNijpkBXOasnw98UJd/QFEU\nRWl50vy6sDEmJCI3ADOBIPCEMWaZiEwD5htjZgCPA8+KyFpgL1ZYKIqiKK2Ib4IAwBjzNvB2TNlv\nPOvlwLf9rIOiKIpSN+0nCFZRFEXxBRUEiqIoKY4KAkVRlBRHBYGiKEqK49uAMr8QkQKgqUOLewGp\nNsedPnNqoM+cGjTnmYcYY+IOS253gqA5iMj8RCPrOir6zKmBPnNq4Nczq2lIURQlxVFBoCiKkuKk\nmiB4NNkVSAL6zKmBPnNq4Mszp5SPQFEURalNqmkEiqIoSgwqCBRFUVKclBEEIjJZRFaJyFoRmZrs\n+rQUIjJIRD4UkeUiskxEbnLKe4jIeyKyxll2d8pFRB50vofFIjI+uU/QNEQkKCILReRNZ3uYiMxx\nnutFJ/U5IpLpbK919g9NZr2biojkisgrIrJSRFaIyHEp8I5/5Pyml4rICyKS1RHfs4g8ISK7nIm6\n3LJGv1sRucw5fo2IX74NkgAABOlJREFUXBbvXolICUEgIkHgYeBMYDRwkYiMTm6tWowQ8GNjzGhg\nIvBD59mmAu8bY0YC7zvbYL+Dkc7nWuBvrV/lFuEmYIVn+x7gfmPMwUAhcJVTfhVQ6JTf7xzXHnkA\neNcYMwo4EvvsHfYdi8gA4EYgzxgzBpvK/kI65nt+CpgcU9aodysiPYDbgGOBCcBtrvBoEHZOzI79\nAY4DZnq2fw78PNn18ulZ/w2cBqwCDnLKDgJWOeuPABd5jq85rr18sLPdvQ98FXgTO53rbiAt9n1j\n58M4zllPc46TZD9DI5+3G7Ahtt4d/B0PALYAPZz39iZwRkd9z8BQYGlT3y1wEfCIpzzquPo+KaER\nEPlRueQ7ZR0KRx0+CpgD9DXGbHd27QD6Ousd4bv4M/BTwJ3JvSdQZIwJOdveZ6p5Xmd/sXN8e2IY\nUAA86ZjD/iEinenA79gYsxX4E7AZ2I59bwvo2O/ZS2PfbbPeeaoIgg6PiHQB/gXcbIwp8e4ztovQ\nIeKEReTrwC5jzIJk16UVSQPGA38zxhwF7CdiKgA61jsGcMwa52KFYH+gM7XNJylBa7zbVBEEW4FB\nnu2BTlmHQETSsULgn8aYV53inSJykLP/IGCXU97ev4sTgHNEZCMwHWseegDIFRF3xj3vM9U8r7O/\nG7CnNSvcAuQD+caYOc72K1jB0FHfMcCpwAZjTIExpgp4FfvuO/J79tLYd9usd54qgmAeMNKJOMjA\nOp1mJLlOLYKICHbu5xXGmPs8u2YAbuTAZVjfgVv+PSf6YCJQ7FFB2zzGmJ8bYwYaY4Zi3+MHxpiL\ngQ+B853DYp/X/R7Od45vVz1nY8wOYIuIHOoUfQ1YTgd9xw6bgYki0sn5jbvP3GHfcwyNfbczgdNF\npLujTZ3ulDWMZDtJWtEZMwVYDawDfpns+rTgc52IVRsXA4uczxSsffR9YA3wX6CHc7xgI6jWAUuw\nURlJf44mPvvJwJvO+nBgLrAWeBnIdMqznO21zv7hya53E591HDDfec+vA907+jsGfgusBJYCzwKZ\nHfE9Ay9g/SBVWO3vqqa8W+BK5/nXAlc0pg6aYkJRFCXFSRXTkKIoipIAFQSKoigpjgoCRVGUFEcF\ngaIoSoqjgkBRFCXFUUGgKDGISLWILPJ8WixbrYgM9WaZVJS2QFr9hyhKylFmjBmX7EooSmuhGoGi\nNBAR2SgifxCRJSIyV0QOdsqHisgHTn7490VksFPeV0ReE5Evnc/xzqWCIvKYk2v/PyKSnbSHUhRU\nEChKPLJjTEMXePYVG2PGAn/BZkEFeAh42hhzBPBP4EGn/EHgI2PMkdjcQMuc8pHAw8aYw4Ei4Fs+\nP4+i1ImOLFaUGERknzGmS5zyjcBXjTHrnUR/O4wxPUVkNzZ3fJVTvt0Y00tECoCBxpgKzzWGAu8Z\nO+EIIvIzIN0Y8zv/n0xR4qMagaI0DpNgvTFUeNarUV+dkmRUEChK47jAs5ztrH+GzYQKcDHwibP+\nPnA91Myx3K21KqkojUF7IopSm2wRWeTZftcY44aQdheRxdhe/UVO2f9hZw/7CXYmsSuc8puAR0Xk\nKmzP/3pslklFaVOoj0BRGojjI8gzxuxOdl0UpSVR05CiKEqKoxqBoihKiqMagaIoSoqjgkBRFCXF\nUUGgKIqS4qggUBRFSXFUECiKoqQ4/w9ZfWASxRnulgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjUzonIA7-eY",
        "colab_type": "code",
        "outputId": "5d70e3dd-7ef1-41bf-828f-1cf8f52824c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=4,weights='uniform')\n",
        "neigh.fit(X_train, y_train)\n",
        "# Python script for confusion matrix creation. \n",
        "\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWtGd9sTfkKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_knn = neigh.predict(X_test) # test the output \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY1cgDZmJPg6",
        "colab_type": "code",
        "outputId": "fbed08e4-cb38-4598-e7f7-8a236ef84e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "results = confusion_matrix(y_test, pred_knn) \n",
        "print('Confusion Matrix :')\n",
        "print(results) \n",
        "print('Accuracy Score :',accuracy_score(y_test, pred_knn))\n",
        "print('Report : ')\n",
        "print(classification_report(y_test, pred_knn))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[33  0  0  0  0]\n",
            " [ 3 53  0  0  0]\n",
            " [ 0  1  9  0  0]\n",
            " [ 0  1  0  1  0]\n",
            " [ 0  0  0  1  0]]\n",
            "Accuracy Score : 0.9411764705882353\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96        33\n",
            "           1       0.96      0.95      0.95        56\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.50      0.50      0.50         2\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.94       102\n",
            "   macro avg       0.68      0.67      0.67       102\n",
            "weighted avg       0.93      0.94      0.94       102\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDwIbm6D8pq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_cnn_prob = cnn.predict_proba(X_test1_nn, batch_size = 64)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqcxFr6UG4_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(y_test.shape[0]):\n",
        "  if y_test[i]!=pred_cnn1[i]:\n",
        "    ind.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrj7tCQXKuET",
        "colab_type": "code",
        "outputId": "5e35d963-681f-415b-eb3d-3a37e79771be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_test.shape[0]-len(ind))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loVcNBT3JU3x",
        "colab_type": "code",
        "outputId": "9a0fce6a-482d-4659-c0f2-f9552612dcd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "k=0\n",
        "corr=[]\n",
        "for i in range(pred_cnn_prob.shape[0]):\n",
        "  if i not in ind:\n",
        "    pred_cnn_prob[i].sort()\n",
        "    #print(pred_cnn_prob)\n",
        "    corr.append(abs(pred_cnn_prob[i][4]-pred_cnn_prob[i][3]))\n",
        "    k+=1\n",
        "l=0\n",
        "for data in corr:\n",
        "  if data<0.96:\n",
        "    #print(data)\n",
        "    l+=1\n",
        "print(k)\n",
        "print(l)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P1tbBw_HcUY",
        "colab_type": "code",
        "outputId": "bf664350-9712-4453-a77c-e6eac76d58b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "wrong=[]\n",
        "for data in ind:\n",
        "  pred_cnn_prob[data].sort()\n",
        "  #print(pred_cnn_prob)\n",
        "  wrong.append(abs(pred_cnn_prob[data][4]-pred_cnn_prob[data][3]))\n",
        "l=0\n",
        "for data in wrong:\n",
        "  if data<0.96:\n",
        "    #print(data)\n",
        "    l+=1\n",
        "print(l)\n",
        "print(len(wrong))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rx4APB-ISNG",
        "colab_type": "code",
        "outputId": "07607f7e-54d3-4077-d4d6-dc88fc999b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "error_index_nn=[]\n",
        "error_index_nn_X=[]\n",
        "error_index_nn_Y=[]\n",
        "for i in range(pred_cnn_prob.shape[0]):\n",
        "  pred_cnn_prob[i].sort()\n",
        "  if abs(pred_cnn_prob[i][4]-pred_cnn_prob[i][3])<0.96:\n",
        "    error_index_nn.append(i)\n",
        "    error_index_nn_X.append(X_test[i])\n",
        "    error_index_nn_Y.append(y_test[i])\n",
        "print(len(error_index_nn))\n",
        "#print(error_index_nn_X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAIyGBWOTUGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error_index_nn_X1 = np.array(error_index_nn_X)\n",
        "#print(error_index_nn_X1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kmC1tw6SSUs",
        "colab_type": "code",
        "outputId": "3ef2f373-4d1c-49bf-ca54-6e6a596d7d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=4,weights='uniform')\n",
        "neigh.fit(X_train,y_train)\n",
        "\n",
        "filename = 'drive/My Drive/BE FINAL/nsl-kdd_final-code_results/knn_model_anomaly.sav'\n",
        "joblib.dump(neigh, filename)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/My Drive/BE FINAL/nsl-kdd_final-code_results/knn_model_anomaly.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1ZuRRf9VZ_H",
        "colab_type": "code",
        "outputId": "3abf00d6-fb93-4927-b8ec-c1130b4f8139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_knn = neigh.predict(error_index_nn_X1)\n",
        "print('Accuracy Score :',accuracy_score(error_index_nn_Y, pred_knn))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwFUcHsO8mWN",
        "colab_type": "code",
        "outputId": "3c3d0ac1-fc2f-46ff-9c97-627ece21ceb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "pred_knn_prob = neigh.predict_proba(error_index_nn_X1)\n",
        "#pred_cnn1 = model.predict_classes(X_test_nn)\n",
        "\n",
        "print(pred_knn_prob)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5  0.5  0.   0.   0.  ]\n",
            " [0.   0.25 0.   0.5  0.25]\n",
            " [0.   0.5  0.5  0.   0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIW_i5PO8mHd",
        "colab_type": "code",
        "outputId": "abd852c8-ccec-4948-8864-c59c876bf054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "i=0\n",
        "for data in error_index_nn:\n",
        "\n",
        "  pred_knn_prob[i].sort()\n",
        "  if abs(pred_knn_prob[i][4]-pred_knn_prob[i][3])>0.00:\n",
        "    pred_cnn1[data]=pred_knn[i]\n",
        "  else:\n",
        "    print(pred_knn_prob[i])\n",
        "  i+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.  0.  0.  0.5 0.5]\n",
            "[0.  0.  0.  0.5 0.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvUE2saCoHXc",
        "colab_type": "code",
        "outputId": "fde1bc5f-2ce4-465f-b15f-2ce9b5b151e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(Counter(y_test))\n",
        "print(Counter(pred_cnn1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({1: 56, 0: 33, 2: 10, 3: 2, 4: 1})\n",
            "Counter({1: 55, 0: 33, 2: 10, 3: 3, 4: 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rVK_qJToHXe",
        "colab_type": "code",
        "outputId": "192b57f8-b9e7-49df-b3d0-6de1f414ad9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Python script for confusion matrix creation. \n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        " \n",
        "results = confusion_matrix(y_test, pred_cnn1) \n",
        "print('Confusion Matrix :')\n",
        "print(results) \n",
        "print('Accuracy Score :',accuracy_score(y_test, pred_cnn1))\n",
        "print('Report : ')\n",
        "print(classification_report(y_test, pred_cnn1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[33  0  0  0  0]\n",
            " [ 0 55  0  0  1]\n",
            " [ 0  0 10  0  0]\n",
            " [ 0  0  0  2  0]\n",
            " [ 0  0  0  1  0]]\n",
            "Accuracy Score : 0.9803921568627451\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       1.00      0.98      0.99        56\n",
            "           2       1.00      1.00      1.00        10\n",
            "           3       0.67      1.00      0.80         2\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.98       102\n",
            "   macro avg       0.73      0.80      0.76       102\n",
            "weighted avg       0.98      0.98      0.98       102\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ubw_1xfoHXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}